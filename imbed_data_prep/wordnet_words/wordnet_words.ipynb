{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<imbed_data_prep.wordnet_words.WordsDacc at 0x12c22e5a0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordnet words\n",
    "\n",
    "Here's how we made the base dataset. The steps are:\n",
    "* Get a list of most frequent (English) words\n",
    "* Get embeddings for each of these words\n",
    "* Get planar projections for these embeddings\n",
    "* Link the words in various ways (i.e make the link data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set project rootdir here\n",
    "rootdir = \"\"\n",
    "\n",
    "# ... or, if you'll be sharing this notebook, make it so that the rootdir will be entered by the user\n",
    "# and placed in a config file...\n",
    "if not rootdir:\n",
    "    from config2py import config_getter  # pip install config2py\n",
    "\n",
    "    # If the env variable is not set, running this will ask the user to enter the rootdir\n",
    "    # and it will save it for them for future use\n",
    "    rootdir = config_getter('WORDNET_WORDS_PROJECT_ROOTDIR') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peeking at the WordsDacc data accessor\n",
    "\n",
    "`WordsDacc` is your entry to all dataset items. \n",
    "You instantiate it with a rootdir and then ask for data items. \n",
    "If the data is stored in your cache, it will be given to you from there, \n",
    "if it's not, it will compute it (download, prepare, etc.) and store it for further use. \n",
    "You can always refresh (redownload, re-compute, etc.) any data items simply by deleting the file in your rootdir. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imbed_data_prep.wordnet_words import *\n",
    "\n",
    "dacc = WordsDacc(rootdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/thorwhalen/graze/https/wordnetcode.princeton.edu_f/glosstag-files_f/WordNet-3.0-glosstag.zip'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dacc.glosstag_zip_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two raw source data items we start with. \n",
    "The first is the wordnet words (because wordnet has a bunch of linguistic features for these):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(dacc.wordnet_words)=147306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['acceptation', 'accepted', 'accepting', 'acceptive', 'acceptor'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{len(dacc.wordnet_words)=}\")\n",
    "dacc.wordnet_words[1000:1005]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second is a word frequency dataset (a count of words in a very large corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(333333,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "word\n",
       "the    23135851162\n",
       "of     13151942776\n",
       "and    12997637966\n",
       "to     12136980858\n",
       "a       9081174698\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{dacc.word_counts.shape}\")\n",
    "dacc.word_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the intersection of both datasets as our `word_list`. \n",
    "Note that you could also specify your own `word_list` via an argument of that name when \n",
    "making a `dacc = WordsDacc(..., word_list=[...])` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(dacc.word_list)=52078\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(dacc.word_list)=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the words of `word_list`, the `wordnet_metadata` data is a big dataframe containing a bunch of information on these words. \n",
    "\n",
    "The row is index by a \"lemma\" id. Without going into linguistics theory too much, we should at least mention this: \n",
    "A \"word\" (or \"lemma name\") is a string of characters, but it could have various meanings (indexed here by \"synset\"), and for each of \n",
    "these (word, meaning) combinations (indexed by \"lemma\") therefore, different characteristics (definition, pos (\"part of speech\"), etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74192, 29)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "example                   He cast a young woman in the role of Desdemona\n",
       "lemmas                                                   [cast, casting]\n",
       "definition             select to play,sing, or dance a part in a play...\n",
       "lexname                                                    verb.creation\n",
       "name                                                           cast.v.03\n",
       "pos                                                                 verb\n",
       "attributes                                                            []\n",
       "causes                                                                []\n",
       "entailments                        [stage.v.01, film.v.02, perform.v.01]\n",
       "hypernyms                                                [delegate.v.02]\n",
       "hyponyms                      [recast.v.01, typecast.v.01, miscast.v.01]\n",
       "in_region_domains                                                     []\n",
       "in_topic_domains                                                      []\n",
       "in_usage_domains                                                      []\n",
       "instance_hypernyms                                                    []\n",
       "instance_hyponyms                                                     []\n",
       "member_holonyms                                                       []\n",
       "member_meronyms                                                       []\n",
       "part_holonyms                                                         []\n",
       "part_meronyms                                                         []\n",
       "region_domains                                                        []\n",
       "root_hypernyms                                            [appoint.v.02]\n",
       "similar_tos                                                           []\n",
       "substance_holonyms                                                    []\n",
       "substance_meronyms                                                    []\n",
       "topic_domains                                     [performing_arts.n.01]\n",
       "usage_domains                                                         []\n",
       "verb_groups                                                  [cast.v.05]\n",
       "definition_mentions    [a.n.06, a.n.07, act.v.03, act.v.05, act.v.10,...\n",
       "Name: cast.v.03, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = dacc.wordnet_metadata\n",
    "print(f\"{meta.shape}\")\n",
    "meta.loc['cast.v.03']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at what different POS ([part-of-speech](https://www.geeksforgeeks.org/nlp-part-of-speech-default-tagging/))\n",
    "categories we have in this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos\n",
       "noun                   46474\n",
       "verb                   11407\n",
       "adjective_satellite     7917\n",
       "adjective               5809\n",
       "adverb                  2585\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.pos.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used an OpenAI embeddings model to compute the embeddings of each (individual) word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dacc.words_embeddings.shape=(52078, 1)\n",
      "Vector size: 1536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "embedding    [0.02674213983118534, 0.008698769845068455, -0...\n",
       "Name: a, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{dacc.words_embeddings.shape=}\")\n",
    "print(f\"Vector size: {len(dacc.words_embeddings.iloc[0].embedding)}\")\n",
    "dacc.words_embeddings.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then can get a planar embedding of these multi-dimensional vectors using all kinds of methods.\n",
    "\n",
    "Here we use UMAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dacc.umap_embeddings.shape=(52078, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>umap_x</th>\n",
       "      <th>umap_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abnormal</th>\n",
       "      <td>0.814811</td>\n",
       "      <td>9.603489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abnormality</th>\n",
       "      <td>0.899243</td>\n",
       "      <td>9.588635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abnormally</th>\n",
       "      <td>0.872207</td>\n",
       "      <td>9.655293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abo</th>\n",
       "      <td>2.871932</td>\n",
       "      <td>3.976475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aboard</th>\n",
       "      <td>0.326998</td>\n",
       "      <td>5.151422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               umap_x    umap_y\n",
       "word                           \n",
       "abnormal     0.814811  9.603489\n",
       "abnormality  0.899243  9.588635\n",
       "abnormally   0.872207  9.655293\n",
       "abo          2.871932  3.976475\n",
       "aboard       0.326998  5.151422"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{dacc.umap_embeddings.shape=}\")\n",
    "dacc.umap_embeddings.iloc[100:105]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `words_and_features` joins a bunch of these data aspects together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dacc.wordnet_feature_meta.shape=(123587, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "word                                                          a\n",
       "frequency                                              0.015441\n",
       "definition    a metric unit of length equal to one ten billi...\n",
       "lexname                                           noun.quantity\n",
       "name                                              angstrom.n.01\n",
       "pos                                                        noun\n",
       "umap_x                                                 3.027916\n",
       "umap_y                                                 3.760965\n",
       "Name: angstrom.n.01.a, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{dacc.wordnet_feature_meta.shape=}\")\n",
    "dacc.wordnet_feature_meta.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making link data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the metadata items we have are lists of synsets (often empty). \n",
    "These have been accessed via the `wordnet_collection_meta` dataframe\n",
    "and can be used to connect some synsets to other synsets, therefore some words to other words.\n",
    "\n",
    "In WordNet, a **synset** (short for \"synonym set\") is a group of words that share the same meaning or concept. Think of it as a cluster of synonyms that can be used interchangeably in certain contexts without changing the overall meaning. For example, the words \"happy,\" \"joyful,\" and \"elated\" might belong to the same synset because they convey similar emotions.\n",
    "\n",
    "The synset relationships are as follows:\n",
    "\n",
    "* **attributes**: These are qualities or characteristics associated with a synset. *Example*: For the synset representing \"banana,\" an attribute might be \"yellow.\"\n",
    "* **causes**: This relationship indicates that one synset brings about or results in another. *Example*: \"Tickling\" (synset) causes \"laughter\" (synset).\n",
    "* **entailments**: Primarily used for verbs, this relationship means that one action logically necessitates another. *Example*: If someone is \"snoring,\" it entails that they are \"sleeping.\"\n",
    "* **hypernyms**: A hypernym is a more general term that encompasses more specific instances. *Example*: \"Vehicle\" is a hypernym of \"car.\"\n",
    "* **hyponyms**: A hyponym is a more specific term within a broader category. *Example*: \"Poodle\" is a hyponym of \"dog.\"\n",
    "* **in_region_domains**: This denotes the regional usage of a synset, indicating where a term is commonly used. *Example*: The term \"biscuit\" in British English refers to what Americans call a \"cookie.\"\n",
    "* **in_topic_domains**: This shows the subject area or field to which a synset belongs. *Example*: The term \"quantum\" belongs to the domain of physics.\n",
    "* **in_usage_domains**: This indicates the context or manner in which a term is used. *Example*: \"LOL\" is used in informal, internet communication.\n",
    "* **instance_hypernyms**: This relationship links a specific instance to its general category. *Example*: \"Einstein\" is an instance of the hypernym \"physicist.\"\n",
    "* **instance_hyponyms**: This connects a general category to its specific instances. *Example*: \"Physicist\" has instance hyponyms like \"Einstein\" and \"Newton.\"\n",
    "* **member_holonyms**: This indicates the whole to which a member belongs. *Example*: A \"tree\" is a member of the holonym \"forest.\"\n",
    "* **member_meronyms**: This shows the members that constitute a collective whole. *Example*: \"Player\" is a member meronym of \"team.\"\n",
    "* **part_holonyms**: This denotes the whole object that a part belongs to. *Example*: A \"wheel\" is part of the holonym \"car.\"\n",
    "* **part_meronyms**: This indicates the parts that make up a whole object. *Example*: \"Keyboard\" is a part meronym of \"computer.\"\n",
    "* **region_domains**: This specifies the geographical area where a term is used. *Example*: \"G'day\" is used in the region domain of Australia.\n",
    "* **root_hypernyms**: This refers to the most general term in a hierarchy. *Example*: For \"poodle,\" the root hypernym might be \"entity.\"\n",
    "* **similar_tos**: This indicates synsets that are similar in meaning. *Example*: \"Big\" is similar to \"large.\"\n",
    "* **substance_holonyms**: This shows the whole that a substance is part of. *Example*: \"Flour\" is a substance holonym of \"bread.\"\n",
    "* **substance_meronyms**: This indicates the substances that make up a whole. *Example*: \"Alcohol\" is a substance meronym of \"wine.\"\n",
    "* **topic_domains**: This denotes the subject area a term is associated with. *Example*: \"Molecule\" belongs to the topic domain of chemistry.\n",
    "* **usage_domains**: This specifies the context in which a term is appropriately used. *Example*: \"Thou\" is used in archaic or poetic contexts.\n",
    "* **verb_groups**: This links verbs that are similar in meaning or usage. *Example*: \"Run\" and \"jog\" might be in the same verb group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imbed_data_prep.wordnet_words import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "attributes                                                            []\n",
       "causes                                                                []\n",
       "definition_mentions    [a.n.06, a.n.07, act.v.03, act.v.05, act.v.10,...\n",
       "entailments                        [stage.v.01, film.v.02, perform.v.01]\n",
       "hypernyms                                                [delegate.v.02]\n",
       "hyponyms                      [recast.v.01, typecast.v.01, miscast.v.01]\n",
       "in_region_domains                                                     []\n",
       "in_topic_domains                                                      []\n",
       "in_usage_domains                                                      []\n",
       "instance_hypernyms                                                    []\n",
       "instance_hyponyms                                                     []\n",
       "member_holonyms                                                       []\n",
       "member_meronyms                                                       []\n",
       "part_holonyms                                                         []\n",
       "part_meronyms                                                         []\n",
       "region_domains                                                        []\n",
       "root_hypernyms                                            [appoint.v.02]\n",
       "similar_tos                                                           []\n",
       "substance_holonyms                                                    []\n",
       "substance_meronyms                                                    []\n",
       "topic_domains                                     [performing_arts.n.01]\n",
       "usage_domains                                                         []\n",
       "verb_groups                                                  [cast.v.05]\n",
       "Name: cast.v.03, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_meta = dacc.wordnet_collection_meta\n",
    "collection_meta.loc['cast.v.03']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['attributes', 'causes', 'definition_mentions', 'entailments',\n",
       "       'hypernyms', 'hyponyms', 'in_region_domains', 'in_topic_domains',\n",
       "       'in_usage_domains', 'instance_hypernyms', 'instance_hyponyms',\n",
       "       'member_holonyms', 'member_meronyms', 'part_holonyms', 'part_meronyms',\n",
       "       'region_domains', 'root_hypernyms', 'similar_tos', 'substance_holonyms',\n",
       "       'substance_meronyms', 'topic_domains', 'usage_domains', 'verb_groups'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dacc.wordnet_collection_meta.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To compute and save all link data, uncomment and run the following line:\n",
    "dacc.compute_and_save_all_link_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glosstag_edges = dacc.glosstag_edges()\n",
    "print(f\"{glosstag_edges.shape=}\")\n",
    "glosstag_edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glosstag_edges.shape=(412241, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entity.n.01</td>\n",
       "      <td>perceive.v.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entity.n.01</td>\n",
       "      <td>known.a.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entity.n.01</td>\n",
       "      <td>understand.v.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>entity.n.01</td>\n",
       "      <td>deduce.v.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entity.n.01</td>\n",
       "      <td>deduce.v.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        source           target\n",
       "0  entity.n.01    perceive.v.02\n",
       "1  entity.n.01       known.a.01\n",
       "2  entity.n.01  understand.v.04\n",
       "3  entity.n.01      deduce.v.01\n",
       "4  entity.n.01      deduce.v.02"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive word to (word definition) words link data\n",
    "\n",
    "Here we would like to link words to the words that are used to define them.\n",
    "\n",
    "`word_indexed_metadata` offers a \"naive\" way to do this.\n",
    "\n",
    "It is naïve in the sense that it literally makes links between a word and the words that make up it's definition.\n",
    "What is the problem with that? The fact that a words have different meanings sometimes. Therefore, they will have multiple definitions. We saw that here by taking the top definition, which is the most common sense of the word. \n",
    "\"Oh fine!\" you may think. We'll just have one definition represented. What's the fuss all about?!\n",
    "\n",
    "Well, my dear naïve reader, the fuss is about the intent of creating linked in the first place.\n",
    "We want to see meaningful connections and clusters in the structure of the graph we are creating.\n",
    " If we take a word and connect it to the words used in the top definition, who is to say that the words that are used in that definition will be used in the the top sense of that word? The fact is, they will not! \n",
    " And that is a problem for our intent of having a semantically meaningful structure.\n",
    "\n",
    "What is really needed is to connect meanings, or \"synsets\" as wordnet calls them. \n",
    "But will do that in the next step, because it requires a different kind of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words: 52078\n",
      "\n",
      "Example: Single row for 'a':\n",
      "synset                                                            a.n.06\n",
      "example                                                                 \n",
      "definition                          the 1st letter of the Roman alphabet\n",
      "lexname                                               noun.communication\n",
      "name                                                              a.n.06\n",
      "pos                                                                 noun\n",
      "attributes                                                            []\n",
      "causes                                                                []\n",
      "entailments                                                           []\n",
      "hypernyms                                                  [letter.n.02]\n",
      "hyponyms                                                              []\n",
      "in_region_domains                                                     []\n",
      "in_topic_domains                                                      []\n",
      "in_usage_domains                                                      []\n",
      "instance_hypernyms                                                    []\n",
      "instance_hyponyms                                                     []\n",
      "member_holonyms                                    [roman_alphabet.n.01]\n",
      "member_meronyms                                                       []\n",
      "part_holonyms                                                         []\n",
      "part_meronyms                                                         []\n",
      "region_domains                                                        []\n",
      "root_hypernyms                                             [entity.n.01]\n",
      "similar_tos                                                           []\n",
      "substance_holonyms                                                    []\n",
      "substance_meronyms                                                    []\n",
      "topic_domains                                                         []\n",
      "usage_domains                                                         []\n",
      "verb_groups                                                           []\n",
      "definition_mentions    [alphabet.n.01, letter.n.01, letter.n.02, lett...\n",
      "frequency                                                       0.015441\n",
      "umap_x                                                          3.027916\n",
      "umap_y                                                          3.760965\n",
      "Name: a, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Explore the word-indexed metadata (unique words with single definitions)\n",
    "word_indexed_meta = dacc.word_indexed_metadata\n",
    "\n",
    "print(f\"Total unique words: {len(word_indexed_meta)}\")\n",
    "print(f\"\\nExample: Single row for 'a':\")\n",
    "if 'a' in word_indexed_meta.index:\n",
    "    print(word_indexed_meta.loc['a'])\n",
    "else:\n",
    "    print(word_indexed_meta.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total word links: 350581\n",
      "\n",
      "First few rows:\n",
      "  source     target\n",
      "0      a     letter\n",
      "1      a      roman\n",
      "2      a   alphabet\n",
      "3     aa          a\n",
      "4     aa        dry\n",
      "5     aa       form\n",
      "6     aa       lava\n",
      "7    aaa         an\n",
      "8    aaa   aneurysm\n",
      "9    aaa  abdominal\n"
     ]
    }
   ],
   "source": [
    "# Get the word definition links using the module\n",
    "word_links_df = dacc.words_used_in_definition_of_words\n",
    "\n",
    "print(f\"Total word links: {len(word_links_df)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(word_links_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More correct word to (word definition) words link data (uses synsets)\n",
    "\n",
    "As we have already mentioned, there is a problem in our word-to-definition-words approach. \n",
    "Here is a more technical expression of this problem, as well as the solution we will use. \n",
    "\n",
    "A graph built from **lemmas** (surface word forms) appearing in WordNet glosses \n",
    "(what we called \"definitions\" here to be comprehensible to the non-linguist!) collapses\n",
    "distinct meanings into a single node, thereby erasing the core design principle of\n",
    "WordNet: the separation of **word forms** from **senses** (synsets). Most English lemmas\n",
    "are polysemous, often highly so (_set_, _run_, _light_, _charge_, _matter_), and the gloss\n",
    "of a synset uses these lemmas in a _sense-specific_ way. If edges are drawn from a\n",
    "source lemma to the lemmas appearing in its definition, the resulting graph entangles\n",
    "multiple unrelated senses into the same neighborhood. The structure then reflects\n",
    "orthographic coincidence rather than semantic relation. This produces systematic\n",
    "artifacts: high-frequency polysemous lemmas become artificial hubs, semantic\n",
    "communities blur, and graph metrics (centrality, clustering, path length) are dominated\n",
    "by ambiguity rather than meaning.\n",
    "\n",
    "The technically correct unit in WordNet is the **synset**, not the lemma. \n",
    "What a gloss actually does is reference _other senses_, \n",
    "but it does so implicitly through lemmas. \n",
    "To recover the intended structure, each gloss token must be mapped from its lemma to \n",
    "the appropriate **sense key**, and from there to the corresponding **synset**. \n",
    "This is precisely a **word sense disambiguation (WSD)** problem over gloss text. \n",
    "Without this step, a “word→word in definition” graph is fundamentally mis-specified: \n",
    "it encodes string co-occurrence, not semantic reference. \n",
    "Only after resolving gloss lemmas to their intended synsets does the graph become \n",
    "a meaningful **synset→synset** **definitional reference network**.\n",
    "\n",
    "The issue of ambiguous lemma strings in WordNet glosses is addressed by using the **Semantically Tagged Glosses / Princeton Annotated Gloss Corpus (“GlossTag”)** dataset from Princeton (https://wordnetcode.princeton.edu/glosstag.shtml). This resource provides **sense-tagged versions of WordNet glosses**, where each content word in a gloss has been annotated with its correct **WordNet sense key**, effectively solving the word sense disambiguation problem over definitions. The code we wrote reads the merged XML files from the GlossTag release, extracts these sense keys from the WSD-annotated glosses, resolves them to WordNet synset IDs via NLTK’s WordNet interface, and constructs a clean **synset→synset edge list** as a pandas DataFrame with `source` and `target` columns. This transforms raw lemma sequences in definitions into semantically meaningful synset reference graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entity.n.01</td>\n",
       "      <td>perceive.v.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entity.n.01</td>\n",
       "      <td>known.a.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entity.n.01</td>\n",
       "      <td>understand.v.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>entity.n.01</td>\n",
       "      <td>deduce.v.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entity.n.01</td>\n",
       "      <td>deduce.v.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412236</th>\n",
       "      <td>vexatiously.r.01</td>\n",
       "      <td>manner.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412237</th>\n",
       "      <td>wrongfully.r.01</td>\n",
       "      <td>inequitable.a.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412238</th>\n",
       "      <td>wrongfully.r.01</td>\n",
       "      <td>unfair.a.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412239</th>\n",
       "      <td>wrongfully.r.01</td>\n",
       "      <td>unjust.a.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412240</th>\n",
       "      <td>wrongfully.r.01</td>\n",
       "      <td>manner.n.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>412241 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  source            target\n",
       "0            entity.n.01     perceive.v.02\n",
       "1            entity.n.01        known.a.01\n",
       "2            entity.n.01   understand.v.04\n",
       "3            entity.n.01       deduce.v.01\n",
       "4            entity.n.01       deduce.v.02\n",
       "...                  ...               ...\n",
       "412236  vexatiously.r.01       manner.n.01\n",
       "412237   wrongfully.r.01  inequitable.a.01\n",
       "412238   wrongfully.r.01       unfair.a.01\n",
       "412239   wrongfully.r.01       unjust.a.02\n",
       "412240   wrongfully.r.01       manner.n.01\n",
       "\n",
       "[412241 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glosstag_links = dacc.glosstag_edges()\n",
    "glosstag_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angstrom.n.01</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>angstrom.n.01</td>\n",
       "      <td>angstrom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>angstrom.n.01</td>\n",
       "      <td>as</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vitamin_a.n.01</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vitamin_a.n.01</td>\n",
       "      <td>as</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123582</th>\n",
       "      <td>zydeco.n.01</td>\n",
       "      <td>zydeco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123583</th>\n",
       "      <td>zygomatic.a.01</td>\n",
       "      <td>zygomatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123584</th>\n",
       "      <td>zygote.n.01</td>\n",
       "      <td>zygote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123585</th>\n",
       "      <td>zygotic.a.01</td>\n",
       "      <td>zygotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123586</th>\n",
       "      <td>proenzyme.n.01</td>\n",
       "      <td>zymogen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123587 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                source     target\n",
       "0        angstrom.n.01          a\n",
       "1        angstrom.n.01   angstrom\n",
       "2        angstrom.n.01         as\n",
       "3       vitamin_a.n.01          a\n",
       "4       vitamin_a.n.01         as\n",
       "...                ...        ...\n",
       "123582     zydeco.n.01     zydeco\n",
       "123583  zygomatic.a.01  zygomatic\n",
       "123584     zygote.n.01     zygote\n",
       "123585    zygotic.a.01    zygotic\n",
       "123586  proenzyme.n.01    zymogen\n",
       "\n",
       "[123587 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synsets_and_lemmas_links = dacc.synsets_and_lemmas_links\n",
    "metadata = dacc.synsets_and_lemmas_meta\n",
    "synsets_and_lemmas_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sleep_together.v.01</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beloved.n.01</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love.v.02</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>love.n.01</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>love.n.02</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>love.n.04</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>love.n.05</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sexual_love.n.02</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>love.v.01</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>love.v.03</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sleep_together.v.01</td>\n",
       "      <td>bang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sleep_together.v.01</td>\n",
       "      <td>banging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sleep_together.v.01</td>\n",
       "      <td>bed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sleep_together.v.01</td>\n",
       "      <td>bedded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sleep_together.v.01</td>\n",
       "      <td>bedding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sleep_together.v.01</td>\n",
       "      <td>bonk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sleep_together.v.01</td>\n",
       "      <td>eff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sleep_together.v.01</td>\n",
       "      <td>fuck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sleep_together.v.01</td>\n",
       "      <td>fucking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sleep_together.v.01</td>\n",
       "      <td>hump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sleep_together.v.01</td>\n",
       "      <td>humped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sleep_together.v.01</td>\n",
       "      <td>jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sleep_together.v.01</td>\n",
       "      <td>know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sleep_together.v.01</td>\n",
       "      <td>knowing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sleep_together.v.01</td>\n",
       "      <td>known</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sleep_together.v.01</td>\n",
       "      <td>loved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sleep_together.v.01</td>\n",
       "      <td>loving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sleep_together.v.01</td>\n",
       "      <td>screw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sleep_together.v.01</td>\n",
       "      <td>screwing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>beloved.n.01</td>\n",
       "      <td>beloved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>beloved.n.01</td>\n",
       "      <td>dear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>beloved.n.01</td>\n",
       "      <td>dearest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>beloved.n.01</td>\n",
       "      <td>honey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>love.v.02</td>\n",
       "      <td>enjoy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>love.v.02</td>\n",
       "      <td>loved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>love.v.02</td>\n",
       "      <td>loving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>love.n.02</td>\n",
       "      <td>passion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>sexual_love.n.02</td>\n",
       "      <td>lovemaking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>love.v.01</td>\n",
       "      <td>loved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>love.v.01</td>\n",
       "      <td>loving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>love.v.03</td>\n",
       "      <td>loved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>love.v.03</td>\n",
       "      <td>loving</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 source      target\n",
       "0   sleep_together.v.01        love\n",
       "1          beloved.n.01        love\n",
       "2             love.v.02        love\n",
       "3             love.n.01        love\n",
       "4             love.n.02        love\n",
       "5             love.n.04        love\n",
       "6             love.n.05        love\n",
       "7      sexual_love.n.02        love\n",
       "8             love.v.01        love\n",
       "9             love.v.03        love\n",
       "10  sleep_together.v.01        bang\n",
       "11  sleep_together.v.01     banging\n",
       "12  sleep_together.v.01         bed\n",
       "13  sleep_together.v.01      bedded\n",
       "14  sleep_together.v.01     bedding\n",
       "15  sleep_together.v.01        bonk\n",
       "16  sleep_together.v.01         eff\n",
       "17  sleep_together.v.01        fuck\n",
       "18  sleep_together.v.01     fucking\n",
       "19  sleep_together.v.01        hump\n",
       "20  sleep_together.v.01      humped\n",
       "21  sleep_together.v.01        jazz\n",
       "22  sleep_together.v.01        know\n",
       "23  sleep_together.v.01     knowing\n",
       "24  sleep_together.v.01       known\n",
       "25  sleep_together.v.01       loved\n",
       "26  sleep_together.v.01      loving\n",
       "27  sleep_together.v.01       screw\n",
       "28  sleep_together.v.01    screwing\n",
       "29         beloved.n.01     beloved\n",
       "30         beloved.n.01        dear\n",
       "31         beloved.n.01     dearest\n",
       "32         beloved.n.01       honey\n",
       "33            love.v.02       enjoy\n",
       "34            love.v.02       loved\n",
       "35            love.v.02      loving\n",
       "36            love.n.02     passion\n",
       "37     sexual_love.n.02  lovemaking\n",
       "38            love.v.01       loved\n",
       "39            love.v.01      loving\n",
       "40            love.v.03       loved\n",
       "41            love.v.03      loving"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imbed_data_prep.wordnet_words import nhop_links\n",
    "\n",
    "nhop_subgraph = nhop_links(synsets_and_lemmas_links, nodes=['love'], n_hops=2)\n",
    "nhop_subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only the metadata for nodes in the subgraph (any metadata.item value that is a value of source or target in the subgraph)\n",
    "sub_metadata = metadata[metadata.item.isin(nhop_subgraph['source']) | metadata.item.isin(nhop_subgraph['target'])]\n",
    "sub_metadata.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item    sleep_together.v.01\n",
       "kind                 synset\n",
       "Name: 6218, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_metadata.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ec375d969d4b8d81b7446d1b77ddc7",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "Cosmograph(background_color=None, components_display_state_mode=None, focused_point_ring_color=None, hovered_p…"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cosmograph import cosmo\n",
    "\n",
    "cosmo(points=sub_metadata, links=nhop_subgraph, point_index_by='item', link_source_by='source', link_target_by='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you haven't done this once on this machine:\n",
    "# import nltk\n",
    "# nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download GlossTag from https://wordnet.princeton.edu/downloads/glosstag, and unarchive...\n",
    "# Define where your GlossTag merged XML files are:\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "glosstag_merged_dir = Path(\"~/Downloads/WordNet-3.0/glosstag/merged\").expanduser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glosstag_links_df.shape=(412241, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n00001740</td>\n",
       "      <td>v00591519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n00001740</td>\n",
       "      <td>a01375174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n00001740</td>\n",
       "      <td>v00593522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n00001740</td>\n",
       "      <td>v00636574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n00001740</td>\n",
       "      <td>v00944924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      source     target\n",
       "0  n00001740  v00591519\n",
       "1  n00001740  a01375174\n",
       "2  n00001740  v00593522\n",
       "3  n00001740  v00636574\n",
       "4  n00001740  v00944924"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'dacc' not in locals():\n",
    "    from imbed_data_prep.wordnet_words import WordsDacc\n",
    "\n",
    "    dacc = WordsDacc(rootdir)\n",
    "\n",
    "save_name = \"glosstag_links.parquet\"\n",
    "\n",
    "if save_name not in dacc.df_files:\n",
    "    import pandas as pd\n",
    "\n",
    "    from cosmo_data_prep.build_glosstag_edges import (\n",
    "        build_glosstag_edges_from_merged_dir,\n",
    "    )\n",
    "\n",
    "\n",
    "    glosstag_links_df = build_glosstag_edges_from_merged_dir(\n",
    "        merged_dir=glosstag_merged_dir,\n",
    "        include_examples=False,   # only <def>\n",
    "        dedup_edges=True,         # simple edge list\n",
    "        add_weight=False,         # no weights\n",
    "    )\n",
    "\n",
    "    dacc.df_files[\"glosstag_links.parquet\"] = glosstag_links_df\n",
    "else:\n",
    "    glosstag_links_df = dacc.df_files[\"glosstag_links.parquet\"]\n",
    "\n",
    "print(f\"{glosstag_links_df.shape=}\")\n",
    "glosstag_links_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123587, 123587)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = dacc.wordnet_metadata.index.values\n",
    "len(t), len(set(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word                                                                   a\n",
       "synset                                                     angstrom.n.01\n",
       "example                                                                 \n",
       "definition             a metric unit of length equal to one ten billi...\n",
       "lexname                                                    noun.quantity\n",
       "name                                                       angstrom.n.01\n",
       "pos                                                                 noun\n",
       "attributes                                                            []\n",
       "causes                                                                []\n",
       "entailments                                                           []\n",
       "hypernyms                                      [metric_linear_unit.n.01]\n",
       "hyponyms                                                              []\n",
       "in_region_domains                                                     []\n",
       "in_topic_domains                                                      []\n",
       "in_usage_domains                                                      []\n",
       "instance_hypernyms                                                    []\n",
       "instance_hyponyms                                                     []\n",
       "member_holonyms                                                       []\n",
       "member_meronyms                                                       []\n",
       "part_holonyms                                           [nanometer.n.01]\n",
       "part_meronyms                                           [picometer.n.01]\n",
       "region_domains                                                        []\n",
       "root_hypernyms                                             [entity.n.01]\n",
       "similar_tos                                                           []\n",
       "substance_holonyms                                                    []\n",
       "substance_meronyms                                                    []\n",
       "topic_domains                                                         []\n",
       "usage_domains                                                         []\n",
       "verb_groups                                                           []\n",
       "definition_mentions    [adequate.a.01, assign.v.04, billionth.n.01, b...\n",
       "Name: angstrom.n.01.a, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dacc.wordnet_metadata\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74192, 52078)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.synset.nunique(), df.word.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get data from remote source\n",
    "\n",
    "from imbed_data_prep.wordnet_words import WordsDacc\n",
    "\n",
    "rootdir = __import__('config2py').config_getter('WORDNET_WORDS_PROJECT_ROOTDIR') \n",
    "\n",
    "dacc = WordsDacc(rootdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cosmograph import cosmo\n",
    "\n",
    "# help(cosmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['attributes', 'causes', 'entailments', 'hypernyms', 'hyponyms',\n",
      "       'in_region_domains', 'in_topic_domains', 'in_usage_domains',\n",
      "       'instance_hypernyms', 'instance_hyponyms', 'member_holonyms',\n",
      "       'member_meronyms', 'part_holonyms', 'part_meronyms', 'region_domains',\n",
      "       'root_hypernyms', 'similar_tos', 'substance_holonyms',\n",
      "       'substance_meronyms', 'topic_domains', 'usage_domains', 'verb_groups'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(dacc.wordnet_collection_meta.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deoxyadenosine_monophosphate.n.01.a</td>\n",
       "      <td>nucleotide.n.01.nucleotide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deoxyadenosine_monophosphate.n.01.a</td>\n",
       "      <td>nucleotide.n.01.base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adenine.n.01.a</td>\n",
       "      <td>purine.n.01.purine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                source                      target\n",
       "0  deoxyadenosine_monophosphate.n.01.a  nucleotide.n.01.nucleotide\n",
       "1  deoxyadenosine_monophosphate.n.01.a        nucleotide.n.01.base\n",
       "2                       adenine.n.01.a          purine.n.01.purine"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relationship_name = 'hypernyms'\n",
    "df = dacc.df_files[f\"link_data/{relationship_name}.parquet\"]\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmo(links=df, link_source_by='source', link_target_by='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.metadata import version, PackageNotFoundError\n",
    "\n",
    "\n",
    "version(\"cosmograph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "definition    a metric unit of length equal to one ten billi...\n",
       "lexname                                           noun.quantity\n",
       "name                                              angstrom.n.01\n",
       "pos                                                        noun\n",
       "Name: angstrom.n.01.a, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = dacc.wordnet_feature_meta\n",
    "t.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word                                                                  a\n",
       "count                                                        9081174698\n",
       "lemma                                                   angstrom.n.01.a\n",
       "synset                                                    angstrom.n.01\n",
       "example                                                                \n",
       "definition            a metric unit of length equal to one ten billi...\n",
       "lexname                                                   noun.quantity\n",
       "name                                                      angstrom.n.01\n",
       "pos                                                                noun\n",
       "attributes                                                           []\n",
       "causes                                                               []\n",
       "entailments                                                          []\n",
       "hypernyms                                     [metric_linear_unit.n.01]\n",
       "hyponyms                                                             []\n",
       "in_region_domains                                                    []\n",
       "in_topic_domains                                                     []\n",
       "in_usage_domains                                                     []\n",
       "instance_hypernyms                                                   []\n",
       "instance_hyponyms                                                    []\n",
       "member_holonyms                                                      []\n",
       "member_meronyms                                                      []\n",
       "part_holonyms                                          [nanometer.n.01]\n",
       "part_meronyms                                          [picometer.n.01]\n",
       "region_domains                                                       []\n",
       "root_hypernyms                                            [entity.n.01]\n",
       "similar_tos                                                          []\n",
       "substance_holonyms                                                   []\n",
       "substance_meronyms                                                   []\n",
       "topic_domains                                                        []\n",
       "usage_domains                                                        []\n",
       "verb_groups                                                          []\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge the wordnet metadata with the word counts\n",
    "word_counts = dacc.word_counts.reset_index().rename(columns={'index': 'word'})\n",
    "wordnet_metadata = dacc.wordnet_metadata\n",
    "wordnet_metadata = wordnet_metadata.reset_index().rename(columns={'index': 'word'})\n",
    "# # word_counts.merge(wordnet_metadata, on='word', how='left')\n",
    "t = pd.merge(word_counts, wordnet_metadata, on='word')\n",
    "t.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['word', 'definition', 'lexname', 'name', 'pos']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imbed_data_prep.wordnet_words import *\n",
    "wordnet_feature_attr_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function cosmo in module cosmograph.base:\n",
      "\n",
      "cosmo(data=None, *, disable_simulation: bool = False, simulation_decay: float = 1000, simulation_gravity: float = 0, simulation_center: float = 0, simulation_repulsion: float = 0.1, simulation_repulsion_theta: float = 1.7, simulation_repulsion_quadtree_levels: float = 12, simulation_link_spring: float = 1, simulation_link_distance: float = 2, simulation_link_dist_random_variation_range: list[typing.Any] = [1, 1.2], simulation_repulsion_from_mouse: float = 2, simulation_friction: float = 0.85, simulation_cluster: float = None, background_color: Union[str, list[float]] = '#222222', space_size: int = 4096, point_color: Union[str, list[float]] = '#b3b3b3', point_greyout_opacity: float = 0.1, point_size: float = 4, point_size_scale: float = 1, hovered_point_cursor: str = None, render_hovered_point_ring: bool = 0.7, hovered_point_ring_color: Union[str, list[float]] = 'white', focused_point_ring_color: Union[str, list[float]] = 0.95, focused_point_index: int = None, render_links: bool = True, link_color: Union[str, list[float]] = '#666666', link_greyout_opacity: float = 0.1, link_width: float = 1, link_width_scale: float = 1, curved_links: bool = False, curved_link_segments: int = 19, curved_link_weight: float = 0.8, curved_link_control_point_distance: float = 0.5, link_arrows: bool = None, link_arrows_size_scale: float = 1, link_visibility_distance_range: list[float] = [50, 150], link_visibility_min_transparency: float = 0.25, use_quadtree: bool = False, show_FPS_monitor: bool = False, pixel_ratio: float = 2, scale_points_on_zoom: bool = True, initial_zoom_level: float = 3, disable_zoom: bool = False, enable_drag: bool = None, fit_view_on_init: bool = True, fit_view_delay: float = 250, fit_view_padding: float = None, fit_view_duration: float = None, fit_view_by_points_in_rect: list[list[float]] = None, random_seed: Union[int, str] = None, point_sampling_distance: int = 150, point_id_by: str = None, point_index_by: str = None, point_color_by: str = None, point_size_by: str = None, point_size_range: list[float] = None, point_label_by: str = None, point_label_weight_by: str = None, point_x_by: str = None, point_y_by: str = None, point_cluster_by: str = None, point_cluster_strength_by: str = None, point_include_columns: list[str] = None, link_source_by: str = None, link_source_index_by: str = None, link_target_by: str = None, link_target_index_by: str = None, link_color_by: str = None, link_width_by: str = None, link_arrow_by: str = None, link_strength_by: str = None, link_strength_range: list[float] = None, link_include_columns: list[str] = None, show_labels: bool = None, show_dynamic_labels: bool = None, show_labels_for: list[str] = None, show_top_labels: bool = None, show_top_labels_limit: int = None, show_top_labels_by: str = None, static_label_weight: float = None, dynamic_label_weight: float = None, label_margin: float = None, show_hovered_point_label: bool = None, disable_point_size_legend: bool = None, disable_link_width_legend: bool = None, disable_point_color_legend: bool = None, disable_link_color_legend: bool = None, points: object = None, links: object = None, clicked_point_index: int = None, clicked_point_id: str = None, selected_point_indices: list[int] = None, selected_point_ids: list[str] = None, changePoints: Callable[[Dict[str, Any]], Any] = None, changeLinks: Callable[[Dict[str, Any]], Any] = None)\n",
      "        Thin layer over CosmographWidget to provide a base interface to the widget object\n",
      "        \n",
      "    Parameters\n",
      "    ----------\n",
      "    disable_simulation : bool, default=False\n",
      "        Prevents the simulation from running, merely rendering the graph.\n",
      "    simulation_decay : float, default=1000\n",
      "        Defines how quickly the simulation cools down.\n",
      "    simulation_gravity : float, default=0\n",
      "        Coefficient for gravity force.\n",
      "    simulation_center : float, default=0\n",
      "        Centers the mass force coefficient.\n",
      "    simulation_repulsion : float, default=0.1\n",
      "        Configures point repulsion between points.\n",
      "    simulation_repulsion_theta : float, default=1.7\n",
      "        Decreases / increases the detalization of the Many-Body force calculations.\n",
      "    simulation_repulsion_quadtree_levels : float, default=12\n",
      "        Barnes–Hut approximation depth, usable when useQuadtree is set to True.\n",
      "    simulation_link_spring : float, default=1\n",
      "        Spring constant for links.\n",
      "    simulation_link_distance : float, default=2\n",
      "        Default distance for links.\n",
      "    simulation_link_dist_random_variation_range : list, default=[1, 1.2]\n",
      "        Random link distance range.\n",
      "    simulation_repulsion_from_mouse : float, default=2\n",
      "        Mouse position repulsion coefficient, activated by right-click.\n",
      "    simulation_friction : float, default=0.85\n",
      "        Sets simulation friction.\n",
      "    simulation_cluster : float, default=None\n",
      "        \n",
      "    background_color : typing.Union[str, list[float]], default=\"#222222\"\n",
      "        Canvas background color.\n",
      "    space_size : int, default=4096\n",
      "        Size of the simulation space.\n",
      "    point_color : typing.Union[str, list[float]], default=\"#b3b3b3\"\n",
      "        Column name for point colors.\n",
      "    point_greyout_opacity : float, default=0.1\n",
      "        Opacity of unselected nodes during selection.\n",
      "    point_size : float, default=4\n",
      "        Column name for point sizes.\n",
      "    point_size_scale : float, default=1\n",
      "        Scale factor for point sizes.\n",
      "    hovered_point_cursor : str, default=None\n",
      "        Cursor type when hovering over a point.\n",
      "    render_hovered_point_ring : bool, default=0.7\n",
      "        Enables ring around hovered points.\n",
      "    hovered_point_ring_color : typing.Union[str, list[float]], default=\"white\"\n",
      "        Color of hovered point ring.\n",
      "    focused_point_ring_color : typing.Union[str, list[float]], default=0.95\n",
      "        Color of the focused point ring.\n",
      "    focused_point_index : int, default=None\n",
      "        Index of the focused point, prioritized over focus_point method.\n",
      "    render_links : bool, default=True\n",
      "        Enables or disables link rendering.\n",
      "    link_color : typing.Union[str, list[float]], default=\"#666666\"\n",
      "        Column name for link colors.\n",
      "    link_greyout_opacity : float, default=0.1\n",
      "        Opacity of unselected links during selection.\n",
      "    link_width : float, default=1\n",
      "        Column name for link widths.\n",
      "    link_width_scale : float, default=1\n",
      "        Scale factor for link widths.\n",
      "    curved_links : bool, default=False\n",
      "        Enables or disables curved links.\n",
      "    curved_link_segments : int, default=19\n",
      "        Segments defining curved links.\n",
      "    curved_link_weight : float, default=0.8\n",
      "        Weight factor for link curvature.\n",
      "    curved_link_control_point_distance : float, default=0.5\n",
      "        Control point positioning for curves.\n",
      "    link_arrows : bool, default=None\n",
      "        \n",
      "    link_arrows_size_scale : float, default=1\n",
      "        Scale factor for link arrow size.\n",
      "    link_visibility_distance_range : list, default=[50, 150]\n",
      "        Pixel distance range for link transparency.\n",
      "    link_visibility_min_transparency : float, default=0.25\n",
      "        Minimum transparency of links based on link_visibility_distance_range.\n",
      "    use_quadtree : bool, default=False\n",
      "        Activates quadtree algorithm for Many-Body force when set to True.\n",
      "    show_FPS_monitor : bool, default=False\n",
      "        Display an FPS counter in the upper right corner of the canvas.\n",
      "    pixel_ratio : float, default=2\n",
      "        Canvas pixel ratio.\n",
      "    scale_points_on_zoom : bool, default=True\n",
      "        Scales point sizes when zooming.\n",
      "    initial_zoom_level : float, default=3\n",
      "        Starting zoom level.\n",
      "    disable_zoom : bool, default=False\n",
      "        Enables or disables zooming.\n",
      "    enable_drag : bool, default=None\n",
      "        Allows graph dragging.\n",
      "    fit_view_on_init : bool, default=True\n",
      "        Automatically fits view to all points upon initialization.\n",
      "    fit_view_delay : float, default=250\n",
      "        Delay for fitting view after initialization in milliseconds.\n",
      "    fit_view_padding : float, default=None\n",
      "        Padding around fit view area.\n",
      "    fit_view_duration : float, default=None\n",
      "        Animation duration for view fitting in milliseconds.\n",
      "    fit_view_by_points_in_rect : list, default=None\n",
      "        Fits view to specified rectangle of points, active when fit_view_on_init is True.\n",
      "    random_seed : typing.Union[int, str], default=None\n",
      "        Seed value for generating random numbers in simulations.\n",
      "    point_sampling_distance : int, default=150\n",
      "        Distance threshold for sampling points.\n",
      "    point_id_by : str, default=None\n",
      "        \n",
      "    point_index_by : str, default=None\n",
      "        \n",
      "    point_color_by : str, default=None\n",
      "        \n",
      "    point_size_by : str, default=None\n",
      "        \n",
      "    point_size_range : list, default=None\n",
      "        \n",
      "    point_label_by : str, default=None\n",
      "        \n",
      "    point_label_weight_by : str, default=None\n",
      "        \n",
      "    point_x_by : str, default=None\n",
      "        \n",
      "    point_y_by : str, default=None\n",
      "        \n",
      "    point_cluster_by : str, default=None\n",
      "        \n",
      "    point_cluster_strength_by : str, default=None\n",
      "        \n",
      "    point_include_columns : list, default=None\n",
      "        An array of additional column names to include in point data.\n",
      "    link_source_by : str, default=None\n",
      "        \n",
      "    link_source_index_by : str, default=None\n",
      "        \n",
      "    link_target_by : str, default=None\n",
      "        \n",
      "    link_target_index_by : str, default=None\n",
      "        \n",
      "    link_color_by : str, default=None\n",
      "        \n",
      "    link_width_by : str, default=None\n",
      "        \n",
      "    link_arrow_by : str, default=None\n",
      "        \n",
      "    link_strength_by : str, default=None\n",
      "        \n",
      "    link_strength_range : list, default=None\n",
      "        \n",
      "    link_include_columns : list, default=None\n",
      "        An array of additional column names to include in link data.\n",
      "    show_labels : bool, default=None\n",
      "        \n",
      "    show_dynamic_labels : bool, default=None\n",
      "        Flag to show dynamic labels for visible points.\n",
      "    show_labels_for : list, default=None\n",
      "        An array of point ids for which to show labels.\n",
      "    show_top_labels : bool, default=None\n",
      "        Flag to display labels for the top points.\n",
      "    show_top_labels_limit : int, default=None\n",
      "        Maximum number of top points to show labels for.\n",
      "    show_top_labels_by : str, default=None\n",
      "        Column to determine which points are considered as a top.\n",
      "    static_label_weight : float, default=None\n",
      "        Weight of static labels.\n",
      "    dynamic_label_weight : float, default=None\n",
      "        Weight of dynamic labels.\n",
      "    label_margin : float, default=None\n",
      "        \n",
      "    show_hovered_point_label : bool, default=None\n",
      "        Flag to display the label for the currently hovered point.\n",
      "    disable_point_size_legend : bool, default=None\n",
      "        \n",
      "    disable_link_width_legend : bool, default=None\n",
      "        \n",
      "    disable_point_color_legend : bool, default=None\n",
      "        \n",
      "    disable_link_color_legend : bool, default=None\n",
      "        \n",
      "    points : object, default=None\n",
      "        Data in a pandas DataFrame format.\n",
      "    links : object, default=None\n",
      "        Data in a pandas DataFrame format.\n",
      "    clicked_point_index : int, default=None\n",
      "        \n",
      "    clicked_point_id : str, default=None\n",
      "        \n",
      "    selected_point_indices : list, default=None\n",
      "        \n",
      "    selected_point_ids : list, default=None\n",
      "        \n",
      "    changePoints : typing.Callable[[typing.Dict[str, typing.Any]], typing.Any], default=None\n",
      "        \n",
      "    changeLinks : typing.Callable[[typing.Dict[str, typing.Any]], typing.Any], default=None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cosmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function cosmo in module cosmograph.base:\n",
      "\n",
      "cosmo(data=None, *, disable_simulation: bool = False, simulation_decay: float = 1000, simulation_gravity: float = 0, simulation_center: float = 0, simulation_repulsion: float = 0.1, simulation_repulsion_theta: float = 1.7, simulation_repulsion_quadtree_levels: float = 12, simulation_link_spring: float = 1, simulation_link_distance: float = 2, simulation_link_dist_random_variation_range: list[typing.Any] = [1, 1.2], simulation_repulsion_from_mouse: float = 2, simulation_friction: float = 0.85, simulation_cluster: float = None, background_color: Union[str, list[float]] = '#222222', space_size: int = 4096, point_color: Union[str, list[float]] = '#b3b3b3', point_greyout_opacity: float = 0.1, point_size: float = 4, point_size_scale: float = 1, hovered_point_cursor: str = None, render_hovered_point_ring: bool = 0.7, hovered_point_ring_color: Union[str, list[float]] = 'white', focused_point_ring_color: Union[str, list[float]] = 0.95, focused_point_index: int = None, render_links: bool = True, link_color: Union[str, list[float]] = '#666666', link_greyout_opacity: float = 0.1, link_width: float = 1, link_width_scale: float = 1, curved_links: bool = False, curved_link_segments: int = 19, curved_link_weight: float = 0.8, curved_link_control_point_distance: float = 0.5, link_arrows: bool = None, link_arrows_size_scale: float = 1, link_visibility_distance_range: list[float] = [50, 150], link_visibility_min_transparency: float = 0.25, use_quadtree: bool = False, show_FPS_monitor: bool = False, pixel_ratio: float = 2, scale_points_on_zoom: bool = True, initial_zoom_level: float = 3, disable_zoom: bool = False, enable_drag: bool = None, fit_view_on_init: bool = True, fit_view_delay: float = 250, fit_view_padding: float = None, fit_view_duration: float = None, fit_view_by_points_in_rect: list[list[float]] = None, random_seed: Union[int, str] = None, point_sampling_distance: int = 150, point_id_by: str = None, point_index_by: str = None, point_color_by: str = None, point_size_by: str = None, point_size_range: list[float] = None, point_label_by: str = None, point_label_weight_by: str = None, point_x_by: str = None, point_y_by: str = None, point_cluster_by: str = None, point_cluster_strength_by: str = None, point_include_columns: list[str] = None, link_source_by: str = None, link_source_index_by: str = None, link_target_by: str = None, link_target_index_by: str = None, link_color_by: str = None, link_width_by: str = None, link_arrow_by: str = None, link_strength_by: str = None, link_strength_range: list[float] = None, link_include_columns: list[str] = None, show_labels: bool = None, show_dynamic_labels: bool = None, show_labels_for: list[str] = None, show_top_labels: bool = None, show_top_labels_limit: int = None, show_top_labels_by: str = None, static_label_weight: float = None, dynamic_label_weight: float = None, label_margin: float = None, show_hovered_point_label: bool = None, disable_point_size_legend: bool = None, disable_link_width_legend: bool = None, disable_point_color_legend: bool = None, disable_link_color_legend: bool = None, points: object = None, links: object = None, clicked_point_index: int = None, clicked_point_id: str = None, selected_point_indices: list[int] = None, selected_point_ids: list[str] = None, changePoints: Callable[[Dict[str, Any]], Any] = None, changeLinks: Callable[[Dict[str, Any]], Any] = None)\n",
      "        Thin layer over CosmographWidget to provide a base interface to the widget object\n",
      "        \n",
      "    Parameters\n",
      "    ----------\n",
      "    disable_simulation : bool, default=False\n",
      "        Prevents the simulation from running, merely rendering the graph.\n",
      "    simulation_decay : float, default=1000\n",
      "        Defines how quickly the simulation cools down.\n",
      "    simulation_gravity : float, default=0\n",
      "        Coefficient for gravity force.\n",
      "    simulation_center : float, default=0\n",
      "        Centers the mass force coefficient.\n",
      "    simulation_repulsion : float, default=0.1\n",
      "        Configures point repulsion between points.\n",
      "    simulation_repulsion_theta : float, default=1.7\n",
      "        Decreases / increases the detalization of the Many-Body force calculations.\n",
      "    simulation_repulsion_quadtree_levels : float, default=12\n",
      "        Barnes–Hut approximation depth, usable when useQuadtree is set to True.\n",
      "    simulation_link_spring : float, default=1\n",
      "        Spring constant for links.\n",
      "    simulation_link_distance : float, default=2\n",
      "        Default distance for links.\n",
      "    simulation_link_dist_random_variation_range : list, default=[1, 1.2]\n",
      "        Random link distance range.\n",
      "    simulation_repulsion_from_mouse : float, default=2\n",
      "        Mouse position repulsion coefficient, activated by right-click.\n",
      "    simulation_friction : float, default=0.85\n",
      "        Sets simulation friction.\n",
      "    simulation_cluster : float, default=None\n",
      "        \n",
      "    background_color : typing.Union[str, list[float]], default=\"#222222\"\n",
      "        Canvas background color.\n",
      "    space_size : int, default=4096\n",
      "        Size of the simulation space.\n",
      "    point_color : typing.Union[str, list[float]], default=\"#b3b3b3\"\n",
      "        Column name for point colors.\n",
      "    point_greyout_opacity : float, default=0.1\n",
      "        Opacity of unselected nodes during selection.\n",
      "    point_size : float, default=4\n",
      "        Column name for point sizes.\n",
      "    point_size_scale : float, default=1\n",
      "        Scale factor for point sizes.\n",
      "    hovered_point_cursor : str, default=None\n",
      "        Cursor type when hovering over a point.\n",
      "    render_hovered_point_ring : bool, default=0.7\n",
      "        Enables ring around hovered points.\n",
      "    hovered_point_ring_color : typing.Union[str, list[float]], default=\"white\"\n",
      "        Color of hovered point ring.\n",
      "    focused_point_ring_color : typing.Union[str, list[float]], default=0.95\n",
      "        Color of the focused point ring.\n",
      "    focused_point_index : int, default=None\n",
      "        Index of the focused point, prioritized over focus_point method.\n",
      "    render_links : bool, default=True\n",
      "        Enables or disables link rendering.\n",
      "    link_color : typing.Union[str, list[float]], default=\"#666666\"\n",
      "        Column name for link colors.\n",
      "    link_greyout_opacity : float, default=0.1\n",
      "        Opacity of unselected links during selection.\n",
      "    link_width : float, default=1\n",
      "        Column name for link widths.\n",
      "    link_width_scale : float, default=1\n",
      "        Scale factor for link widths.\n",
      "    curved_links : bool, default=False\n",
      "        Enables or disables curved links.\n",
      "    curved_link_segments : int, default=19\n",
      "        Segments defining curved links.\n",
      "    curved_link_weight : float, default=0.8\n",
      "        Weight factor for link curvature.\n",
      "    curved_link_control_point_distance : float, default=0.5\n",
      "        Control point positioning for curves.\n",
      "    link_arrows : bool, default=None\n",
      "        \n",
      "    link_arrows_size_scale : float, default=1\n",
      "        Scale factor for link arrow size.\n",
      "    link_visibility_distance_range : list, default=[50, 150]\n",
      "        Pixel distance range for link transparency.\n",
      "    link_visibility_min_transparency : float, default=0.25\n",
      "        Minimum transparency of links based on link_visibility_distance_range.\n",
      "    use_quadtree : bool, default=False\n",
      "        Activates quadtree algorithm for Many-Body force when set to True.\n",
      "    show_FPS_monitor : bool, default=False\n",
      "        Display an FPS counter in the upper right corner of the canvas.\n",
      "    pixel_ratio : float, default=2\n",
      "        Canvas pixel ratio.\n",
      "    scale_points_on_zoom : bool, default=True\n",
      "        Scales point sizes when zooming.\n",
      "    initial_zoom_level : float, default=3\n",
      "        Starting zoom level.\n",
      "    disable_zoom : bool, default=False\n",
      "        Enables or disables zooming.\n",
      "    enable_drag : bool, default=None\n",
      "        Allows graph dragging.\n",
      "    fit_view_on_init : bool, default=True\n",
      "        Automatically fits view to all points upon initialization.\n",
      "    fit_view_delay : float, default=250\n",
      "        Delay for fitting view after initialization in milliseconds.\n",
      "    fit_view_padding : float, default=None\n",
      "        Padding around fit view area.\n",
      "    fit_view_duration : float, default=None\n",
      "        Animation duration for view fitting in milliseconds.\n",
      "    fit_view_by_points_in_rect : list, default=None\n",
      "        Fits view to specified rectangle of points, active when fit_view_on_init is True.\n",
      "    random_seed : typing.Union[int, str], default=None\n",
      "        Seed value for generating random numbers in simulations.\n",
      "    point_sampling_distance : int, default=150\n",
      "        Distance threshold for sampling points.\n",
      "    point_id_by : str, default=None\n",
      "        \n",
      "    point_index_by : str, default=None\n",
      "        \n",
      "    point_color_by : str, default=None\n",
      "        \n",
      "    point_size_by : str, default=None\n",
      "        \n",
      "    point_size_range : list, default=None\n",
      "        \n",
      "    point_label_by : str, default=None\n",
      "        \n",
      "    point_label_weight_by : str, default=None\n",
      "        \n",
      "    point_x_by : str, default=None\n",
      "        \n",
      "    point_y_by : str, default=None\n",
      "        \n",
      "    point_cluster_by : str, default=None\n",
      "        \n",
      "    point_cluster_strength_by : str, default=None\n",
      "        \n",
      "    point_include_columns : list, default=None\n",
      "        An array of additional column names to include in point data.\n",
      "    link_source_by : str, default=None\n",
      "        \n",
      "    link_source_index_by : str, default=None\n",
      "        \n",
      "    link_target_by : str, default=None\n",
      "        \n",
      "    link_target_index_by : str, default=None\n",
      "        \n",
      "    link_color_by : str, default=None\n",
      "        \n",
      "    link_width_by : str, default=None\n",
      "        \n",
      "    link_arrow_by : str, default=None\n",
      "        \n",
      "    link_strength_by : str, default=None\n",
      "        \n",
      "    link_strength_range : list, default=None\n",
      "        \n",
      "    link_include_columns : list, default=None\n",
      "        An array of additional column names to include in link data.\n",
      "    show_labels : bool, default=None\n",
      "        \n",
      "    show_dynamic_labels : bool, default=None\n",
      "        Flag to show dynamic labels for visible points.\n",
      "    show_labels_for : list, default=None\n",
      "        An array of point ids for which to show labels.\n",
      "    show_top_labels : bool, default=None\n",
      "        Flag to display labels for the top points.\n",
      "    show_top_labels_limit : int, default=None\n",
      "        Maximum number of top points to show labels for.\n",
      "    show_top_labels_by : str, default=None\n",
      "        Column to determine which points are considered as a top.\n",
      "    static_label_weight : float, default=None\n",
      "        Weight of static labels.\n",
      "    dynamic_label_weight : float, default=None\n",
      "        Weight of dynamic labels.\n",
      "    label_margin : float, default=None\n",
      "        \n",
      "    show_hovered_point_label : bool, default=None\n",
      "        Flag to display the label for the currently hovered point.\n",
      "    disable_point_size_legend : bool, default=None\n",
      "        \n",
      "    disable_link_width_legend : bool, default=None\n",
      "        \n",
      "    disable_point_color_legend : bool, default=None\n",
      "        \n",
      "    disable_link_color_legend : bool, default=None\n",
      "        \n",
      "    points : object, default=None\n",
      "        Data in a pandas DataFrame format.\n",
      "    links : object, default=None\n",
      "        Data in a pandas DataFrame format.\n",
      "    clicked_point_index : int, default=None\n",
      "        \n",
      "    clicked_point_id : str, default=None\n",
      "        \n",
      "    selected_point_indices : list, default=None\n",
      "        \n",
      "    selected_point_ids : list, default=None\n",
      "        \n",
      "    changePoints : typing.Callable[[typing.Dict[str, typing.Any]], typing.Any], default=None\n",
      "        \n",
      "    changeLinks : typing.Callable[[typing.Dict[str, typing.Any]], typing.Any], default=None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from cosmograph import cosmo\n",
    "\n",
    "help(cosmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ad2d1ebadc46a6823189e457d088b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Cosmograph(background_color=None, focused_point_ring_color=None, hovered_point_ring_color=None, link_color=Non…"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosmo(points=pd.DataFrame([[1,2], [3,4], [5,6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from cosmograph import cosmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape=(123587, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "word                                                          a\n",
       "frequency                                              0.015441\n",
       "definition    a metric unit of length equal to one ten billi...\n",
       "lexname                                           noun.quantity\n",
       "name                                              angstrom.n.01\n",
       "pos                                                        noun\n",
       "umap_x                                                 3.027916\n",
       "umap_y                                                 3.760965\n",
       "Name: angstrom.n.01.a, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('https://www.dropbox.com/scl/fi/4mnk1e2wx31j9mdsjzecy/wordnet_feature_meta.parquet?rlkey=ixjiiso80s1uk4yhx1v38ekhm&dl=1')\n",
    "print(f\"{df.shape=}\")\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyponyms.shape=(258896, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "source           vitamin_a.n.01.a\n",
       "target    vitamin_a1.n.01.retinol\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyponyms = pd.read_parquet('https://www.dropbox.com/scl/fi/pl72ixv34soo1o8zanfrz/hyponyms.parquet?rlkey=t4d606fmq1uinn29qmli7bx6r&dl=1')\n",
    "print(f\"{hyponyms.shape=}\")\n",
    "hyponyms.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40bbdedd27ed47c5a4ce8df2612dfba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Cosmograph(background_color=None, focused_point_ring_color=None, hovered_point_ring_color=None, link_color=Non…"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = cosmo(\n",
    "    df,\n",
    "    point_id_by='lemma',\n",
    "    point_label_by='word',\n",
    "    point_x_by='umap_x',\n",
    "    point_y_by='umap_y',\n",
    "    point_color_by='pos',\n",
    "    point_size_by='frequency',\n",
    "    point_size_scale=0.01,  # often have to play with this number to get the size right\n",
    ")\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "583a49c4901b4944bbb9b9fbfaeea5da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Cosmograph(background_color=None, focused_point_ring_color=None, hovered_point_ring_color=None, link_color=Non…"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = cosmo(\n",
    "    points=df,\n",
    "    links=hyponyms,\n",
    "    link_source_by='source',\n",
    "    link_target_by='target',\n",
    "    point_id_by='lemma',\n",
    "    point_label_by='word',\n",
    "    # point_x_by='umap_x',\n",
    "    # point_y_by='umap_y',\n",
    "    point_color_by='pos',\n",
    "    point_size_by='frequency',\n",
    "    point_size_scale=0.01,  # often have to play with this number to get the size right\n",
    ")\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: WIP and scrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>23135851162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>13151942776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>12997637966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>12136980858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>9081174698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333328</th>\n",
       "      <td>gooek</td>\n",
       "      <td>12711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333329</th>\n",
       "      <td>gooddg</td>\n",
       "      <td>12711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333330</th>\n",
       "      <td>gooblle</td>\n",
       "      <td>12711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333331</th>\n",
       "      <td>gollgo</td>\n",
       "      <td>12711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333332</th>\n",
       "      <td>golgw</td>\n",
       "      <td>12711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333333 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word        count\n",
       "0           the  23135851162\n",
       "1            of  13151942776\n",
       "2           and  12997637966\n",
       "3            to  12136980858\n",
       "4             a   9081174698\n",
       "...         ...          ...\n",
       "333328    gooek        12711\n",
       "333329   gooddg        12711\n",
       "333330  gooblle        12711\n",
       "333331   gollgo        12711\n",
       "333332    golgw        12711\n",
       "\n",
       "[333333 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequency_data_url = 'https://github.com/thorwhalen/content/raw/refs/heads/master/tables/csv/zip/english-word-frequency.csv.zip'\n",
    "\n",
    "# Note: The (..., keep_default_na=False, na_values=[]) is to avoid words \"null\" and \"nan\" being interpretted as NaN\n",
    "#    see https://www.skytowner.com/explore/preventing_strings_from_getting_parsed_as_nan_for_read_csv_in_pandas\n",
    "word_counts = pd.read_csv(word_frequency_data_url, keep_default_na=False, na_values=[])\n",
    "word_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word properties (definition, type, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147306"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "len(list(wn.all_lemma_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147306"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lexis  # pip install lexis\n",
    "\n",
    "lemmas = lexis.Lemmas()\n",
    "len(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52078"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The words that are both in the lemmas and in the word_counts\n",
    "word_list = sorted(set(lemmas) & set(word_counts.word))\n",
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['examples',\n",
       " '__slots__',\n",
       " 'in_topic_domains',\n",
       " 'attributes',\n",
       " '_examples',\n",
       " 'frame_ids',\n",
       " 'part_holonyms',\n",
       " 'mst',\n",
       " '_lemma_pointers',\n",
       " 'substance_meronyms',\n",
       " '__module__',\n",
       " '_lexname',\n",
       " '_iter_hypernym_lists',\n",
       " '__dir__',\n",
       " '_instance_hypernyms',\n",
       " 'name',\n",
       " '__hash__',\n",
       " '_min_depth',\n",
       " 'topic_domains',\n",
       " 'acyclic_tree',\n",
       " 'in_usage_domains',\n",
       " '__doc__',\n",
       " 'verb_groups',\n",
       " '__dict__',\n",
       " 'entailments',\n",
       " 'hyponyms',\n",
       " 'substance_holonyms',\n",
       " 'hypernym_distances',\n",
       " '__weakref__',\n",
       " 'root_hypernyms',\n",
       " 'min_depth',\n",
       " 'member_holonyms',\n",
       " '_definition',\n",
       " 'hypernym_paths',\n",
       " 'in_region_domains',\n",
       " 'lemma_names',\n",
       " '_name',\n",
       " '_pointers',\n",
       " 'similar_tos',\n",
       " 'definition',\n",
       " '_lemmas',\n",
       " '_pos',\n",
       " 'max_depth',\n",
       " 'causes',\n",
       " 'instance_hypernyms',\n",
       " 'part_meronyms',\n",
       " '_max_depth',\n",
       " '_needs_root',\n",
       " '_hypernyms',\n",
       " 'instance_hyponyms',\n",
       " '_frame_ids',\n",
       " 'lexname',\n",
       " 'usage_domains',\n",
       " 'also_sees',\n",
       " 'member_meronyms',\n",
       " '__sizeof__',\n",
       " 'hypernyms',\n",
       " '__reduce__',\n",
       " '_lemma_names',\n",
       " '__repr__',\n",
       " 'lemmas',\n",
       " '__str__',\n",
       " 'offset',\n",
       " 'region_domains',\n",
       " 'pos',\n",
       " '_offset']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = lemmas['body']\n",
    "tt = t['body.n.01']\n",
    "list(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the entire structure of an organism (an animal, plant, or human being)'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt['definition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_all_hypernyms',\n",
       " '_definition',\n",
       " '_doc',\n",
       " '_examples',\n",
       " '_frame_ids',\n",
       " '_hypernyms',\n",
       " '_instance_hypernyms',\n",
       " '_iter_hypernym_lists',\n",
       " '_lemma_names',\n",
       " '_lemma_pointers',\n",
       " '_lemmas',\n",
       " '_lexname',\n",
       " '_max_depth',\n",
       " '_min_depth',\n",
       " '_name',\n",
       " '_needs_root',\n",
       " '_offset',\n",
       " '_pointers',\n",
       " '_pos',\n",
       " '_related',\n",
       " '_shortest_hypernym_paths',\n",
       " '_wordnet_corpus_reader',\n",
       " 'acyclic_tree',\n",
       " 'also_sees',\n",
       " 'attributes',\n",
       " 'causes',\n",
       " 'closure',\n",
       " 'common_hypernyms',\n",
       " 'definition',\n",
       " 'entailments',\n",
       " 'examples',\n",
       " 'frame_ids',\n",
       " 'hypernym_distances',\n",
       " 'hypernym_paths',\n",
       " 'hypernyms',\n",
       " 'hyponyms',\n",
       " 'in_region_domains',\n",
       " 'in_topic_domains',\n",
       " 'in_usage_domains',\n",
       " 'instance_hypernyms',\n",
       " 'instance_hyponyms',\n",
       " 'jcn_similarity',\n",
       " 'lch_similarity',\n",
       " 'lemma_names',\n",
       " 'lemmas',\n",
       " 'lexname',\n",
       " 'lin_similarity',\n",
       " 'lowest_common_hypernyms',\n",
       " 'max_depth',\n",
       " 'member_holonyms',\n",
       " 'member_meronyms',\n",
       " 'min_depth',\n",
       " 'mst',\n",
       " 'name',\n",
       " 'offset',\n",
       " 'part_holonyms',\n",
       " 'part_meronyms',\n",
       " 'path_similarity',\n",
       " 'pos',\n",
       " 'region_domains',\n",
       " 'res_similarity',\n",
       " 'root_hypernyms',\n",
       " 'shortest_path_distance',\n",
       " 'similar_tos',\n",
       " 'substance_holonyms',\n",
       " 'substance_meronyms',\n",
       " 'topic_domains',\n",
       " 'tree',\n",
       " 'usage_domains',\n",
       " 'verb_groups',\n",
       " 'wup_similarity']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tt.store.store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['body', 'organic_structure', 'physical_structure']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.store.store.lemma_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he felt as if his whole body were on fire']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.store.store.examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'go.n.01': WordnetElement('go.n.01'),\n",
       " 'adam.n.03': WordnetElement('adam.n.03'),\n",
       " 'crack.n.09': WordnetElement('crack.n.09'),\n",
       " 'go.n.04': WordnetElement('go.n.04'),\n",
       " 'travel.v.01': WordnetElement('travel.v.01'),\n",
       " 'go.v.02': WordnetElement('go.v.02'),\n",
       " 'go.v.03': WordnetElement('go.v.03'),\n",
       " 'become.v.01': WordnetElement('become.v.01'),\n",
       " 'go.v.05': WordnetElement('go.v.05'),\n",
       " 'run.v.05': WordnetElement('run.v.05'),\n",
       " 'run.v.03': WordnetElement('run.v.03'),\n",
       " 'proceed.v.04': WordnetElement('proceed.v.04'),\n",
       " 'go.v.09': WordnetElement('go.v.09'),\n",
       " 'go.v.10': WordnetElement('go.v.10'),\n",
       " 'sound.v.02': WordnetElement('sound.v.02'),\n",
       " 'function.v.01': WordnetElement('function.v.01'),\n",
       " 'run_low.v.01': WordnetElement('run_low.v.01'),\n",
       " 'move.v.13': WordnetElement('move.v.13'),\n",
       " 'survive.v.01': WordnetElement('survive.v.01'),\n",
       " 'go.v.16': WordnetElement('go.v.16'),\n",
       " 'die.v.01': WordnetElement('die.v.01'),\n",
       " 'belong.v.03': WordnetElement('belong.v.03'),\n",
       " 'go.v.19': WordnetElement('go.v.19'),\n",
       " 'start.v.09': WordnetElement('start.v.09'),\n",
       " 'move.v.15': WordnetElement('move.v.15'),\n",
       " 'go.v.22': WordnetElement('go.v.22'),\n",
       " 'go.v.23': WordnetElement('go.v.23'),\n",
       " 'blend.v.02': WordnetElement('blend.v.02'),\n",
       " 'go.v.25': WordnetElement('go.v.25'),\n",
       " 'fit.v.02': WordnetElement('fit.v.02'),\n",
       " 'rifle.v.02': WordnetElement('rifle.v.02'),\n",
       " 'go.v.28': WordnetElement('go.v.28'),\n",
       " 'plump.v.04': WordnetElement('plump.v.04'),\n",
       " 'fail.v.04': WordnetElement('fail.v.04'),\n",
       " 'go.a.01': WordnetElement('go.a.01')}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexis.lemma_methods_returning_lemmas\n",
    "lemma = lemmas['go']\n",
    "lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = lemma['a.n.06']\n",
    "dir(w)\n",
    "w.verb_groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('None')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexis.lemma_methods_returning_lemmas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lexis.KvSynset"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = lemmas['a']['a.n.06']\n",
    "type(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "wn.lemma('salt.n.03.saltiness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>synset</th>\n",
       "      <th>definition</th>\n",
       "      <th>example</th>\n",
       "      <th>pos</th>\n",
       "      <th>hypernyms</th>\n",
       "      <th>hyponyms</th>\n",
       "      <th>member_holonyms</th>\n",
       "      <th>substance_holonyms</th>\n",
       "      <th>part_holonyms</th>\n",
       "      <th>...</th>\n",
       "      <th>part_meronyms</th>\n",
       "      <th>attributes</th>\n",
       "      <th>also_sees</th>\n",
       "      <th>verb_groups</th>\n",
       "      <th>entailments</th>\n",
       "      <th>causes</th>\n",
       "      <th>similar_tos</th>\n",
       "      <th>domain_topic</th>\n",
       "      <th>domain_region</th>\n",
       "      <th>domain_usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>body</td>\n",
       "      <td>body.n.01</td>\n",
       "      <td>the entire structure of an organism (an animal...</td>\n",
       "      <td>he felt as if his whole body were on fire</td>\n",
       "      <td>n</td>\n",
       "      <td>[natural_object.n.01]</td>\n",
       "      <td>[human_body.n.01, life_form.n.01, live_body.n.01]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[arm.n.01, articulatory_system.n.01, body_subs...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[animal.n.01, homo.n.02]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>body</td>\n",
       "      <td>body.n.02</td>\n",
       "      <td>a group of persons associated by some common t...</td>\n",
       "      <td>the whole body filed out of the auditorium</td>\n",
       "      <td>n</td>\n",
       "      <td>[social_group.n.01]</td>\n",
       "      <td>[administration.n.02, christendom.n.01, church...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>body</td>\n",
       "      <td>body.n.03</td>\n",
       "      <td>a natural object consisting of a dead animal o...</td>\n",
       "      <td>they found the body in the lake</td>\n",
       "      <td>n</td>\n",
       "      <td>[natural_object.n.01]</td>\n",
       "      <td>[cadaver.n.01, carcase.n.01, carrion.n.01, mum...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>body</td>\n",
       "      <td>body.n.04</td>\n",
       "      <td>an individual 3-dimensional object that has ma...</td>\n",
       "      <td>heavenly body</td>\n",
       "      <td>n</td>\n",
       "      <td>[natural_object.n.01]</td>\n",
       "      <td>[chromosome.n.01, inclusion_body.n.01, mass.n....</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>body</td>\n",
       "      <td>torso.n.01</td>\n",
       "      <td>the body excluding the head and neck and limbs</td>\n",
       "      <td>they moved their arms and legs and bodies</td>\n",
       "      <td>n</td>\n",
       "      <td>[body_part.n.01]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[body.n.01]</td>\n",
       "      <td>...</td>\n",
       "      <td>[abdomen.n.01, back.n.01, belly.n.02, buttock....</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>hand</td>\n",
       "      <td>hand.n.12</td>\n",
       "      <td>a round of applause to signify approval</td>\n",
       "      <td>give the little lady a great big hand</td>\n",
       "      <td>n</td>\n",
       "      <td>[applause.n.01]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>hand</td>\n",
       "      <td>hand.n.13</td>\n",
       "      <td>terminal part of the forelimb in certain verte...</td>\n",
       "      <td>the kangaroo's forearms seem undeveloped but t...</td>\n",
       "      <td>n</td>\n",
       "      <td>[forepaw.n.01]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>hand</td>\n",
       "      <td>hand.n.14</td>\n",
       "      <td>physical assistance</td>\n",
       "      <td>give me a hand with the chores</td>\n",
       "      <td>n</td>\n",
       "      <td>[aid.n.02]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>hand</td>\n",
       "      <td>pass.v.05</td>\n",
       "      <td>place into the hands or custody of</td>\n",
       "      <td>hand me the spoon, please</td>\n",
       "      <td>v</td>\n",
       "      <td>[transfer.v.05]</td>\n",
       "      <td>[deal.v.12, entrust.v.01, entrust.v.02, give.v...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>hand</td>\n",
       "      <td>hand.v.02</td>\n",
       "      <td>guide or conduct or usher somewhere</td>\n",
       "      <td>hand the elderly lady into the taxi</td>\n",
       "      <td>v</td>\n",
       "      <td>[lead.v.01]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    word      synset                                         definition  \\\n",
       "0   body   body.n.01  the entire structure of an organism (an animal...   \n",
       "1   body   body.n.02  a group of persons associated by some common t...   \n",
       "2   body   body.n.03  a natural object consisting of a dead animal o...   \n",
       "3   body   body.n.04  an individual 3-dimensional object that has ma...   \n",
       "4   body  torso.n.01     the body excluding the head and neck and limbs   \n",
       "..   ...         ...                                                ...   \n",
       "65  hand   hand.n.12            a round of applause to signify approval   \n",
       "66  hand   hand.n.13  terminal part of the forelimb in certain verte...   \n",
       "67  hand   hand.n.14                                physical assistance   \n",
       "68  hand   pass.v.05                 place into the hands or custody of   \n",
       "69  hand   hand.v.02                guide or conduct or usher somewhere   \n",
       "\n",
       "                                              example pos  \\\n",
       "0           he felt as if his whole body were on fire   n   \n",
       "1          the whole body filed out of the auditorium   n   \n",
       "2                     they found the body in the lake   n   \n",
       "3                                       heavenly body   n   \n",
       "4           they moved their arms and legs and bodies   n   \n",
       "..                                                ...  ..   \n",
       "65              give the little lady a great big hand   n   \n",
       "66  the kangaroo's forearms seem undeveloped but t...   n   \n",
       "67                     give me a hand with the chores   n   \n",
       "68                          hand me the spoon, please   v   \n",
       "69                hand the elderly lady into the taxi   v   \n",
       "\n",
       "                hypernyms                                           hyponyms  \\\n",
       "0   [natural_object.n.01]  [human_body.n.01, life_form.n.01, live_body.n.01]   \n",
       "1     [social_group.n.01]  [administration.n.02, christendom.n.01, church...   \n",
       "2   [natural_object.n.01]  [cadaver.n.01, carcase.n.01, carrion.n.01, mum...   \n",
       "3   [natural_object.n.01]  [chromosome.n.01, inclusion_body.n.01, mass.n....   \n",
       "4        [body_part.n.01]                                                 []   \n",
       "..                    ...                                                ...   \n",
       "65        [applause.n.01]                                                 []   \n",
       "66         [forepaw.n.01]                                                 []   \n",
       "67             [aid.n.02]                                                 []   \n",
       "68        [transfer.v.05]  [deal.v.12, entrust.v.01, entrust.v.02, give.v...   \n",
       "69            [lead.v.01]                                                 []   \n",
       "\n",
       "   member_holonyms substance_holonyms part_holonyms  ...  \\\n",
       "0               []                 []            []  ...   \n",
       "1               []                 []            []  ...   \n",
       "2               []                 []            []  ...   \n",
       "3               []                 []            []  ...   \n",
       "4               []                 []   [body.n.01]  ...   \n",
       "..             ...                ...           ...  ...   \n",
       "65              []                 []            []  ...   \n",
       "66              []                 []            []  ...   \n",
       "67              []                 []            []  ...   \n",
       "68              []                 []            []  ...   \n",
       "69              []                 []            []  ...   \n",
       "\n",
       "                                        part_meronyms attributes also_sees  \\\n",
       "0   [arm.n.01, articulatory_system.n.01, body_subs...         []        []   \n",
       "1                                                  []         []        []   \n",
       "2                                                  []         []        []   \n",
       "3                                                  []         []        []   \n",
       "4   [abdomen.n.01, back.n.01, belly.n.02, buttock....         []        []   \n",
       "..                                                ...        ...       ...   \n",
       "65                                                 []         []        []   \n",
       "66                                                 []         []        []   \n",
       "67                                                 []         []        []   \n",
       "68                                                 []         []        []   \n",
       "69                                                 []         []        []   \n",
       "\n",
       "   verb_groups entailments causes similar_tos              domain_topic  \\\n",
       "0           []          []     []          []  [animal.n.01, homo.n.02]   \n",
       "1           []          []     []          []                        []   \n",
       "2           []          []     []          []                        []   \n",
       "3           []          []     []          []                        []   \n",
       "4           []          []     []          []                        []   \n",
       "..         ...         ...    ...         ...                       ...   \n",
       "65          []          []     []          []                        []   \n",
       "66          []          []     []          []                        []   \n",
       "67          []          []     []          []                        []   \n",
       "68          []          []     []          []                        []   \n",
       "69          []          []     []          []                        []   \n",
       "\n",
       "   domain_region domain_usage  \n",
       "0             []           []  \n",
       "1             []           []  \n",
       "2             []           []  \n",
       "3             []           []  \n",
       "4             []           []  \n",
       "..           ...          ...  \n",
       "65            []           []  \n",
       "66            []           []  \n",
       "67            []           []  \n",
       "68            []           []  \n",
       "69            []           []  \n",
       "\n",
       "[70 rows x 22 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_words = ['body', 'head', 'hand']\n",
    "\n",
    "t = pd.DataFrame(wordnet_details(test_words))\n",
    "print(f\"{t.shape}\")\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    word      synset                                         definition  \\\n",
      "0   body   body.n.01  the entire structure of an organism (an animal...   \n",
      "1   body   body.n.02  a group of persons associated by some common t...   \n",
      "2   body   body.n.03  a natural object consisting of a dead animal o...   \n",
      "3   body   body.n.04  an individual 3-dimensional object that has ma...   \n",
      "4   body  torso.n.01     the body excluding the head and neck and limbs   \n",
      "..   ...         ...                                                ...   \n",
      "65  hand   hand.n.12            a round of applause to signify approval   \n",
      "66  hand   hand.n.13  terminal part of the forelimb in certain verte...   \n",
      "67  hand   hand.n.14                                physical assistance   \n",
      "68  hand   pass.v.05                 place into the hands or custody of   \n",
      "69  hand   hand.v.02                guide or conduct or usher somewhere   \n",
      "\n",
      "                                             examples pos  \\\n",
      "0         [he felt as if his whole body were on fire]   n   \n",
      "1   [the whole body filed out of the auditorium, t...   n   \n",
      "2                   [they found the body in the lake]   n   \n",
      "3                                     [heavenly body]   n   \n",
      "4         [they moved their arms and legs and bodies]   n   \n",
      "..                                                ...  ..   \n",
      "65            [give the little lady a great big hand]   n   \n",
      "66  [the kangaroo's forearms seem undeveloped but ...   n   \n",
      "67                   [give me a hand with the chores]   n   \n",
      "68  [hand me the spoon, please, Turn the files ove...   v   \n",
      "69              [hand the elderly lady into the taxi]   v   \n",
      "\n",
      "                                      lemma_names              hypernyms  \\\n",
      "0   [body, organic_structure, physical_structure]  [natural_object.n.01]   \n",
      "1                                          [body]    [social_group.n.01]   \n",
      "2                               [body, dead_body]  [natural_object.n.01]   \n",
      "3                                          [body]  [natural_object.n.01]   \n",
      "4                            [torso, trunk, body]       [body_part.n.01]   \n",
      "..                                            ...                    ...   \n",
      "65                                         [hand]        [applause.n.01]   \n",
      "66                                         [hand]         [forepaw.n.01]   \n",
      "67                           [hand, helping_hand]             [aid.n.02]   \n",
      "68  [pass, hand, reach, pass_on, turn_over, give]        [transfer.v.05]   \n",
      "69                                         [hand]            [lead.v.01]   \n",
      "\n",
      "                                             hyponyms holonyms meronyms  \n",
      "0   [human_body.n.01, life_form.n.01, live_body.n.01]       []       []  \n",
      "1   [administration.n.02, christendom.n.01, church...       []       []  \n",
      "2   [cadaver.n.01, carcase.n.01, carrion.n.01, mum...       []       []  \n",
      "3   [chromosome.n.01, inclusion_body.n.01, mass.n....       []       []  \n",
      "4                                                  []       []       []  \n",
      "..                                                ...      ...      ...  \n",
      "65                                                 []       []       []  \n",
      "66                                                 []       []       []  \n",
      "67                                                 []       []       []  \n",
      "68  [deal.v.12, entrust.v.01, entrust.v.02, give.v...       []       []  \n",
      "69                                                 []       []       []  \n",
      "\n",
      "[70 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import lexis\n",
    "lemmas = lexis.Lemmas()\n",
    "\n",
    "def extract_synset_features(word):\n",
    "    if word in lemmas:\n",
    "        for synset_key, synset in lemmas[word].items():\n",
    "            row = {\n",
    "                \"word\": word,\n",
    "                \"synset\": synset_key,\n",
    "                \"definition\": synset.get('definition', ''),\n",
    "                \"examples\": synset.get('examples', []),\n",
    "                \"pos\": synset.get('pos', ''),\n",
    "                \"lemma_names\": synset.get('lemma_names', []),\n",
    "                \"hypernyms\": [h.name() for h in synset.get('hypernyms', [])],\n",
    "                \"hyponyms\": [h.name() for h in synset.get('hyponyms', [])],\n",
    "                \"holonyms\": [h.name() for h in synset.get('member_holonyms', [])],\n",
    "                \"meronyms\": [h.name() for h in synset.get('member_meronyms', [])],\n",
    "            }\n",
    "            yield row\n",
    "\n",
    "    return data\n",
    "\n",
    "# Combine data for all words\n",
    "\n",
    "rows = []\n",
    "for word in ['body', 'head', 'hand']:\n",
    "    rows.extend(extract_synset_features(word))\n",
    "\n",
    "# Create the dataframe\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Display the dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lemma('natural_object.n.01.natural_object')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'body'\n",
    "t = lemmas[word]\n",
    "t['body.n.01']['hypernyms'][0].lemmas()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147306"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: word, dtype: object)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.word[word_counts.word.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graze as gz\n",
    "b = gz.graze(word_frequency_data_url)\n",
    "from dol import zip_decompress\n",
    "b = zip_decompress(b)\n",
    "import io\n",
    "bi = io.BytesIO(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333331"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = pd.read_csv(bi, na_values=[])\n",
    "t.word.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = bi.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'nan,3398089\\n'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it[12819 + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting embeddings of our words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = '/Users/thorwhalen/Dropbox/_odata/figiri/english_words'\n",
    "\n",
    "from tabled import DfFiles\n",
    "\n",
    "df_files = DfFiles(rootdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52078"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'words_embeddings.parquet' not in df_files:\n",
    "    import oa\n",
    "\n",
    "    assert len(word_list) == len(set(word_list)), \"Words not unique\"\n",
    "    word_embeddings = oa.embeddings(word_list)\n",
    "    df = pd.DataFrame(index=word_list, data=map(lambda x: [x], word_embeddings))\n",
    "    df.columns = ['embedding']\n",
    "    df_files['words_embeddings.parquet'] = df\n",
    "else:\n",
    "    df = df_files['words_embeddings.parquet']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'umap_embeddings.parquet' not in df_files:\n",
    "    import imbed\n",
    "    umap_planar_embeddings = imbed.umap_2d_embeddings(df.embedding)\n",
    "    umap_embeddings = imbed.planar_embeddings_dict_to_df(umap_planar_embeddings, index_name='word')\n",
    "    df_files['umap_embeddings.parquet'] = umap_embeddings\n",
    "else:\n",
    "    umap_embeddings = df_files['umap_embeddings.parquet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>3.027916</td>\n",
       "      <td>3.760965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa</td>\n",
       "      <td>3.009660</td>\n",
       "      <td>3.677792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaa</td>\n",
       "      <td>2.991489</td>\n",
       "      <td>3.758253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aachen</td>\n",
       "      <td>1.601711</td>\n",
       "      <td>1.289808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aah</td>\n",
       "      <td>2.878280</td>\n",
       "      <td>3.509061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52073</th>\n",
       "      <td>zygomatic</td>\n",
       "      <td>-2.601842</td>\n",
       "      <td>2.954538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52074</th>\n",
       "      <td>zygote</td>\n",
       "      <td>-2.934901</td>\n",
       "      <td>1.785373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52075</th>\n",
       "      <td>zygotic</td>\n",
       "      <td>-3.039186</td>\n",
       "      <td>1.812226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52076</th>\n",
       "      <td>zyloprim</td>\n",
       "      <td>-3.420418</td>\n",
       "      <td>0.476265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52077</th>\n",
       "      <td>zymogen</td>\n",
       "      <td>-3.384059</td>\n",
       "      <td>1.371314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52078 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word         x         y\n",
       "0              a  3.027916  3.760965\n",
       "1             aa  3.009660  3.677792\n",
       "2            aaa  2.991489  3.758253\n",
       "3         aachen  1.601711  1.289808\n",
       "4            aah  2.878280  3.509061\n",
       "...          ...       ...       ...\n",
       "52073  zygomatic -2.601842  2.954538\n",
       "52074     zygote -2.934901  1.785373\n",
       "52075    zygotic -3.039186  1.812226\n",
       "52076   zyloprim -3.420418  0.476265\n",
       "52077    zymogen -3.384059  1.371314\n",
       "\n",
       "[52078 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umap_embeddings.reset_index(inplace=True)\n",
    "umap_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files['umap_embeddings.csv'] = umap_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = lemmas['body']['body.n.01']\n",
    "w.lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.lemmas()[0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 0]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = next(iter(lemmas['go'].values()))\n",
    "[x.count() for x in w.lemmas()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_frame_ids',\n",
       " '_frame_strings',\n",
       " '_hypernyms',\n",
       " '_instance_hypernyms',\n",
       " '_key',\n",
       " '_lang',\n",
       " '_lex_id',\n",
       " '_lexname_index',\n",
       " '_name',\n",
       " '_related',\n",
       " '_synset',\n",
       " '_syntactic_marker',\n",
       " '_wordnet_corpus_reader',\n",
       " 'also_sees',\n",
       " 'antonyms',\n",
       " 'attributes',\n",
       " 'causes',\n",
       " 'count',\n",
       " 'derivationally_related_forms',\n",
       " 'entailments',\n",
       " 'frame_ids',\n",
       " 'frame_strings',\n",
       " 'hypernyms',\n",
       " 'hyponyms',\n",
       " 'in_region_domains',\n",
       " 'in_topic_domains',\n",
       " 'in_usage_domains',\n",
       " 'instance_hypernyms',\n",
       " 'instance_hyponyms',\n",
       " 'key',\n",
       " 'lang',\n",
       " 'member_holonyms',\n",
       " 'member_meronyms',\n",
       " 'name',\n",
       " 'part_holonyms',\n",
       " 'part_meronyms',\n",
       " 'pertainyms',\n",
       " 'region_domains',\n",
       " 'similar_tos',\n",
       " 'substance_holonyms',\n",
       " 'substance_meronyms',\n",
       " 'synset',\n",
       " 'syntactic_marker',\n",
       " 'topic_domains',\n",
       " 'usage_domains',\n",
       " 'verb_groups']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(w.lemmas()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ww = w.lemmas()[0]\n",
    "ww.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ww.pertainyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
