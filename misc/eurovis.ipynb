{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eurovis data prep dacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EurovisDacc(name='eurovis', saves_dir='/Users/thorwhalen/Dropbox/_odata/app_data/imbed/saves/eurovis', verbose=1, model='text-embedding-3-small')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imbed_data_prep.eurovis import EurovisDacc\n",
    "from lkj import truncate_dict_values\n",
    "from itertools import islice\n",
    "\n",
    "dict_head = lambda d, n=5: dict(islice(d.items(), n))  # name rudeness initially unintended, but loved, so kept\n",
    "\n",
    "dacc = EurovisDacc()\n",
    "dacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dacc.embeddable.shape=(5597, 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "conference                                                      EuroVis\n",
       "year                                                               2024\n",
       "title                 A Prediction-Traversal Approach for Compressin...\n",
       "doi                                                   10.1111/cgf.15097\n",
       "abstract              We explore an error-bounded lossy compression ...\n",
       "authorNamesDeduped           Congrong Ren;Xin Liang 0001;Hanqi Guo 0001\n",
       "award                                                              None\n",
       "resources                                                             P\n",
       "link                     https://vispubs.com/?paper=10.1111%2Fcgf.15097\n",
       "segment               ##A Prediction-Traversal Approach for Compress...\n",
       "n_tokens                                                            318\n",
       "Name: 10.1111/cgf.15097, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{dacc.embeddable.shape=}\")\n",
    "dacc.embeddable.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(dacc.segments)=5597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'10.1111/cgf.15097': '##A Prediction-Traversal Approach for Compressing Scientific Data on Unstructured Meshes with Bounded Error\\n\\nWe explore an error-bounded lossy compression approach for reducing scientific data associated with 2D/3D unstructured meshes. While existing lossy compressors offer a high compression ratio with bounded error for regular grid data, methodologies tailored for unstructured mesh data are lacking; for example, one can compress nodal data as 1D arrays, neglecting the spatial coherency of the mesh nodes. Inspired by the SZ compressor, which predicts and quantizes values in a multidimensional array, we dynamically reorganize nodal data into sequences. Each sequence starts with a seed cell; based on a predefined traversal order, the next cell is added to the sequence if the current cell can predict and quantize the nodal data in the next cell with the given error bound. As a result, one can efficiently compress the quantized nodal data in each sequence until all mesh nodes are traversed. This paper also introduces a suite of novel error metrics, namely continuous mean squared error (CMSE) and continuous peak signal-to-noise ratio (CPSNR), to assess compression results for unstructured mesh data. The continuous error metrics are defined by integrating the error function on all cells, providing objective statistics across nonuniformly distributed nodes/cells in the mesh. We evaluate our methods with several scientific simulations ranging from ocean-climate models and computational fluid dynamics simulations with both traditional and continuous error metrics. We demonstrated superior compression ratios and quality than existing lossy compressors.',\n",
       " '10.1111/cgf.15111': '##A Systematic Literature Review of User Evaluation in Immersive Analytics\\n\\nUser evaluation is a common and useful tool for systematically generating knowledge and validating novel approaches in the domain of Immersive Analytics. Since this research domain centres around users, user evaluation is of extraordinary relevance. Additionally, Immersive Analytics is an interdisciplinary field of research where different communities bring in their own methodologies. It is vital to investigate and synchronise these different approaches with the long-term goal to reach a shared evaluation framework. While there have been several studies focusing on Immersive Analytics as a whole or on certain aspects of the domain, this is the first systematic review of the state of evaluation methodology in Immersive Analytics. The main objective of this systematic literature review is to illustrate methodologies and research areas that are still underrepresented in user studies by identifying current practice in user evaluation in the domain of Immersive Analytics in coherence with the PRISMA protocol. (see https://www.acm.org/publications/class-2012)',\n",
       " '10.1111/cgf.15077': '##An Experimental Evaluation of Viewpoint-Based 3D Graph Drawing\\n\\nNode-link diagrams are a widely used metaphor for creating visualizations of relational data. Most frequently, such techniques address creating 2D graph drawings, which are easy to use on computer screens and in print. In contrast, 3D node-link graph visualizations are far less used, as they have many known limitations and comparatively few well-understood advantages. A key issue here is that such 3D visualizations require users to select suitable viewpoints. We address this limitation by studying the ability of layout techniques to produce high-quality views of 3D graph drawings. For this, we perform a thorough experimental evaluation, comparing 3D graph drawings, rendered from a covering sampling of all viewpoints, with their 2D counterparts across various state-of-the-art node-link drawing algorithms, graph families, and quality metrics. Our results show that, depending on the graph family, 3D node-link diagrams can contain a many viewpoints that yield 2D visualizations that are of higher quality than those created by directly using 2D node-link diagrams. This not only sheds light on the potential of 3D node-link diagrams but also gives a simple approach to produce high-quality 2D node-link diagrams.',\n",
       " '10.1111/cgf.15088': \"##Antarstick: Extracting Snow Height From Time-Lapse Photography\\n\\nThe evolution and accumulation of snow cover are among the most important characteristics influencing Antarctica's climate and biotopes. The changes in Antarctica are also substantially impacting global climate change. Therefore, detailed monitoring of snow evolution is key to understanding such changes. One way to conduct this monitoring is by installing trail cameras in a particular region and then processing the captured information. This option is affordable, but has some drawbacks, such as the fully automatic solution for the extraction of snow height from these images is not feasible. Therefore, it still requires human intervention, manually correcting the inaccurately extracted information. In this paper, we present Antarstick, a tool for visual guidance of the user to potentially wrong values extracted from poor-quality images and support for their interactive correction. This tool allows for much quicker and semi-automated processing of snow height from time-lapse photography.\",\n",
       " '10.1111/cgf.15099': '##AutoVizuA11y: A Tool to Automate Screen Reader Accessibility in Charts\\n\\nCharts remain widely inaccessible on the web for users of assistive technologies like screen readers. This is, in part, due to data visualization experts still lacking the experience, knowledge, and time to consistently implement accessible charts. As a result, screen reader users are prevented from accessing information and are forced to resort to tabular alternatives (if available), limiting the insights that they can gather. We worked with both groups to develop AutoVizuA11y, a tool that automates the addition of accessible features to web-based charts. It generates human-like descriptions of the data using a large language model, calculates statistical insights from the data, and provides keyboard navigation between multiple charts and underlying elements. Fifteen screen reader users interacted with charts made accessible with AutoVizuA11y in a usability test, thirteen of which praised the tool for its intuitive design, short learning curve, and rich information. On average, they took 66 seconds to complete each of the eight analytical tasks presented and achieved a success rate of 89%. Through a SUS questionnaire, the participants gave AutoVizuA11y an \"Excellent\" score â€” 83.5/100 points. We also gathered feedback from two data visualization experts who used the tool. They praised the tool availability, ease of use and functionalities, and provided feedback to add AutoVizuA11y support for other technologies in the future.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a dict of the segments (with index of embedable as keys)\n",
    "print(f\"{len(dacc.segments)=}\")\n",
    "dict_head(dacc.segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dacc.clusters_df.shape=(5500, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_05</th>\n",
       "      <th>cluster_08</th>\n",
       "      <th>cluster_13</th>\n",
       "      <th>cluster_21</th>\n",
       "      <th>cluster_34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10.1111/cgf.15097</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1111/cgf.15111</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1111/cgf.15077</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1111/cgf.15088</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1111/cgf.15099</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   cluster_05  cluster_08  cluster_13  cluster_21  cluster_34\n",
       "10.1111/cgf.15097           3           4           2           2           3\n",
       "10.1111/cgf.15111           3           4           2           2           3\n",
       "10.1111/cgf.15077           3           4           2           2           3\n",
       "10.1111/cgf.15088           3           4           2           2           3\n",
       "10.1111/cgf.15099           3           4           2           2           3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{dacc.clusters_df.shape=}\")\n",
    "dacc.clusters_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cosmograph import cosmo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t.shape=(5500, 17)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "conference                                                      EuroVis\n",
       "year                                                               2024\n",
       "title                 A Prediction-Traversal Approach for Compressin...\n",
       "abstract              We explore an error-bounded lossy compression ...\n",
       "authorNamesDeduped           Congrong Ren;Xin Liang 0001;Hanqi Guo 0001\n",
       "award                                                              None\n",
       "resources                                                             P\n",
       "link                     https://vispubs.com/?paper=10.1111%2Fcgf.15097\n",
       "segment               ##A Prediction-Traversal Approach for Compress...\n",
       "n_tokens                                                            318\n",
       "x                                                            -29.573154\n",
       "y                                                             -3.688721\n",
       "cluster_05                                                            3\n",
       "cluster_08                                                            4\n",
       "cluster_13                                                            2\n",
       "cluster_21                                                            2\n",
       "cluster_34                                                            3\n",
       "Name: 10.1111/cgf.15097, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = dacc.merged_artifacts\n",
    "print(f\"{t.shape=}\")\n",
    "t.iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conference</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authorNamesDeduped</th>\n",
       "      <th>award</th>\n",
       "      <th>resources</th>\n",
       "      <th>link</th>\n",
       "      <th>segment</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>cluster_05</th>\n",
       "      <th>cluster_08</th>\n",
       "      <th>cluster_13</th>\n",
       "      <th>cluster_21</th>\n",
       "      <th>cluster_34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10.1111/cgf.15097</th>\n",
       "      <td>EuroVis</td>\n",
       "      <td>2024</td>\n",
       "      <td>A Prediction-Traversal Approach for Compressin...</td>\n",
       "      <td>We explore an error-bounded lossy compression ...</td>\n",
       "      <td>Congrong Ren;Xin Liang 0001;Hanqi Guo 0001</td>\n",
       "      <td>None</td>\n",
       "      <td>P</td>\n",
       "      <td>https://vispubs.com/?paper=10.1111%2Fcgf.15097</td>\n",
       "      <td>##A Prediction-Traversal Approach for Compress...</td>\n",
       "      <td>318</td>\n",
       "      <td>-29.573154</td>\n",
       "      <td>-3.688721</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1111/cgf.15111</th>\n",
       "      <td>EuroVis</td>\n",
       "      <td>2024</td>\n",
       "      <td>A Systematic Literature Review of User Evaluat...</td>\n",
       "      <td>User evaluation is a common and useful tool fo...</td>\n",
       "      <td>Judith Friedl-Knirsch;Fabian Pointecker;S. Pfi...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://vispubs.com/?paper=10.1111%2Fcgf.15111</td>\n",
       "      <td>##A Systematic Literature Review of User Evalu...</td>\n",
       "      <td>196</td>\n",
       "      <td>15.060126</td>\n",
       "      <td>3.490866</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1111/cgf.15077</th>\n",
       "      <td>EuroVis</td>\n",
       "      <td>2024</td>\n",
       "      <td>An Experimental Evaluation of Viewpoint-Based ...</td>\n",
       "      <td>Node-link diagrams are a widely used metaphor ...</td>\n",
       "      <td>Simon van Wageningen;Tamara Mchedlidze;Alexand...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://vispubs.com/?paper=10.1111%2Fcgf.15077</td>\n",
       "      <td>##An Experimental Evaluation of Viewpoint-Base...</td>\n",
       "      <td>256</td>\n",
       "      <td>-29.541185</td>\n",
       "      <td>-3.692561</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1111/cgf.15088</th>\n",
       "      <td>EuroVis</td>\n",
       "      <td>2024</td>\n",
       "      <td>Antarstick: Extracting Snow Height From Time-L...</td>\n",
       "      <td>The evolution and accumulation of snow cover a...</td>\n",
       "      <td>Matej Lang;Radoslav MrÃ¡z;Marek TrtÃ­k;Sergej St...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://vispubs.com/?paper=10.1111%2Fcgf.15088</td>\n",
       "      <td>##Antarstick: Extracting Snow Height From Time...</td>\n",
       "      <td>184</td>\n",
       "      <td>-29.395565</td>\n",
       "      <td>-3.648016</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1111/cgf.15099</th>\n",
       "      <td>EuroVis</td>\n",
       "      <td>2024</td>\n",
       "      <td>AutoVizuA11y: A Tool to Automate Screen Reader...</td>\n",
       "      <td>Charts remain widely inaccessible on the web f...</td>\n",
       "      <td>Diogo Duarte;Rita Costa;Pedro Bizarro;Carlos D...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://vispubs.com/?paper=10.1111%2Fcgf.15099</td>\n",
       "      <td>##AutoVizuA11y: A Tool to Automate Screen Read...</td>\n",
       "      <td>297</td>\n",
       "      <td>-29.468313</td>\n",
       "      <td>-3.666119</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1109/VISUAL.1991.175826</th>\n",
       "      <td>Vis</td>\n",
       "      <td>1991</td>\n",
       "      <td>How visualization applications drive tool sele...</td>\n",
       "      <td>This paper looks at the role visualization and...</td>\n",
       "      <td>D. Prawel;M. Brown;C. Harris;R. Kriz;M. Vigil</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://vispubs.com/?paper=10.1109%2FVISUAL.19...</td>\n",
       "      <td>##How visualization applications drive tool se...</td>\n",
       "      <td>67</td>\n",
       "      <td>0.933912</td>\n",
       "      <td>-5.174725</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1109/VISUAL.1991.175814</th>\n",
       "      <td>Vis</td>\n",
       "      <td>1991</td>\n",
       "      <td>Image handling in a multi-vendor environment</td>\n",
       "      <td>Software developed to deal with differing imag...</td>\n",
       "      <td>David R. Nadeau;T. Todd Elvins;Michael J. Bailey</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://vispubs.com/?paper=10.1109%2FVISUAL.19...</td>\n",
       "      <td>##Image handling in a multi-vendor environment...</td>\n",
       "      <td>140</td>\n",
       "      <td>0.901553</td>\n",
       "      <td>-5.090282</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1109/VISUAL.1991.175801</th>\n",
       "      <td>Vis</td>\n",
       "      <td>1991</td>\n",
       "      <td>In vivo blood flow visualization with magnetic...</td>\n",
       "      <td>Blood movement investigated by magnetic resona...</td>\n",
       "      <td>Guang-Zhong Yang;Peter Burger;Philip J. Kilner...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://vispubs.com/?paper=10.1109%2FVISUAL.19...</td>\n",
       "      <td>##In vivo blood flow visualization with magnet...</td>\n",
       "      <td>167</td>\n",
       "      <td>0.895913</td>\n",
       "      <td>-5.134688</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1109/VISUAL.1991.175812</th>\n",
       "      <td>Vis</td>\n",
       "      <td>1991</td>\n",
       "      <td>Integration of visualization and scientific ca...</td>\n",
       "      <td>The problems and advantages of integrating sci...</td>\n",
       "      <td>Ulrich Lang 0002;Ruth E. Lang;Roland RÃ¼hle</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://vispubs.com/?paper=10.1109%2FVISUAL.19...</td>\n",
       "      <td>##Integration of visualization and scientific ...</td>\n",
       "      <td>112</td>\n",
       "      <td>0.875707</td>\n",
       "      <td>-5.113888</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1109/VISUAL.1991.175809</th>\n",
       "      <td>Vis</td>\n",
       "      <td>1991</td>\n",
       "      <td>Interactive data exploration with a supercomputer</td>\n",
       "      <td>An experiment in exploratory data visualizatio...</td>\n",
       "      <td>Stuart Smith;Georges G. Grinstein;R. Daniel Be...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://vispubs.com/?paper=10.1109%2FVISUAL.19...</td>\n",
       "      <td>##Interactive data exploration with a supercom...</td>\n",
       "      <td>137</td>\n",
       "      <td>0.907948</td>\n",
       "      <td>-5.094199</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5500 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           conference  year  \\\n",
       "10.1111/cgf.15097             EuroVis  2024   \n",
       "10.1111/cgf.15111             EuroVis  2024   \n",
       "10.1111/cgf.15077             EuroVis  2024   \n",
       "10.1111/cgf.15088             EuroVis  2024   \n",
       "10.1111/cgf.15099             EuroVis  2024   \n",
       "...                               ...   ...   \n",
       "10.1109/VISUAL.1991.175826        Vis  1991   \n",
       "10.1109/VISUAL.1991.175814        Vis  1991   \n",
       "10.1109/VISUAL.1991.175801        Vis  1991   \n",
       "10.1109/VISUAL.1991.175812        Vis  1991   \n",
       "10.1109/VISUAL.1991.175809        Vis  1991   \n",
       "\n",
       "                                                                        title  \\\n",
       "10.1111/cgf.15097           A Prediction-Traversal Approach for Compressin...   \n",
       "10.1111/cgf.15111           A Systematic Literature Review of User Evaluat...   \n",
       "10.1111/cgf.15077           An Experimental Evaluation of Viewpoint-Based ...   \n",
       "10.1111/cgf.15088           Antarstick: Extracting Snow Height From Time-L...   \n",
       "10.1111/cgf.15099           AutoVizuA11y: A Tool to Automate Screen Reader...   \n",
       "...                                                                       ...   \n",
       "10.1109/VISUAL.1991.175826  How visualization applications drive tool sele...   \n",
       "10.1109/VISUAL.1991.175814       Image handling in a multi-vendor environment   \n",
       "10.1109/VISUAL.1991.175801  In vivo blood flow visualization with magnetic...   \n",
       "10.1109/VISUAL.1991.175812  Integration of visualization and scientific ca...   \n",
       "10.1109/VISUAL.1991.175809  Interactive data exploration with a supercomputer   \n",
       "\n",
       "                                                                     abstract  \\\n",
       "10.1111/cgf.15097           We explore an error-bounded lossy compression ...   \n",
       "10.1111/cgf.15111           User evaluation is a common and useful tool fo...   \n",
       "10.1111/cgf.15077           Node-link diagrams are a widely used metaphor ...   \n",
       "10.1111/cgf.15088           The evolution and accumulation of snow cover a...   \n",
       "10.1111/cgf.15099           Charts remain widely inaccessible on the web f...   \n",
       "...                                                                       ...   \n",
       "10.1109/VISUAL.1991.175826  This paper looks at the role visualization and...   \n",
       "10.1109/VISUAL.1991.175814  Software developed to deal with differing imag...   \n",
       "10.1109/VISUAL.1991.175801  Blood movement investigated by magnetic resona...   \n",
       "10.1109/VISUAL.1991.175812  The problems and advantages of integrating sci...   \n",
       "10.1109/VISUAL.1991.175809  An experiment in exploratory data visualizatio...   \n",
       "\n",
       "                                                           authorNamesDeduped  \\\n",
       "10.1111/cgf.15097                  Congrong Ren;Xin Liang 0001;Hanqi Guo 0001   \n",
       "10.1111/cgf.15111           Judith Friedl-Knirsch;Fabian Pointecker;S. Pfi...   \n",
       "10.1111/cgf.15077           Simon van Wageningen;Tamara Mchedlidze;Alexand...   \n",
       "10.1111/cgf.15088           Matej Lang;Radoslav MrÃ¡z;Marek TrtÃ­k;Sergej St...   \n",
       "10.1111/cgf.15099           Diogo Duarte;Rita Costa;Pedro Bizarro;Carlos D...   \n",
       "...                                                                       ...   \n",
       "10.1109/VISUAL.1991.175826      D. Prawel;M. Brown;C. Harris;R. Kriz;M. Vigil   \n",
       "10.1109/VISUAL.1991.175814   David R. Nadeau;T. Todd Elvins;Michael J. Bailey   \n",
       "10.1109/VISUAL.1991.175801  Guang-Zhong Yang;Peter Burger;Philip J. Kilner...   \n",
       "10.1109/VISUAL.1991.175812         Ulrich Lang 0002;Ruth E. Lang;Roland RÃ¼hle   \n",
       "10.1109/VISUAL.1991.175809  Stuart Smith;Georges G. Grinstein;R. Daniel Be...   \n",
       "\n",
       "                           award resources  \\\n",
       "10.1111/cgf.15097           None         P   \n",
       "10.1111/cgf.15111           None      None   \n",
       "10.1111/cgf.15077           None      None   \n",
       "10.1111/cgf.15088           None      None   \n",
       "10.1111/cgf.15099           None      None   \n",
       "...                          ...       ...   \n",
       "10.1109/VISUAL.1991.175826  None      None   \n",
       "10.1109/VISUAL.1991.175814  None      None   \n",
       "10.1109/VISUAL.1991.175801  None      None   \n",
       "10.1109/VISUAL.1991.175812  None      None   \n",
       "10.1109/VISUAL.1991.175809  None      None   \n",
       "\n",
       "                                                                         link  \\\n",
       "10.1111/cgf.15097              https://vispubs.com/?paper=10.1111%2Fcgf.15097   \n",
       "10.1111/cgf.15111              https://vispubs.com/?paper=10.1111%2Fcgf.15111   \n",
       "10.1111/cgf.15077              https://vispubs.com/?paper=10.1111%2Fcgf.15077   \n",
       "10.1111/cgf.15088              https://vispubs.com/?paper=10.1111%2Fcgf.15088   \n",
       "10.1111/cgf.15099              https://vispubs.com/?paper=10.1111%2Fcgf.15099   \n",
       "...                                                                       ...   \n",
       "10.1109/VISUAL.1991.175826  https://vispubs.com/?paper=10.1109%2FVISUAL.19...   \n",
       "10.1109/VISUAL.1991.175814  https://vispubs.com/?paper=10.1109%2FVISUAL.19...   \n",
       "10.1109/VISUAL.1991.175801  https://vispubs.com/?paper=10.1109%2FVISUAL.19...   \n",
       "10.1109/VISUAL.1991.175812  https://vispubs.com/?paper=10.1109%2FVISUAL.19...   \n",
       "10.1109/VISUAL.1991.175809  https://vispubs.com/?paper=10.1109%2FVISUAL.19...   \n",
       "\n",
       "                                                                      segment  \\\n",
       "10.1111/cgf.15097           ##A Prediction-Traversal Approach for Compress...   \n",
       "10.1111/cgf.15111           ##A Systematic Literature Review of User Evalu...   \n",
       "10.1111/cgf.15077           ##An Experimental Evaluation of Viewpoint-Base...   \n",
       "10.1111/cgf.15088           ##Antarstick: Extracting Snow Height From Time...   \n",
       "10.1111/cgf.15099           ##AutoVizuA11y: A Tool to Automate Screen Read...   \n",
       "...                                                                       ...   \n",
       "10.1109/VISUAL.1991.175826  ##How visualization applications drive tool se...   \n",
       "10.1109/VISUAL.1991.175814  ##Image handling in a multi-vendor environment...   \n",
       "10.1109/VISUAL.1991.175801  ##In vivo blood flow visualization with magnet...   \n",
       "10.1109/VISUAL.1991.175812  ##Integration of visualization and scientific ...   \n",
       "10.1109/VISUAL.1991.175809  ##Interactive data exploration with a supercom...   \n",
       "\n",
       "                            n_tokens          x         y  cluster_05  \\\n",
       "10.1111/cgf.15097                318 -29.573154 -3.688721           3   \n",
       "10.1111/cgf.15111                196  15.060126  3.490866           3   \n",
       "10.1111/cgf.15077                256 -29.541185 -3.692561           3   \n",
       "10.1111/cgf.15088                184 -29.395565 -3.648016           3   \n",
       "10.1111/cgf.15099                297 -29.468313 -3.666119           3   \n",
       "...                              ...        ...       ...         ...   \n",
       "10.1109/VISUAL.1991.175826        67   0.933912 -5.174725           4   \n",
       "10.1109/VISUAL.1991.175814       140   0.901553 -5.090282           4   \n",
       "10.1109/VISUAL.1991.175801       167   0.895913 -5.134688           4   \n",
       "10.1109/VISUAL.1991.175812       112   0.875707 -5.113888           4   \n",
       "10.1109/VISUAL.1991.175809       137   0.907948 -5.094199           4   \n",
       "\n",
       "                            cluster_08  cluster_13  cluster_21  cluster_34  \n",
       "10.1111/cgf.15097                    4           2           2           3  \n",
       "10.1111/cgf.15111                    4           2           2           3  \n",
       "10.1111/cgf.15077                    4           2           2           3  \n",
       "10.1111/cgf.15088                    4           2           2           3  \n",
       "10.1111/cgf.15099                    4           2           2           3  \n",
       "...                                ...         ...         ...         ...  \n",
       "10.1109/VISUAL.1991.175826           2           9          12          18  \n",
       "10.1109/VISUAL.1991.175814           2           9          12          18  \n",
       "10.1109/VISUAL.1991.175801           2           9          12          18  \n",
       "10.1109/VISUAL.1991.175812           2           9          12          18  \n",
       "10.1109/VISUAL.1991.175809           2           9          12          18  \n",
       "\n",
       "[5500 rows x 17 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dacc.merged_artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eurovis data prep WIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EurovisDacc(name='eurovis', saves_dir='/Users/thorwhalen/Dropbox/_odata/app_data/imbed/saves/eurovis', verbose=1, model='text-embedding-3-small')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imbed_data_prep.eurovis import EurovisDacc\n",
    "\n",
    "dacc = EurovisDacc()\n",
    "dacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dacc.saves_bytes_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape=(5699, 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "conference                                                      EuroVis\n",
       "year                                                               2024\n",
       "title                 A Prediction-Traversal Approach for Compressin...\n",
       "doi                                                   10.1111/cgf.15097\n",
       "abstract              We explore an error-bounded lossy compression ...\n",
       "authorNamesDeduped           Congrong Ren;Xin Liang 0001;Hanqi Guo 0001\n",
       "award                                                               NaN\n",
       "resources                                                             P\n",
       "link                     https://vispubs.com/?paper=10.1111%2Fcgf.15097\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dacc.raw_data\n",
    "print(f\"{df.shape=}\")\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnose and clean raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum(df['title'].isna())=0\n",
      "sum(df['abstract'].isna())=0\n"
     ]
    }
   ],
   "source": [
    "print(f\"{sum(df['title'].isna())=}\")\n",
    "print(f\"{sum(df['abstract'].isna())=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with missing title or abstract\n",
    "df = dacc.raw_data.dropna(subset=['title', 'abstract'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add some util columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contatenate title and abstract to make segment\n",
    "df['segment'] = '##' + df['title'] + '\\n\\n' + df.get('abstract')\n",
    "\n",
    "assert not any(df.segment.isna()), \"some segments are NaN\"\n",
    "\n",
    "import oa\n",
    "\n",
    "# apply oa.num_tokens to segment to get n_tokens\n",
    "df['n_tokens'] = df['segment'].apply(oa.num_tokens)\n",
    "max_tokens = oa.util.embeddings_models[oa.base.DFLT_EMBEDDINGS_MODEL]['max_input']\n",
    "assert df['n_tokens'].max() <= max_tokens, \"some segments exceed max tokens\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = dict(zip(df.doi, df.segment))\n",
    "assert len(segments) == len(df), \"oops, duplicate DOIs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(map(oa.text_is_valid, df.segment)), \"some segments are invalid\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_head = lambda d, n=5: dict(islice(d.items(), n))  # name rudeness initially unintended, but loved, so kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(dacc.segments)=5597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'10.1111/cgf.15097': '##A Prediction-Traversal Approach for Compressing Scientific Data on Unstructured Meshes with Bounded Error\\n\\nWe explore an error-bounded lossy compression approach for reducing scientific data associated with 2D/3D unstructured meshes. While existing lossy compressors offer a high compression ratio with bounded error for regular grid data, methodologies tailored for unstructured mesh data are lacking; for example, one can compress nodal data as 1D arrays, neglecting the spatial coherency of the mesh nodes. Inspired by the SZ compressor, which predicts and quantizes values in a multidimensional array, we dynamically reorganize nodal data into sequences. Each sequence starts with a seed cell; based on a predefined traversal order, the next cell is added to the sequence if the current cell can predict and quantize the nodal data in the next cell with the given error bound. As a result, one can efficiently compress the quantized nodal data in each sequence until all mesh nodes are traversed. This paper also introduces a suite of novel error metrics, namely continuous mean squared error (CMSE) and continuous peak signal-to-noise ratio (CPSNR), to assess compression results for unstructured mesh data. The continuous error metrics are defined by integrating the error function on all cells, providing objective statistics across nonuniformly distributed nodes/cells in the mesh. We evaluate our methods with several scientific simulations ranging from ocean-climate models and computational fluid dynamics simulations with both traditional and continuous error metrics. We demonstrated superior compression ratios and quality than existing lossy compressors.',\n",
       " '10.1111/cgf.15111': '##A Systematic Literature Review of User Evaluation in Immersive Analytics\\n\\nUser evaluation is a common and useful tool for systematically generating knowledge and validating novel approaches in the domain of Immersive Analytics. Since this research domain centres around users, user evaluation is of extraordinary relevance. Additionally, Immersive Analytics is an interdisciplinary field of research where different communities bring in their own methodologies. It is vital to investigate and synchronise these different approaches with the long-term goal to reach a shared evaluation framework. While there have been several studies focusing on Immersive Analytics as a whole or on certain aspects of the domain, this is the first systematic review of the state of evaluation methodology in Immersive Analytics. The main objective of this systematic literature review is to illustrate methodologies and research areas that are still underrepresented in user studies by identifying current practice in user evaluation in the domain of Immersive Analytics in coherence with the PRISMA protocol. (see https://www.acm.org/publications/class-2012)',\n",
       " '10.1111/cgf.15077': '##An Experimental Evaluation of Viewpoint-Based 3D Graph Drawing\\n\\nNode-link diagrams are a widely used metaphor for creating visualizations of relational data. Most frequently, such techniques address creating 2D graph drawings, which are easy to use on computer screens and in print. In contrast, 3D node-link graph visualizations are far less used, as they have many known limitations and comparatively few well-understood advantages. A key issue here is that such 3D visualizations require users to select suitable viewpoints. We address this limitation by studying the ability of layout techniques to produce high-quality views of 3D graph drawings. For this, we perform a thorough experimental evaluation, comparing 3D graph drawings, rendered from a covering sampling of all viewpoints, with their 2D counterparts across various state-of-the-art node-link drawing algorithms, graph families, and quality metrics. Our results show that, depending on the graph family, 3D node-link diagrams can contain a many viewpoints that yield 2D visualizations that are of higher quality than those created by directly using 2D node-link diagrams. This not only sheds light on the potential of 3D node-link diagrams but also gives a simple approach to produce high-quality 2D node-link diagrams.',\n",
       " '10.1111/cgf.15088': \"##Antarstick: Extracting Snow Height From Time-Lapse Photography\\n\\nThe evolution and accumulation of snow cover are among the most important characteristics influencing Antarctica's climate and biotopes. The changes in Antarctica are also substantially impacting global climate change. Therefore, detailed monitoring of snow evolution is key to understanding such changes. One way to conduct this monitoring is by installing trail cameras in a particular region and then processing the captured information. This option is affordable, but has some drawbacks, such as the fully automatic solution for the extraction of snow height from these images is not feasible. Therefore, it still requires human intervention, manually correcting the inaccurately extracted information. In this paper, we present Antarstick, a tool for visual guidance of the user to potentially wrong values extracted from poor-quality images and support for their interactive correction. This tool allows for much quicker and semi-automated processing of snow height from time-lapse photography.\",\n",
       " '10.1111/cgf.15099': '##AutoVizuA11y: A Tool to Automate Screen Reader Accessibility in Charts\\n\\nCharts remain widely inaccessible on the web for users of assistive technologies like screen readers. This is, in part, due to data visualization experts still lacking the experience, knowledge, and time to consistently implement accessible charts. As a result, screen reader users are prevented from accessing information and are forced to resort to tabular alternatives (if available), limiting the insights that they can gather. We worked with both groups to develop AutoVizuA11y, a tool that automates the addition of accessible features to web-based charts. It generates human-like descriptions of the data using a large language model, calculates statistical insights from the data, and provides keyboard navigation between multiple charts and underlying elements. Fifteen screen reader users interacted with charts made accessible with AutoVizuA11y in a usability test, thirteen of which praised the tool for its intuitive design, short learning curve, and rich information. On average, they took 66 seconds to complete each of the eight analytical tasks presented and achieved a success rate of 89%. Through a SUS questionnaire, the participants gave AutoVizuA11y an \"Excellent\" score â€” 83.5/100 points. We also gathered feedback from two data visualization experts who used the tool. They praised the tool availability, ease of use and functionalities, and provided feedback to add AutoVizuA11y support for other technologies in the future.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{len(dacc.segments)=}\")\n",
    "dict_head(dacc.segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are (at least) three ways to compute embeddings, which are more or less ideal \n",
    "depending on the situation.\n",
    "\n",
    "* One by one, locally and serially (that is, we wait for the response of the request \n",
    "    before sending another). This is **VERY** slow, and you don't want to do this with \n",
    "    a lot of data. But it has the advantage of being simple and straightforward, and, \n",
    "    if one of your segments has a problem, you'll know easily exactly which one does.\n",
    "* In batches, locally and serially.\n",
    "* In batches, remotely, in parallel, asynchronously. Advantages here are that it's \n",
    "    remote, so you're not hogging down the resources of your computer, and the remote \n",
    "    server will manage the persistence, status, etc. It's also cheaper (with OpenAI, \n",
    "    at the time of writing this, half the price). But it's more complex, and though \n",
    "    often faster to get your response every time I've ever tried, you are \"only\" \n",
    "    guaranteed getting your batch jobs within 24h of launching them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from oa import embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Mapping, Generator\n",
    "\n",
    "KeyVectorPairs = Generator[tuple[str, list[float]], None, None]\n",
    "\n",
    "def embed_segments_one_by_one(segments: Mapping[str, str]) -> KeyVectorPairs:\n",
    "    assert isinstance(segments, dict)\n",
    "    for i, (key, segment) in enumerate(segments.items()):\n",
    "        try:\n",
    "            vector = oa.embeddings(segment)\n",
    "            yield key, vector\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing ({i=}) {key}: {e}\")\n",
    "            # continue\n",
    "\n",
    "vectors = dict(embed_segments_one_by_one(segments))  # 55 minutes !!! (but for some reason it failed when giving all segments)\n",
    "# ... but batch processing API was much faster, and got through"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OpenAI's files and batch processing API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oa import OaStores\n",
    "from oa.batches import mk_batch_file_embeddings_task\n",
    "\n",
    "s = OaStores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imbed import fixed_step_chunker\n",
    "from lkj import print_progress, clog as _clog\n",
    "from functools import partial \n",
    "\n",
    "clog = partial(_clog, log_func=print_progress)\n",
    "\n",
    "\n",
    "def length_if_sizable(segments):\n",
    "    if hasattr(segments, '__len__'):\n",
    "        return len(segments)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "def create_embedding_task_batches(segments: dict, batch_size, *, oa_stores=None, verbose=True):\n",
    "    log = clog(verbose)\n",
    "    if oa_stores is None:\n",
    "        from oa import OaStores\n",
    "        oa_stores = OaStores()\n",
    "\n",
    "    total_length = length_if_sizable(segments)\n",
    "    if total_length is not None:\n",
    "        total_n_batches = int(total_length / batch_size) + 1\n",
    "    else:\n",
    "        total_n_batches = '<size unknown>'\n",
    "\n",
    "    try:\n",
    "        for i, batch in enumerate(fixed_step_chunker(segments.items(), batch_size)):\n",
    "            keys, texts = zip(*batch)\n",
    "            log(f\"Uploading batch {i+1} of {total_n_batches}\")\n",
    "            file_id = oa_stores.files.create_embedding_task(texts)\n",
    "            log(f\"  Launching batch for {file_id=}\")\n",
    "            batch_id = oa_stores.batches.append(file_id)\n",
    "            log(f\"  {batch_id.id=}, {batch_id.created_at=}\")\n",
    "            yield batch_id.id, keys\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21)22:26:42 - Uploading batch 1 of 12\n",
      "(21)22:26:44 -   Launching batch for file_id=FileObject(id='file-qm7lIuqr5x9kFADJSchYD3AI', bytes=700649, created_at=1726950403, filename='upload', object='file', purpose='batch', status='processed', status_details=None)\n",
      "(21)22:26:44 -   batch_id.id='batch_6jmdu3Kj3klFshjZniK9o9CY', batch_id.created_at=1726950404\n",
      "(21)22:26:44 - Uploading batch 2 of 12\n",
      "(21)22:26:45 -   Launching batch for file_id=FileObject(id='file-0TRiUQo5labi9YRSdZbgpkmJ', bytes=694448, created_at=1726950405, filename='upload', object='file', purpose='batch', status='processed', status_details=None)\n",
      "(21)22:26:46 -   batch_id.id='batch_81ahe68bJWV5umbIuwwk1kdz', batch_id.created_at=1726950406\n",
      "(21)22:26:46 - Uploading batch 3 of 12\n",
      "(21)22:26:47 -   Launching batch for file_id=FileObject(id='file-7e7aasKm45XTJLf2XccaDLVW', bytes=669356, created_at=1726950407, filename='upload', object='file', purpose='batch', status='processed', status_details=None)\n",
      "(21)22:26:47 -   batch_id.id='batch_IYDpQx2zjHGQxhi6vN7YiqeF', batch_id.created_at=1726950407\n",
      "(21)22:26:47 - Uploading batch 4 of 12\n",
      "(21)22:26:48 -   Launching batch for file_id=FileObject(id='file-UU61ZdbWLJJXx2vCrFqm2Te8', bytes=641283, created_at=1726950408, filename='upload', object='file', purpose='batch', status='processed', status_details=None)\n",
      "(21)22:26:49 -   batch_id.id='batch_ze18LAjFmrYvTmV9sZLpbKEc', batch_id.created_at=1726950409\n",
      "(21)22:26:49 - Uploading batch 5 of 12\n",
      "(21)22:26:50 -   Launching batch for file_id=FileObject(id='file-WQ30dCxa38j0ugBQnDQZVH6G', bytes=646437, created_at=1726950409, filename='upload', object='file', purpose='batch', status='processed', status_details=None)\n",
      "(21)22:26:50 -   batch_id.id='batch_eb84YEGrf1Hvc0T4BO564C3f', batch_id.created_at=1726950410\n",
      "(21)22:26:50 - Uploading batch 6 of 12\n",
      "(21)22:26:51 -   Launching batch for file_id=FileObject(id='file-Bpe1F2NrmziVcHTUVB86yOBy', bytes=617093, created_at=1726950411, filename='upload', object='file', purpose='batch', status='processed', status_details=None)\n",
      "(21)22:26:52 -   batch_id.id='batch_AB7wbu8cmEgWEUYEQeyPxHy9', batch_id.created_at=1726950412\n",
      "(21)22:26:52 - Uploading batch 7 of 12\n",
      "(21)22:26:53 -   Launching batch for file_id=FileObject(id='file-sM9D3a0KCAQWF0j4pD6JQc3f', bytes=591965, created_at=1726950412, filename='upload', object='file', purpose='batch', status='processed', status_details=None)\n",
      "(21)22:26:53 -   batch_id.id='batch_OhUecJdwCUbSdnb0APbmKMkq', batch_id.created_at=1726950413\n",
      "(21)22:26:53 - Uploading batch 8 of 12\n",
      "(21)22:26:54 -   Launching batch for file_id=FileObject(id='file-uvo3bO4kLQKPOVclEo7e8ykT', bytes=562517, created_at=1726950414, filename='upload', object='file', purpose='batch', status='processed', status_details=None)\n",
      "(21)22:26:54 -   batch_id.id='batch_S52TApAAVVkUfAeeEgG0PpFT', batch_id.created_at=1726950414\n",
      "(21)22:26:54 - Uploading batch 9 of 12\n",
      "(21)22:26:55 -   Launching batch for file_id=FileObject(id='file-E5jfhu2sqSYsNawFb2YygJdc', bytes=518873, created_at=1726950415, filename='upload', object='file', purpose='batch', status='processed', status_details=None)\n",
      "(21)22:26:56 -   batch_id.id='batch_h2SSnhCyCy7ncXNQLZgEo1Qv', batch_id.created_at=1726950416\n",
      "(21)22:26:56 - Uploading batch 10 of 12\n",
      "(21)22:26:57 -   Launching batch for file_id=FileObject(id='file-gjBpZ7Bp9jYnShjIUYowqTFX', bytes=478760, created_at=1726950416, filename='upload', object='file', purpose='batch', status='processed', status_details=None)\n",
      "(21)22:26:57 -   batch_id.id='batch_9Hkif2Np8S6AucV3Yzojcakb', batch_id.created_at=1726950417\n",
      "(21)22:26:57 - Uploading batch 11 of 12\n",
      "(21)22:26:59 -   Launching batch for file_id=FileObject(id='file-8ZHJ3exkeywvo5Lg4XXKSvKt', bytes=437395, created_at=1726950419, filename='upload', object='file', purpose='batch', status='processed', status_details=None)\n",
      "(21)22:27:00 -   batch_id.id='batch_Wf21mgaUVuKOQuFpd8L8f7Fo', batch_id.created_at=1726950419\n",
      "(21)22:27:00 - Uploading batch 12 of 12\n",
      "(21)22:27:00 -   Launching batch for file_id=FileObject(id='file-EhIo3iSkoaPSrhXSlm7aP2cr', bytes=76783, created_at=1726950420, filename='upload', object='file', purpose='batch', status='processed', status_details=None)\n",
      "(21)22:27:00 -   batch_id.id='batch_DsIFKEb8N1F3bqQVjEilK0Zz', batch_id.created_at=1726950420\n"
     ]
    }
   ],
   "source": [
    "it = create_embedding_task_batches(dacc.segments, batch_size=500)  # Adjust batch size as needed\n",
    "batch_keys = dict(it)\n",
    "dacc.saves['oa_embeddings_batch_keys.pkl'] = batch_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the results from the batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<oa.stores.OaStores at 0x10768d900>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from oa import OaStores\n",
    "\n",
    "s = OaStores()\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_infos_df.shape=(12, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>completion_window</th>\n",
       "      <th>created_at</th>\n",
       "      <th>endpoint</th>\n",
       "      <th>input_file_id</th>\n",
       "      <th>object</th>\n",
       "      <th>status</th>\n",
       "      <th>cancelled_at</th>\n",
       "      <th>cancelling_at</th>\n",
       "      <th>completed_at</th>\n",
       "      <th>error_file_id</th>\n",
       "      <th>errors</th>\n",
       "      <th>expired_at</th>\n",
       "      <th>expires_at</th>\n",
       "      <th>failed_at</th>\n",
       "      <th>finalizing_at</th>\n",
       "      <th>in_progress_at</th>\n",
       "      <th>metadata</th>\n",
       "      <th>output_file_id</th>\n",
       "      <th>request_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>batch_6jmdu3Kj3klFshjZniK9o9CY</td>\n",
       "      <td>24h</td>\n",
       "      <td>1726950404</td>\n",
       "      <td>/v1/embeddings</td>\n",
       "      <td>file-qm7lIuqr5x9kFADJSchYD3AI</td>\n",
       "      <td>batch</td>\n",
       "      <td>completed</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1726950410</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1727036804</td>\n",
       "      <td>None</td>\n",
       "      <td>1726950409</td>\n",
       "      <td>1726950405</td>\n",
       "      <td>None</td>\n",
       "      <td>file-OhyLmwGZ07j0xzwXuKQRuEuz</td>\n",
       "      <td>{'completed': 1, 'failed': 0, 'total': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>batch_81ahe68bJWV5umbIuwwk1kdz</td>\n",
       "      <td>24h</td>\n",
       "      <td>1726950406</td>\n",
       "      <td>/v1/embeddings</td>\n",
       "      <td>file-0TRiUQo5labi9YRSdZbgpkmJ</td>\n",
       "      <td>batch</td>\n",
       "      <td>completed</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1726950412</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1727036806</td>\n",
       "      <td>None</td>\n",
       "      <td>1726950411</td>\n",
       "      <td>1726950406</td>\n",
       "      <td>None</td>\n",
       "      <td>file-z5ZeVOJ7gw7xXxMsRf1ncajH</td>\n",
       "      <td>{'completed': 1, 'failed': 0, 'total': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>batch_IYDpQx2zjHGQxhi6vN7YiqeF</td>\n",
       "      <td>24h</td>\n",
       "      <td>1726950407</td>\n",
       "      <td>/v1/embeddings</td>\n",
       "      <td>file-7e7aasKm45XTJLf2XccaDLVW</td>\n",
       "      <td>batch</td>\n",
       "      <td>completed</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1726950418</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1727036807</td>\n",
       "      <td>None</td>\n",
       "      <td>1726950417</td>\n",
       "      <td>1726950408</td>\n",
       "      <td>None</td>\n",
       "      <td>file-pV05M3eq07FCIp9LGbufKH8y</td>\n",
       "      <td>{'completed': 1, 'failed': 0, 'total': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>batch_ze18LAjFmrYvTmV9sZLpbKEc</td>\n",
       "      <td>24h</td>\n",
       "      <td>1726950409</td>\n",
       "      <td>/v1/embeddings</td>\n",
       "      <td>file-UU61ZdbWLJJXx2vCrFqm2Te8</td>\n",
       "      <td>batch</td>\n",
       "      <td>completed</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1726950418</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1727036809</td>\n",
       "      <td>None</td>\n",
       "      <td>1726950417</td>\n",
       "      <td>1726950409</td>\n",
       "      <td>None</td>\n",
       "      <td>file-YWVaMSW31adKfcawvzDasfxf</td>\n",
       "      <td>{'completed': 1, 'failed': 0, 'total': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>batch_eb84YEGrf1Hvc0T4BO564C3f</td>\n",
       "      <td>24h</td>\n",
       "      <td>1726950410</td>\n",
       "      <td>/v1/embeddings</td>\n",
       "      <td>file-WQ30dCxa38j0ugBQnDQZVH6G</td>\n",
       "      <td>batch</td>\n",
       "      <td>completed</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1726950415</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1727036810</td>\n",
       "      <td>None</td>\n",
       "      <td>1726950414</td>\n",
       "      <td>1726950411</td>\n",
       "      <td>None</td>\n",
       "      <td>file-MYokO1csXDHsaSGp2bDOhcpg</td>\n",
       "      <td>{'completed': 1, 'failed': 0, 'total': 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               id completion_window  created_at  \\\n",
       "0  batch_6jmdu3Kj3klFshjZniK9o9CY               24h  1726950404   \n",
       "1  batch_81ahe68bJWV5umbIuwwk1kdz               24h  1726950406   \n",
       "2  batch_IYDpQx2zjHGQxhi6vN7YiqeF               24h  1726950407   \n",
       "3  batch_ze18LAjFmrYvTmV9sZLpbKEc               24h  1726950409   \n",
       "4  batch_eb84YEGrf1Hvc0T4BO564C3f               24h  1726950410   \n",
       "\n",
       "         endpoint                  input_file_id object     status  \\\n",
       "0  /v1/embeddings  file-qm7lIuqr5x9kFADJSchYD3AI  batch  completed   \n",
       "1  /v1/embeddings  file-0TRiUQo5labi9YRSdZbgpkmJ  batch  completed   \n",
       "2  /v1/embeddings  file-7e7aasKm45XTJLf2XccaDLVW  batch  completed   \n",
       "3  /v1/embeddings  file-UU61ZdbWLJJXx2vCrFqm2Te8  batch  completed   \n",
       "4  /v1/embeddings  file-WQ30dCxa38j0ugBQnDQZVH6G  batch  completed   \n",
       "\n",
       "  cancelled_at cancelling_at  completed_at error_file_id errors expired_at  \\\n",
       "0         None          None    1726950410          None   None       None   \n",
       "1         None          None    1726950412          None   None       None   \n",
       "2         None          None    1726950418          None   None       None   \n",
       "3         None          None    1726950418          None   None       None   \n",
       "4         None          None    1726950415          None   None       None   \n",
       "\n",
       "   expires_at failed_at  finalizing_at  in_progress_at metadata  \\\n",
       "0  1727036804      None     1726950409      1726950405     None   \n",
       "1  1727036806      None     1726950411      1726950406     None   \n",
       "2  1727036807      None     1726950417      1726950408     None   \n",
       "3  1727036809      None     1726950417      1726950409     None   \n",
       "4  1727036810      None     1726950414      1726950411     None   \n",
       "\n",
       "                  output_file_id                             request_counts  \n",
       "0  file-OhyLmwGZ07j0xzwXuKQRuEuz  {'completed': 1, 'failed': 0, 'total': 1}  \n",
       "1  file-z5ZeVOJ7gw7xXxMsRf1ncajH  {'completed': 1, 'failed': 0, 'total': 1}  \n",
       "2  file-pV05M3eq07FCIp9LGbufKH8y  {'completed': 1, 'failed': 0, 'total': 1}  \n",
       "3  file-YWVaMSW31adKfcawvzDasfxf  {'completed': 1, 'failed': 0, 'total': 1}  \n",
       "4  file-MYokO1csXDHsaSGp2bDOhcpg  {'completed': 1, 'failed': 0, 'total': 1}  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_keys = dacc.saves['oa_embeddings_batch_keys.pkl']\n",
    "batch_infos = list(map(s.batches_base.get, batch_keys))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "batch_infos_df = pd.DataFrame([x.to_dict() for x in batch_infos])\n",
    "print(f\"{batch_infos_df.shape=}\")\n",
    "batch_infos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "completed    12\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_infos_df.status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "completed    12\n",
       "failed        0\n",
       "total        12\n",
       "dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(batch_infos_df.request_counts.to_list()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21)22:32:41 - i=0, batch_info=Batch(id='batch_6jmdu3Kj3klFshjZniK9o9CY', completion_window='24h', created_at=1726950404, endpoint='/v1/embeddings', input_file_id='file-qm7lIuqr5x9kFADJSchYD3AI', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1726950410, error_file_id=None, errors=None, expired_at=None, expires_at=1727036804, failed_at=None, finalizing_at=1726950409, in_progress_at=1726950405, metadata=None, output_file_id='file-OhyLmwGZ07j0xzwXuKQRuEuz', request_counts=BatchRequestCounts(completed=1, failed=0, total=1))\n",
      "(21)22:32:44 - i=1, batch_info=Batch(id='batch_81ahe68bJWV5umbIuwwk1kdz', completion_window='24h', created_at=1726950406, endpoint='/v1/embeddings', input_file_id='file-0TRiUQo5labi9YRSdZbgpkmJ', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1726950412, error_file_id=None, errors=None, expired_at=None, expires_at=1727036806, failed_at=None, finalizing_at=1726950411, in_progress_at=1726950406, metadata=None, output_file_id='file-z5ZeVOJ7gw7xXxMsRf1ncajH', request_counts=BatchRequestCounts(completed=1, failed=0, total=1))\n",
      "(21)22:32:46 - i=2, batch_info=Batch(id='batch_IYDpQx2zjHGQxhi6vN7YiqeF', completion_window='24h', created_at=1726950407, endpoint='/v1/embeddings', input_file_id='file-7e7aasKm45XTJLf2XccaDLVW', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1726950418, error_file_id=None, errors=None, expired_at=None, expires_at=1727036807, failed_at=None, finalizing_at=1726950417, in_progress_at=1726950408, metadata=None, output_file_id='file-pV05M3eq07FCIp9LGbufKH8y', request_counts=BatchRequestCounts(completed=1, failed=0, total=1))\n",
      "(21)22:32:48 - i=3, batch_info=Batch(id='batch_ze18LAjFmrYvTmV9sZLpbKEc', completion_window='24h', created_at=1726950409, endpoint='/v1/embeddings', input_file_id='file-UU61ZdbWLJJXx2vCrFqm2Te8', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1726950418, error_file_id=None, errors=None, expired_at=None, expires_at=1727036809, failed_at=None, finalizing_at=1726950417, in_progress_at=1726950409, metadata=None, output_file_id='file-YWVaMSW31adKfcawvzDasfxf', request_counts=BatchRequestCounts(completed=1, failed=0, total=1))\n",
      "(21)22:32:50 - i=4, batch_info=Batch(id='batch_eb84YEGrf1Hvc0T4BO564C3f', completion_window='24h', created_at=1726950410, endpoint='/v1/embeddings', input_file_id='file-WQ30dCxa38j0ugBQnDQZVH6G', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1726950415, error_file_id=None, errors=None, expired_at=None, expires_at=1727036810, failed_at=None, finalizing_at=1726950414, in_progress_at=1726950411, metadata=None, output_file_id='file-MYokO1csXDHsaSGp2bDOhcpg', request_counts=BatchRequestCounts(completed=1, failed=0, total=1))\n",
      "(21)22:32:53 - i=5, batch_info=Batch(id='batch_AB7wbu8cmEgWEUYEQeyPxHy9', completion_window='24h', created_at=1726950412, endpoint='/v1/embeddings', input_file_id='file-Bpe1F2NrmziVcHTUVB86yOBy', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1726950418, error_file_id=None, errors=None, expired_at=None, expires_at=1727036812, failed_at=None, finalizing_at=1726950416, in_progress_at=1726950412, metadata=None, output_file_id='file-oZ8EzhmNrogma1MdpgzYlhWF', request_counts=BatchRequestCounts(completed=1, failed=0, total=1))\n",
      "(21)22:32:54 - i=6, batch_info=Batch(id='batch_OhUecJdwCUbSdnb0APbmKMkq', completion_window='24h', created_at=1726950413, endpoint='/v1/embeddings', input_file_id='file-sM9D3a0KCAQWF0j4pD6JQc3f', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1726950419, error_file_id=None, errors=None, expired_at=None, expires_at=1727036813, failed_at=None, finalizing_at=1726950418, in_progress_at=1726950413, metadata=None, output_file_id='file-APCtLjLopyNi7BMDug2gqP9o', request_counts=BatchRequestCounts(completed=1, failed=0, total=1))\n",
      "(21)22:32:56 - i=7, batch_info=Batch(id='batch_S52TApAAVVkUfAeeEgG0PpFT', completion_window='24h', created_at=1726950414, endpoint='/v1/embeddings', input_file_id='file-uvo3bO4kLQKPOVclEo7e8ykT', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1726950419, error_file_id=None, errors=None, expired_at=None, expires_at=1727036814, failed_at=None, finalizing_at=1726950418, in_progress_at=1726950415, metadata=None, output_file_id='file-OPAvfHscGmdlhRX13R5WBtIt', request_counts=BatchRequestCounts(completed=1, failed=0, total=1))\n",
      "(21)22:32:58 - i=8, batch_info=Batch(id='batch_h2SSnhCyCy7ncXNQLZgEo1Qv', completion_window='24h', created_at=1726950416, endpoint='/v1/embeddings', input_file_id='file-E5jfhu2sqSYsNawFb2YygJdc', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1726950420, error_file_id=None, errors=None, expired_at=None, expires_at=1727036816, failed_at=None, finalizing_at=1726950420, in_progress_at=1726950416, metadata=None, output_file_id='file-7dWCkCLgJiVx9WFC5wd532zZ', request_counts=BatchRequestCounts(completed=1, failed=0, total=1))\n",
      "(21)22:33:00 - i=9, batch_info=Batch(id='batch_9Hkif2Np8S6AucV3Yzojcakb', completion_window='24h', created_at=1726950417, endpoint='/v1/embeddings', input_file_id='file-gjBpZ7Bp9jYnShjIUYowqTFX', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1726950483, error_file_id=None, errors=None, expired_at=None, expires_at=1727036817, failed_at=None, finalizing_at=1726950482, in_progress_at=1726950418, metadata=None, output_file_id='file-kY5eAkEBNt9xN4jw5nRGuIcJ', request_counts=BatchRequestCounts(completed=1, failed=0, total=1))\n",
      "(21)22:33:03 - i=10, batch_info=Batch(id='batch_Wf21mgaUVuKOQuFpd8L8f7Fo', completion_window='24h', created_at=1726950419, endpoint='/v1/embeddings', input_file_id='file-8ZHJ3exkeywvo5Lg4XXKSvKt', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1726950424, error_file_id=None, errors=None, expired_at=None, expires_at=1727036819, failed_at=None, finalizing_at=1726950423, in_progress_at=1726950420, metadata=None, output_file_id='file-fEmDkJtfj674aNo3WWes5iXB', request_counts=BatchRequestCounts(completed=1, failed=0, total=1))\n",
      "(21)22:33:04 - i=11, batch_info=Batch(id='batch_DsIFKEb8N1F3bqQVjEilK0Zz', completion_window='24h', created_at=1726950420, endpoint='/v1/embeddings', input_file_id='file-EhIo3iSkoaPSrhXSlm7aP2cr', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1726950423, error_file_id=None, errors=None, expired_at=None, expires_at=1727036820, failed_at=None, finalizing_at=1726950423, in_progress_at=1726950421, metadata=None, output_file_id='file-gpCFPT0mjMwS72w5MKtp8xOu', request_counts=BatchRequestCounts(completed=1, failed=0, total=1))\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write the version of this that doesn't take segments, but the keys of batch_keys\n",
    "from lkj import print_with_timestamp\n",
    "import pandas as pd \n",
    "from oa.batches import batch_info_to_segments_and_embeddings\n",
    "\n",
    "for i, batch_info in enumerate(batch_infos):\n",
    "    if batch_info.output_file_id is not None:\n",
    "        print_with_timestamp(f\"{i=}, {batch_info=}\")\n",
    "        if batch_info.endpoint == '/v1/embeddings' and batch_info.status == 'completed':\n",
    "            _segment, _embedding = batch_info_to_segments_and_embeddings(s.jsonl_files, batch_info)\n",
    "            df = pd.DataFrame(dict(zip(['segment', 'embedding'], [_segment, _embedding])))\n",
    "            dacc.saves[f'embeddings/embeddings_{i:03d}.parquet'] = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/thorwhalen/Dropbox/_odata/app_data/imbed/saves/eurovis'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dacc.saves_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5597, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Make a tool for saving chunks to a folder, then aggregating, then saving the aggregated file and deleting the chunks.\n",
    "# Concatenate all the parquet files into one dataframe.\n",
    "\n",
    "import os\n",
    "from tabled import DfFiles, ColumnOrientedMapping\n",
    "from dol import filt_iter, cached_keys, Pipe\n",
    "from functools import partial\n",
    "import re\n",
    "\n",
    "mk_df_files_aggregate = Pipe(\n",
    "    DfFiles,\n",
    "    filt_iter.suffixes('.parquet'),\n",
    "    cached_keys(keys_cache=partial(sorted, key=lambda k: int(re.compile(r'(\\d+)').search(k).group(1)))), \n",
    ")\n",
    "\n",
    "df_files = mk_df_files_aggregate(os.path.join(dacc.saves_dir, 'embeddings'))\n",
    "_embeddings_df = ColumnOrientedMapping(df_files).df()  # 22s\n",
    "print(_embeddings_df.shape)\n",
    "_embeddings_df.head()\n",
    "len(df_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10.1111/cgf.15097</th>\n",
       "      <td>[0.045571942, 0.039998397, 0.02147455, 0.03886...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1111/cgf.15111</th>\n",
       "      <td>[-0.029467016, 0.052141637, -0.010563176, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1111/cgf.15077</th>\n",
       "      <td>[-0.020076588, 0.01872325, 0.034814317, -0.028...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1111/cgf.15088</th>\n",
       "      <td>[0.010777265, 0.0052750786, 0.018732894, -0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1111/cgf.15099</th>\n",
       "      <td>[-0.030659508, 0.05751415, 0.009932633, 0.0193...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1145/97243.97318</th>\n",
       "      <td>[0.0026892165, 0.043056898, 0.009226478, -0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1145/67449.67513</th>\n",
       "      <td>[-0.007736603, 0.072621584, 0.038157962, 0.008...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1145/57167.57168</th>\n",
       "      <td>[-0.010273671, 0.021275217, 0.017378045, 0.026...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1145/22627.22348</th>\n",
       "      <td>[-0.009675234, 0.03988838, 0.03618065, -0.0103...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1145/22627.22349</th>\n",
       "      <td>[-0.058277257, 0.023804866, -0.000547663, 0.01...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5599 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             embedding\n",
       "id_                                                                   \n",
       "10.1111/cgf.15097    [0.045571942, 0.039998397, 0.02147455, 0.03886...\n",
       "10.1111/cgf.15111    [-0.029467016, 0.052141637, -0.010563176, 0.02...\n",
       "10.1111/cgf.15077    [-0.020076588, 0.01872325, 0.034814317, -0.028...\n",
       "10.1111/cgf.15088    [0.010777265, 0.0052750786, 0.018732894, -0.03...\n",
       "10.1111/cgf.15099    [-0.030659508, 0.05751415, 0.009932633, 0.0193...\n",
       "...                                                                ...\n",
       "10.1145/97243.97318  [0.0026892165, 0.043056898, 0.009226478, -0.03...\n",
       "10.1145/67449.67513  [-0.007736603, 0.072621584, 0.038157962, 0.008...\n",
       "10.1145/57167.57168  [-0.010273671, 0.021275217, 0.017378045, 0.026...\n",
       "10.1145/22627.22348  [-0.009675234, 0.03988838, 0.03618065, -0.0103...\n",
       "10.1145/22627.22349  [-0.058277257, 0.023804866, -0.000547663, 0.01...\n",
       "\n",
       "[5599 rows x 1 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join the dacc.embeddable['segment'] and embeddings_df, over the segment column, to get the embeddings for each segment, and know the id_\n",
    "\n",
    "embeddings_df = (\n",
    "    dacc.embeddable[['segment']]\n",
    "    .join(_embeddings_df.set_index('segment'), on='segment')\n",
    "    .drop(columns='segment')\n",
    ")\n",
    "embeddings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "dacc.saves['embeddings_df.parquet']  = embeddings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(kd_embeddings)=5599\n",
      "len(kd_embeddings)=5597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5597"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imbed.util import *\n",
    "\n",
    "kd_embeddings = dacc.embeddings_df.embedding\n",
    "print(f\"{len(kd_embeddings)=}\")\n",
    "# get a function to compute the embeddings\n",
    "embeddings_func = planar_embeddings_func('ncvis')\n",
    "# make sure the input embeddings have a mapping interface\n",
    "kd_embeddings = ensure_embedding_dict(dacc.embeddings_df.embedding)\n",
    "print(f\"{len(kd_embeddings)=}\")\n",
    "embedding_vectors = embeddings_func(np.array(list(kd_embeddings.values())))\n",
    "t = {k: tuple(v) for k, v in zip(kd_embeddings.keys(), embedding_vectors)}\n",
    "len(kd_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5597, 5599)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imbed\n",
    "\n",
    "planar_embeddings_ = imbed.planar_embeddings(\n",
    "    dacc.embeddings_df.embedding, embeddings_func='ncvis'\n",
    ")\n",
    "len(planar_embeddings_), len(dacc.embeddings_df)  #  looses two rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "dacc.saves['planar_embeddings.parquet'] = imbed.util.planar_embeddings_dict_to_df(\n",
    "    planar_embeddings_\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conference</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authorNamesDeduped</th>\n",
       "      <th>award</th>\n",
       "      <th>resources</th>\n",
       "      <th>link</th>\n",
       "      <th>segment</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>cluster_05</th>\n",
       "      <th>cluster_08</th>\n",
       "      <th>cluster_13</th>\n",
       "      <th>cluster_21</th>\n",
       "      <th>cluster_34</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10.1111/cgf.15097</th>\n",
       "      <td>EuroVis</td>\n",
       "      <td>2024</td>\n",
       "      <td>A Prediction-Traversal Approach for Compressin...</td>\n",
       "      <td>10.1111/cgf.15097</td>\n",
       "      <td>We explore an error-bounded lossy compression ...</td>\n",
       "      <td>Congrong Ren;Xin Liang 0001;Hanqi Guo 0001</td>\n",
       "      <td>None</td>\n",
       "      <td>P</td>\n",
       "      <td>https://vispubs.com/?paper=10.1111%2Fcgf.15097</td>\n",
       "      <td>##A Prediction-Traversal Approach for Compress...</td>\n",
       "      <td>318</td>\n",
       "      <td>-16.307396</td>\n",
       "      <td>-14.705571</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1111/cgf.15111</th>\n",
       "      <td>EuroVis</td>\n",
       "      <td>2024</td>\n",
       "      <td>A Systematic Literature Review of User Evaluat...</td>\n",
       "      <td>10.1111/cgf.15111</td>\n",
       "      <td>User evaluation is a common and useful tool fo...</td>\n",
       "      <td>Judith Friedl-Knirsch;Fabian Pointecker;S. Pfi...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://vispubs.com/?paper=10.1111%2Fcgf.15111</td>\n",
       "      <td>##A Systematic Literature Review of User Evalu...</td>\n",
       "      <td>196</td>\n",
       "      <td>11.463908</td>\n",
       "      <td>3.781468</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1111/cgf.15077</th>\n",
       "      <td>EuroVis</td>\n",
       "      <td>2024</td>\n",
       "      <td>An Experimental Evaluation of Viewpoint-Based ...</td>\n",
       "      <td>10.1111/cgf.15077</td>\n",
       "      <td>Node-link diagrams are a widely used metaphor ...</td>\n",
       "      <td>Simon van Wageningen;Tamara Mchedlidze;Alexand...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://vispubs.com/?paper=10.1111%2Fcgf.15077</td>\n",
       "      <td>##An Experimental Evaluation of Viewpoint-Base...</td>\n",
       "      <td>256</td>\n",
       "      <td>-7.072111</td>\n",
       "      <td>14.292480</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1111/cgf.15088</th>\n",
       "      <td>EuroVis</td>\n",
       "      <td>2024</td>\n",
       "      <td>Antarstick: Extracting Snow Height From Time-L...</td>\n",
       "      <td>10.1111/cgf.15088</td>\n",
       "      <td>The evolution and accumulation of snow cover a...</td>\n",
       "      <td>Matej Lang;Radoslav MrÃ¡z;Marek TrtÃ­k;Sergej St...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://vispubs.com/?paper=10.1111%2Fcgf.15088</td>\n",
       "      <td>##Antarstick: Extracting Snow Height From Time...</td>\n",
       "      <td>184</td>\n",
       "      <td>-8.591015</td>\n",
       "      <td>3.640828</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1111/cgf.15099</th>\n",
       "      <td>EuroVis</td>\n",
       "      <td>2024</td>\n",
       "      <td>AutoVizuA11y: A Tool to Automate Screen Reader...</td>\n",
       "      <td>10.1111/cgf.15099</td>\n",
       "      <td>Charts remain widely inaccessible on the web f...</td>\n",
       "      <td>Diogo Duarte;Rita Costa;Pedro Bizarro;Carlos D...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://vispubs.com/?paper=10.1111%2Fcgf.15099</td>\n",
       "      <td>##AutoVizuA11y: A Tool to Automate Screen Read...</td>\n",
       "      <td>297</td>\n",
       "      <td>15.518506</td>\n",
       "      <td>-2.733241</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1145/97243.97318</th>\n",
       "      <td>CHI</td>\n",
       "      <td>1990</td>\n",
       "      <td>Track - a trace construction kit</td>\n",
       "      <td>10.1145/97243.97318</td>\n",
       "      <td>TRACK is a kit to interactively construct envi...</td>\n",
       "      <td>Heinz-Dieter BÃ¶cker;JÃ¼rgen Herczeg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://vispubs.com/?paper=10.1145%2F97243.97318</td>\n",
       "      <td>##Track - a trace construction kit\\n\\nTRACK is...</td>\n",
       "      <td>125</td>\n",
       "      <td>2.137997</td>\n",
       "      <td>-0.188143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1145/67449.67513</th>\n",
       "      <td>CHI</td>\n",
       "      <td>1989</td>\n",
       "      <td>Constraint grammars-a new model for specifying...</td>\n",
       "      <td>10.1145/67449.67513</td>\n",
       "      <td>User Interface Management Systems often attemp...</td>\n",
       "      <td>Bradley T. Vander Zanden</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://vispubs.com/?paper=10.1145%2F67449.67513</td>\n",
       "      <td>##Constraint grammars-a new model for specifyi...</td>\n",
       "      <td>125</td>\n",
       "      <td>-6.188530</td>\n",
       "      <td>10.008981</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1145/57167.57168</th>\n",
       "      <td>CHI</td>\n",
       "      <td>1988</td>\n",
       "      <td>Grasping reality through illusion - interactiv...</td>\n",
       "      <td>10.1145/57167.57168</td>\n",
       "      <td>I treat three related subjects: virtual-worlds...</td>\n",
       "      <td>Frederick P. Brooks Jr.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://vispubs.com/?paper=10.1145%2F57167.57168</td>\n",
       "      <td>##Grasping reality through illusion - interact...</td>\n",
       "      <td>156</td>\n",
       "      <td>1.712703</td>\n",
       "      <td>-5.182271</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1145/22627.22348</th>\n",
       "      <td>CHI</td>\n",
       "      <td>1986</td>\n",
       "      <td>Design principles for the enhanced presentatio...</td>\n",
       "      <td>10.1145/22627.22348</td>\n",
       "      <td>In order to make computer programs more readab...</td>\n",
       "      <td>Ronald Baecker;Aaron Marcus</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://vispubs.com/?paper=10.1145%2F22627.22348</td>\n",
       "      <td>##Design principles for the enhanced presentat...</td>\n",
       "      <td>118</td>\n",
       "      <td>3.431993</td>\n",
       "      <td>-1.305101</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1145/22627.22349</th>\n",
       "      <td>CHI</td>\n",
       "      <td>1986</td>\n",
       "      <td>Visual programming, programming by example, an...</td>\n",
       "      <td>10.1145/22627.22349</td>\n",
       "      <td>There has been a great interest recently in sy...</td>\n",
       "      <td>Brad A. Myers</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://vispubs.com/?paper=10.1145%2F22627.22349</td>\n",
       "      <td>##Visual programming, programming by example, ...</td>\n",
       "      <td>131</td>\n",
       "      <td>3.271198</td>\n",
       "      <td>-1.526583</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5599 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    conference  year  \\\n",
       "id_                                    \n",
       "10.1111/cgf.15097      EuroVis  2024   \n",
       "10.1111/cgf.15111      EuroVis  2024   \n",
       "10.1111/cgf.15077      EuroVis  2024   \n",
       "10.1111/cgf.15088      EuroVis  2024   \n",
       "10.1111/cgf.15099      EuroVis  2024   \n",
       "...                        ...   ...   \n",
       "10.1145/97243.97318        CHI  1990   \n",
       "10.1145/67449.67513        CHI  1989   \n",
       "10.1145/57167.57168        CHI  1988   \n",
       "10.1145/22627.22348        CHI  1986   \n",
       "10.1145/22627.22349        CHI  1986   \n",
       "\n",
       "                                                                 title  \\\n",
       "id_                                                                      \n",
       "10.1111/cgf.15097    A Prediction-Traversal Approach for Compressin...   \n",
       "10.1111/cgf.15111    A Systematic Literature Review of User Evaluat...   \n",
       "10.1111/cgf.15077    An Experimental Evaluation of Viewpoint-Based ...   \n",
       "10.1111/cgf.15088    Antarstick: Extracting Snow Height From Time-L...   \n",
       "10.1111/cgf.15099    AutoVizuA11y: A Tool to Automate Screen Reader...   \n",
       "...                                                                ...   \n",
       "10.1145/97243.97318                   Track - a trace construction kit   \n",
       "10.1145/67449.67513  Constraint grammars-a new model for specifying...   \n",
       "10.1145/57167.57168  Grasping reality through illusion - interactiv...   \n",
       "10.1145/22627.22348  Design principles for the enhanced presentatio...   \n",
       "10.1145/22627.22349  Visual programming, programming by example, an...   \n",
       "\n",
       "                                     doi  \\\n",
       "id_                                        \n",
       "10.1111/cgf.15097      10.1111/cgf.15097   \n",
       "10.1111/cgf.15111      10.1111/cgf.15111   \n",
       "10.1111/cgf.15077      10.1111/cgf.15077   \n",
       "10.1111/cgf.15088      10.1111/cgf.15088   \n",
       "10.1111/cgf.15099      10.1111/cgf.15099   \n",
       "...                                  ...   \n",
       "10.1145/97243.97318  10.1145/97243.97318   \n",
       "10.1145/67449.67513  10.1145/67449.67513   \n",
       "10.1145/57167.57168  10.1145/57167.57168   \n",
       "10.1145/22627.22348  10.1145/22627.22348   \n",
       "10.1145/22627.22349  10.1145/22627.22349   \n",
       "\n",
       "                                                              abstract  \\\n",
       "id_                                                                      \n",
       "10.1111/cgf.15097    We explore an error-bounded lossy compression ...   \n",
       "10.1111/cgf.15111    User evaluation is a common and useful tool fo...   \n",
       "10.1111/cgf.15077    Node-link diagrams are a widely used metaphor ...   \n",
       "10.1111/cgf.15088    The evolution and accumulation of snow cover a...   \n",
       "10.1111/cgf.15099    Charts remain widely inaccessible on the web f...   \n",
       "...                                                                ...   \n",
       "10.1145/97243.97318  TRACK is a kit to interactively construct envi...   \n",
       "10.1145/67449.67513  User Interface Management Systems often attemp...   \n",
       "10.1145/57167.57168  I treat three related subjects: virtual-worlds...   \n",
       "10.1145/22627.22348  In order to make computer programs more readab...   \n",
       "10.1145/22627.22349  There has been a great interest recently in sy...   \n",
       "\n",
       "                                                    authorNamesDeduped award  \\\n",
       "id_                                                                            \n",
       "10.1111/cgf.15097           Congrong Ren;Xin Liang 0001;Hanqi Guo 0001  None   \n",
       "10.1111/cgf.15111    Judith Friedl-Knirsch;Fabian Pointecker;S. Pfi...  None   \n",
       "10.1111/cgf.15077    Simon van Wageningen;Tamara Mchedlidze;Alexand...  None   \n",
       "10.1111/cgf.15088    Matej Lang;Radoslav MrÃ¡z;Marek TrtÃ­k;Sergej St...  None   \n",
       "10.1111/cgf.15099    Diogo Duarte;Rita Costa;Pedro Bizarro;Carlos D...  None   \n",
       "...                                                                ...   ...   \n",
       "10.1145/97243.97318                 Heinz-Dieter BÃ¶cker;JÃ¼rgen Herczeg  None   \n",
       "10.1145/67449.67513                           Bradley T. Vander Zanden  None   \n",
       "10.1145/57167.57168                            Frederick P. Brooks Jr.  None   \n",
       "10.1145/22627.22348                        Ronald Baecker;Aaron Marcus  None   \n",
       "10.1145/22627.22349                                      Brad A. Myers  None   \n",
       "\n",
       "                    resources  \\\n",
       "id_                             \n",
       "10.1111/cgf.15097           P   \n",
       "10.1111/cgf.15111        None   \n",
       "10.1111/cgf.15077        None   \n",
       "10.1111/cgf.15088        None   \n",
       "10.1111/cgf.15099        None   \n",
       "...                       ...   \n",
       "10.1145/97243.97318      None   \n",
       "10.1145/67449.67513      None   \n",
       "10.1145/57167.57168      None   \n",
       "10.1145/22627.22348      None   \n",
       "10.1145/22627.22349      None   \n",
       "\n",
       "                                                                 link  \\\n",
       "id_                                                                     \n",
       "10.1111/cgf.15097      https://vispubs.com/?paper=10.1111%2Fcgf.15097   \n",
       "10.1111/cgf.15111      https://vispubs.com/?paper=10.1111%2Fcgf.15111   \n",
       "10.1111/cgf.15077      https://vispubs.com/?paper=10.1111%2Fcgf.15077   \n",
       "10.1111/cgf.15088      https://vispubs.com/?paper=10.1111%2Fcgf.15088   \n",
       "10.1111/cgf.15099      https://vispubs.com/?paper=10.1111%2Fcgf.15099   \n",
       "...                                                               ...   \n",
       "10.1145/97243.97318  https://vispubs.com/?paper=10.1145%2F97243.97318   \n",
       "10.1145/67449.67513  https://vispubs.com/?paper=10.1145%2F67449.67513   \n",
       "10.1145/57167.57168  https://vispubs.com/?paper=10.1145%2F57167.57168   \n",
       "10.1145/22627.22348  https://vispubs.com/?paper=10.1145%2F22627.22348   \n",
       "10.1145/22627.22349  https://vispubs.com/?paper=10.1145%2F22627.22349   \n",
       "\n",
       "                                                               segment  \\\n",
       "id_                                                                      \n",
       "10.1111/cgf.15097    ##A Prediction-Traversal Approach for Compress...   \n",
       "10.1111/cgf.15111    ##A Systematic Literature Review of User Evalu...   \n",
       "10.1111/cgf.15077    ##An Experimental Evaluation of Viewpoint-Base...   \n",
       "10.1111/cgf.15088    ##Antarstick: Extracting Snow Height From Time...   \n",
       "10.1111/cgf.15099    ##AutoVizuA11y: A Tool to Automate Screen Read...   \n",
       "...                                                                ...   \n",
       "10.1145/97243.97318  ##Track - a trace construction kit\\n\\nTRACK is...   \n",
       "10.1145/67449.67513  ##Constraint grammars-a new model for specifyi...   \n",
       "10.1145/57167.57168  ##Grasping reality through illusion - interact...   \n",
       "10.1145/22627.22348  ##Design principles for the enhanced presentat...   \n",
       "10.1145/22627.22349  ##Visual programming, programming by example, ...   \n",
       "\n",
       "                     n_tokens          x          y  cluster_05  cluster_08  \\\n",
       "id_                                                                           \n",
       "10.1111/cgf.15097         318 -16.307396 -14.705571           4           7   \n",
       "10.1111/cgf.15111         196  11.463908   3.781468           1           4   \n",
       "10.1111/cgf.15077         256  -7.072111  14.292480           3           0   \n",
       "10.1111/cgf.15088         184  -8.591015   3.640828           1           2   \n",
       "10.1111/cgf.15099         297  15.518506  -2.733241           1           6   \n",
       "...                       ...        ...        ...         ...         ...   \n",
       "10.1145/97243.97318       125   2.137997  -0.188143           1           0   \n",
       "10.1145/67449.67513       125  -6.188530  10.008981           1           0   \n",
       "10.1145/57167.57168       156   1.712703  -5.182271           0           4   \n",
       "10.1145/22627.22348       118   3.431993  -1.305101           0           6   \n",
       "10.1145/22627.22349       131   3.271198  -1.526583           0           6   \n",
       "\n",
       "                     cluster_13  cluster_21  cluster_34  \n",
       "id_                                                      \n",
       "10.1111/cgf.15097            12          16          30  \n",
       "10.1111/cgf.15111            10          15          19  \n",
       "10.1111/cgf.15077             0          20          12  \n",
       "10.1111/cgf.15088             1           1          31  \n",
       "10.1111/cgf.15099             7           2          28  \n",
       "...                         ...         ...         ...  \n",
       "10.1145/97243.97318           1           4          29  \n",
       "10.1145/67449.67513           0          20          28  \n",
       "10.1145/57167.57168           2          13          14  \n",
       "10.1145/22627.22348          10           2          28  \n",
       "10.1145/22627.22349           7           5          29  \n",
       "\n",
       "[5599 rows x 18 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imbed.tools import ClusterLabeler\n",
    "from imbed_data_prep.eurovis import EurovisDacc\n",
    "\n",
    "dacc = EurovisDacc()\n",
    "\n",
    "dacc.merged_artifacts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '\"Visualizing Complex Graph Data\"',\n",
      " 1: '\"Visual Analytics Case Studies\"',\n",
      " 2: '\"Visualizations in Virtual Reality\"',\n",
      " 3: '\"Visualizing Complex Scientific Data\"',\n",
      " 4: '\"Advanced Flow Visualization Techniques\"',\n",
      " 5: '\"Visual Perception in Data Presentation\"',\n",
      " 6: '\"Weather Data Visualization Studies\"',\n",
      " 7: '\"Explorations in Data Visualization\"',\n",
      " 8: '\"Advancements in Volume Visualization\"',\n",
      " 9: '\"Visualizing High-Dimensional Data\"',\n",
      " 10: '\"Advancements in Data Visualization\"',\n",
      " 11: '\"Advanced Vector Field Visualization\"',\n",
      " 12: '\"Advances in Isosurface Visualization\"'}\n"
     ]
    }
   ],
   "source": [
    "cluster_labels = ClusterLabeler(cluster_idx_col='cluster_13').label_clusters(dacc.merged_artifacts)\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(cluster_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '\"Visualization in Network Analysis\"',\n",
      " 1: '\"Visual Analytics in Diverse Disciplines\"',\n",
      " 2: '\"Advancements in Interactive Visualization\"',\n",
      " 3: '\"Scientific Research Visualization Techniques\"',\n",
      " 4: '\"Fluid Dynamics Visualization Techniques\"',\n",
      " 5: '\"Perception in Data Visualization\"',\n",
      " 6: '\"Visualizing Uncertainty in Data\"',\n",
      " 7: '\"Advancements in Data Visualization\"',\n",
      " 8: '\"Advancements in Volume Rendering\"',\n",
      " 9: '\"Multivariate Data Visualization Techniques\"',\n",
      " 10: '\"Visualizations in Data Interaction\"',\n",
      " 11: '\"Advanced Vector Field Visualization\"',\n",
      " 12: '\"Advanced Computational Geometry Techniques\"'}\n"
     ]
    }
   ],
   "source": [
    "context = \"\"\"\n",
    "    Research papers for data visualization, visual analytics, and related fields.\n",
    "\"\"\"\n",
    "cluster_labels = ClusterLabeler(cluster_idx_col='cluster_13').label_clusters(dacc.merged_artifacts)\n",
    "\n",
    "pprint(cluster_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.DataFrame(data=cluster_labels.values(), index=cluster_labels.keys(), columns=['label']).sort_index()\n",
    "dacc.saves['cluster_13_labels.parquet'] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '\"Molecular Visualization Techniques Analysis\"',\n",
      " 1: '\"Visual Analytics in Geoscience\"',\n",
      " 2: '\"Enhancing Data Visualization Techniques\"',\n",
      " 3: '\"Visualizing Healthcare Innovations\"',\n",
      " 4: '\"Visualization Techniques in Analytics\"',\n",
      " 5: '\"Visualizing Complex System Designs\"',\n",
      " 6: '\"Effectiveness of Data Visualization\"',\n",
      " 7: '\"Visual Analytics in AI\"',\n",
      " 8: '\"Advancements in Volume Rendering\"',\n",
      " 9: '\"Advanced Flow Visualization Techniques\"',\n",
      " 10: '\"Advanced Field Visualization Techniques\"',\n",
      " 11: '\"Visualizing Analytic Text Segments\"',\n",
      " 12: '\"Unconventional Interaction Design Themes\"',\n",
      " 13: '\"Advancements in Virtual Reality\"',\n",
      " 14: '\"Advancements in Visualization Techniques\"',\n",
      " 15: '\"Advancements in Data Visualization\"',\n",
      " 16: '\"Advancements in Geometric Simplification\"',\n",
      " 17: '\"Hierarchical Data Visualization Methods\"',\n",
      " 18: '\"Exploring High-Dimensional Data Visualization\"',\n",
      " 19: '\"Visual Analytics in Network Exploration\"',\n",
      " 20: '\"Advanced Graph Visualization Techniques\"'}\n"
     ]
    }
   ],
   "source": [
    "context = \"\"\"\n",
    "    Research papers for data visualization, visual analytics, and related fields.\n",
    "\"\"\"\n",
    "cluster_labels = ClusterLabeler(cluster_idx_col='cluster_21').label_clusters(dacc.merged_artifacts)\n",
    "\n",
    "tt = pd.DataFrame(data=cluster_labels.values(), index=cluster_labels.keys(), columns=['label']).sort_index()\n",
    "dacc.saves['cluster_21_labels.parquet'] = tt\n",
    "\n",
    "pprint(cluster_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1986"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dacc.merged_artifacts.year.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imbed.tools import ClusterLabeler\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "w = ClusterLabeler(\n",
    "    cluster_idx_col='cluster_13', context=context, get_row_segments=itemgetter('title')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '\"Advancements in Data Visualization\"',\n",
      " 1: '\"Semantic Interaction in Visualizations\"',\n",
      " 2: '\"Advancements in Visual Analytics\"',\n",
      " 3: '\"Advanced Techniques in Data Visualization\"',\n",
      " 4: '\"Advanced Data Visualization Techniques\"',\n",
      " 5: '\"Advancements in Data Visualization\"',\n",
      " 6: '\"Visual Analytics Techniques Varieties\"',\n",
      " 7: '\"Advanced Visualization Techniques Exploration\"',\n",
      " 8: '\"Advancements in Visual Data Analysis\"',\n",
      " 9: '\"Advanced Data Visualization Techniques\"',\n",
      " 10: '\"Advanced Techniques in Data Visualization\"',\n",
      " 11: '\"Advanced Visualization Techniques Analysis\"',\n",
      " 12: '\"Visual Analytics Techniques Variation\"'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "labels = w.label_clusters(dacc.merged_artifacts)\n",
    "\n",
    "pprint(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[185], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m t \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data\u001b[38;5;241m=\u001b[39m\u001b[43mlabels\u001b[49m\u001b[38;5;241m.\u001b[39mvalues(), index\u001b[38;5;241m=\u001b[39mlabels\u001b[38;5;241m.\u001b[39mkeys(), columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39msort_index()\n\u001b[1;32m      2\u001b[0m dacc\u001b[38;5;241m.\u001b[39msaves[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster_13_labels.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m t\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "t = pd.DataFrame(data=labels.values(), index=labels.keys(), columns=['label']).sort_index()\n",
    "dacc.saves['cluster_13_labels.parquet'] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Advancements in Data Visualization\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Semantic Interaction in Visualizations\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Advancements in Visual Analytics\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Advanced Techniques in Data Visualization\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Advanced Data Visualization Techniques\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"Advancements in Data Visualization\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"Visual Analytics Techniques Varieties\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Advanced Visualization Techniques Exploration\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Advancements in Visual Data Analysis\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Advanced Data Visualization Techniques\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"Advanced Techniques in Data Visualization\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\"Advanced Visualization Techniques Analysis\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\"Visual Analytics Techniques Variation\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              label\n",
       "0              \"Advancements in Data Visualization\"\n",
       "1          \"Semantic Interaction in Visualizations\"\n",
       "2                \"Advancements in Visual Analytics\"\n",
       "3       \"Advanced Techniques in Data Visualization\"\n",
       "4          \"Advanced Data Visualization Techniques\"\n",
       "5              \"Advancements in Data Visualization\"\n",
       "6           \"Visual Analytics Techniques Varieties\"\n",
       "7   \"Advanced Visualization Techniques Exploration\"\n",
       "8            \"Advancements in Visual Data Analysis\"\n",
       "9          \"Advanced Data Visualization Techniques\"\n",
       "10      \"Advanced Techniques in Data Visualization\"\n",
       "11     \"Advanced Visualization Techniques Analysis\"\n",
       "12          \"Visual Analytics Techniques Variation\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "pd.DataFrame(data=labels.values(), index=labels.keys(), columns=['label']).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Why doesn't it work?\n",
    "\n",
    "# dacc.saves['cluster_13_labels.json'] = {k: labels[k] for k in range(len(labels))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.DataFrame(data=labels.values(), index=labels.keys(), columns=['label']).sort_index()\n",
    "dacc.saves['cluster_13_labels.parquet'] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '\"Advanced Techniques in Data Visualization\"',\n",
      " 1: '\"Advanced Visualization Techniques Analysis\"',\n",
      " 2: '\"Advanced Data Visualization Techniques\"',\n",
      " 3: '\"Advanced Data Visualization Techniques\"',\n",
      " 4: '\"Interactive Visualization Research Papers\"',\n",
      " 5: '\"Advancements in Visual Analytics\"',\n",
      " 6: '\"Advancements in Visualization Techniques\"',\n",
      " 7: '\"Advanced Visualization Techniques Study\"',\n",
      " 8: '\"Advanced Data Visualization Methods\"',\n",
      " 9: '\"Innovations in Data Visualization\"',\n",
      " 10: '\"Advanced Visualization Techniques Analysis\"',\n",
      " 11: '\"Advancements in Visual Analytics\"',\n",
      " 12: '\"Advanced Visualization Techniques Study\"',\n",
      " 13: '\"Advanced Techniques in Visual Analytics\"',\n",
      " 14: '\"Advancements in Data Visualization\"',\n",
      " 15: '\"Advanced Visualization Techniques\"',\n",
      " 16: '\"Advanced Techniques in Data Visualization\"',\n",
      " 17: '\"Visualizing Data Utilization Techniques\"',\n",
      " 18: '\"Innovative Data Visualization Approaches\"',\n",
      " 19: '\"Advancements in Visualization Techniques\"',\n",
      " 20: '\"Advanced Visualization Techniques Analysis\"'}\n"
     ]
    }
   ],
   "source": [
    "w = ClusterLabeler(\n",
    "    cluster_idx_col='cluster_21', context=context, get_row_segments=itemgetter('title')\n",
    ")\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "labels = w.label_clusters(dacc.merged_artifacts)\n",
    "\n",
    "pprint(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.DataFrame(data=labels.values(), index=labels.keys(), columns=['label']).sort_index()\n",
    "dacc.saves['cluster_21_labels.parquet'] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "i, segments = next(w._cluster_idx_and_segments_sample(dacc.merged_artifacts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = w._label_clusters(dacc.merged_artifacts)\n",
    "it = cluster_labels()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, '\"Advancements in Visualization Techniques\"')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, '\"Advanced Data Visualization Techniques\"')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, '\"Visual Analytics Techniques Diversity\"')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dacc = WildchatDacc()\n",
    "\n",
    "# embeddings = dacc.saves['embeddings.parquet']\n",
    "# ids = embeddings.id_\n",
    "\n",
    "# # make a np array of the embeddings\n",
    "# embeddings = np.array(embeddings.embedding.to_list())\n",
    "\n",
    "# clusters_df_ = clusters_df(embeddings)\n",
    "\n",
    "# # set the indices of the clusters_df_ to the same as the embeddings\n",
    "# clusters_df_ = clusters_df_.set_index(ids)\n",
    "\n",
    "# dacc.saves['clusters.parquet'] = clusters_df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join raw data with embeddings and clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imbed_data_prep.eurovis import EurovisDacc\n",
    "\n",
    "dacc = EurovisDacc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = dacc.saves['raw_data.csv']\n",
    "tt = dacc.saves['planar_embeddings.parquet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conference</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authorNamesDeduped</th>\n",
       "      <th>award</th>\n",
       "      <th>resources</th>\n",
       "      <th>link</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EuroVis</td>\n",
       "      <td>2024</td>\n",
       "      <td>A Prediction-Traversal Approach for Compressin...</td>\n",
       "      <td>10.1111/cgf.15097</td>\n",
       "      <td>We explore an error-bounded lossy compression ...</td>\n",
       "      <td>Congrong Ren;Xin Liang 0001;Hanqi Guo 0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>https://vispubs.com/?paper=10.1111%2Fcgf.15097</td>\n",
       "      <td>-29.573154</td>\n",
       "      <td>-3.688721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EuroVis</td>\n",
       "      <td>2024</td>\n",
       "      <td>A Systematic Literature Review of User Evaluat...</td>\n",
       "      <td>10.1111/cgf.15111</td>\n",
       "      <td>User evaluation is a common and useful tool fo...</td>\n",
       "      <td>Judith Friedl-Knirsch;Fabian Pointecker;S. Pfi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://vispubs.com/?paper=10.1111%2Fcgf.15111</td>\n",
       "      <td>15.060126</td>\n",
       "      <td>3.490866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EuroVis</td>\n",
       "      <td>2024</td>\n",
       "      <td>An Experimental Evaluation of Viewpoint-Based ...</td>\n",
       "      <td>10.1111/cgf.15077</td>\n",
       "      <td>Node-link diagrams are a widely used metaphor ...</td>\n",
       "      <td>Simon van Wageningen;Tamara Mchedlidze;Alexand...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://vispubs.com/?paper=10.1111%2Fcgf.15077</td>\n",
       "      <td>-29.541185</td>\n",
       "      <td>-3.692561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EuroVis</td>\n",
       "      <td>2024</td>\n",
       "      <td>Antarstick: Extracting Snow Height From Time-L...</td>\n",
       "      <td>10.1111/cgf.15088</td>\n",
       "      <td>The evolution and accumulation of snow cover a...</td>\n",
       "      <td>Matej Lang;Radoslav MrÃ¡z;Marek TrtÃ­k;Sergej St...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://vispubs.com/?paper=10.1111%2Fcgf.15088</td>\n",
       "      <td>-29.395565</td>\n",
       "      <td>-3.648016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EuroVis</td>\n",
       "      <td>2024</td>\n",
       "      <td>AutoVizuA11y: A Tool to Automate Screen Reader...</td>\n",
       "      <td>10.1111/cgf.15099</td>\n",
       "      <td>Charts remain widely inaccessible on the web f...</td>\n",
       "      <td>Diogo Duarte;Rita Costa;Pedro Bizarro;Carlos D...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://vispubs.com/?paper=10.1111%2Fcgf.15099</td>\n",
       "      <td>-29.468313</td>\n",
       "      <td>-3.666119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5597</th>\n",
       "      <td>Vis</td>\n",
       "      <td>1991</td>\n",
       "      <td>How visualization applications drive tool sele...</td>\n",
       "      <td>10.1109/VISUAL.1991.175826</td>\n",
       "      <td>This paper looks at the role visualization and...</td>\n",
       "      <td>D. Prawel;M. Brown;C. Harris;R. Kriz;M. Vigil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://vispubs.com/?paper=10.1109%2FVISUAL.19...</td>\n",
       "      <td>0.933912</td>\n",
       "      <td>-5.174725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5598</th>\n",
       "      <td>Vis</td>\n",
       "      <td>1991</td>\n",
       "      <td>Image handling in a multi-vendor environment</td>\n",
       "      <td>10.1109/VISUAL.1991.175814</td>\n",
       "      <td>Software developed to deal with differing imag...</td>\n",
       "      <td>David R. Nadeau;T. Todd Elvins;Michael J. Bailey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://vispubs.com/?paper=10.1109%2FVISUAL.19...</td>\n",
       "      <td>0.901553</td>\n",
       "      <td>-5.090282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5599</th>\n",
       "      <td>Vis</td>\n",
       "      <td>1991</td>\n",
       "      <td>In vivo blood flow visualization with magnetic...</td>\n",
       "      <td>10.1109/VISUAL.1991.175801</td>\n",
       "      <td>Blood movement investigated by magnetic resona...</td>\n",
       "      <td>Guang-Zhong Yang;Peter Burger;Philip J. Kilner...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://vispubs.com/?paper=10.1109%2FVISUAL.19...</td>\n",
       "      <td>0.895913</td>\n",
       "      <td>-5.134688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5600</th>\n",
       "      <td>Vis</td>\n",
       "      <td>1991</td>\n",
       "      <td>Integration of visualization and scientific ca...</td>\n",
       "      <td>10.1109/VISUAL.1991.175812</td>\n",
       "      <td>The problems and advantages of integrating sci...</td>\n",
       "      <td>Ulrich Lang 0002;Ruth E. Lang;Roland RÃ¼hle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://vispubs.com/?paper=10.1109%2FVISUAL.19...</td>\n",
       "      <td>0.875707</td>\n",
       "      <td>-5.113888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5601</th>\n",
       "      <td>Vis</td>\n",
       "      <td>1991</td>\n",
       "      <td>Interactive data exploration with a supercomputer</td>\n",
       "      <td>10.1109/VISUAL.1991.175809</td>\n",
       "      <td>An experiment in exploratory data visualizatio...</td>\n",
       "      <td>Stuart Smith;Georges G. Grinstein;R. Daniel Be...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://vispubs.com/?paper=10.1109%2FVISUAL.19...</td>\n",
       "      <td>0.907948</td>\n",
       "      <td>-5.094199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5500 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     conference  year                                              title  \\\n",
       "0       EuroVis  2024  A Prediction-Traversal Approach for Compressin...   \n",
       "1       EuroVis  2024  A Systematic Literature Review of User Evaluat...   \n",
       "2       EuroVis  2024  An Experimental Evaluation of Viewpoint-Based ...   \n",
       "3       EuroVis  2024  Antarstick: Extracting Snow Height From Time-L...   \n",
       "4       EuroVis  2024  AutoVizuA11y: A Tool to Automate Screen Reader...   \n",
       "...         ...   ...                                                ...   \n",
       "5597        Vis  1991  How visualization applications drive tool sele...   \n",
       "5598        Vis  1991       Image handling in a multi-vendor environment   \n",
       "5599        Vis  1991  In vivo blood flow visualization with magnetic...   \n",
       "5600        Vis  1991  Integration of visualization and scientific ca...   \n",
       "5601        Vis  1991  Interactive data exploration with a supercomputer   \n",
       "\n",
       "                             doi  \\\n",
       "0              10.1111/cgf.15097   \n",
       "1              10.1111/cgf.15111   \n",
       "2              10.1111/cgf.15077   \n",
       "3              10.1111/cgf.15088   \n",
       "4              10.1111/cgf.15099   \n",
       "...                          ...   \n",
       "5597  10.1109/VISUAL.1991.175826   \n",
       "5598  10.1109/VISUAL.1991.175814   \n",
       "5599  10.1109/VISUAL.1991.175801   \n",
       "5600  10.1109/VISUAL.1991.175812   \n",
       "5601  10.1109/VISUAL.1991.175809   \n",
       "\n",
       "                                               abstract  \\\n",
       "0     We explore an error-bounded lossy compression ...   \n",
       "1     User evaluation is a common and useful tool fo...   \n",
       "2     Node-link diagrams are a widely used metaphor ...   \n",
       "3     The evolution and accumulation of snow cover a...   \n",
       "4     Charts remain widely inaccessible on the web f...   \n",
       "...                                                 ...   \n",
       "5597  This paper looks at the role visualization and...   \n",
       "5598  Software developed to deal with differing imag...   \n",
       "5599  Blood movement investigated by magnetic resona...   \n",
       "5600  The problems and advantages of integrating sci...   \n",
       "5601  An experiment in exploratory data visualizatio...   \n",
       "\n",
       "                                     authorNamesDeduped award resources  \\\n",
       "0            Congrong Ren;Xin Liang 0001;Hanqi Guo 0001   NaN         P   \n",
       "1     Judith Friedl-Knirsch;Fabian Pointecker;S. Pfi...   NaN       NaN   \n",
       "2     Simon van Wageningen;Tamara Mchedlidze;Alexand...   NaN       NaN   \n",
       "3     Matej Lang;Radoslav MrÃ¡z;Marek TrtÃ­k;Sergej St...   NaN       NaN   \n",
       "4     Diogo Duarte;Rita Costa;Pedro Bizarro;Carlos D...   NaN       NaN   \n",
       "...                                                 ...   ...       ...   \n",
       "5597      D. Prawel;M. Brown;C. Harris;R. Kriz;M. Vigil   NaN       NaN   \n",
       "5598   David R. Nadeau;T. Todd Elvins;Michael J. Bailey   NaN       NaN   \n",
       "5599  Guang-Zhong Yang;Peter Burger;Philip J. Kilner...   NaN       NaN   \n",
       "5600         Ulrich Lang 0002;Ruth E. Lang;Roland RÃ¼hle   NaN       NaN   \n",
       "5601  Stuart Smith;Georges G. Grinstein;R. Daniel Be...   NaN       NaN   \n",
       "\n",
       "                                                   link          x         y  \n",
       "0        https://vispubs.com/?paper=10.1111%2Fcgf.15097 -29.573154 -3.688721  \n",
       "1        https://vispubs.com/?paper=10.1111%2Fcgf.15111  15.060126  3.490866  \n",
       "2        https://vispubs.com/?paper=10.1111%2Fcgf.15077 -29.541185 -3.692561  \n",
       "3        https://vispubs.com/?paper=10.1111%2Fcgf.15088 -29.395565 -3.648016  \n",
       "4        https://vispubs.com/?paper=10.1111%2Fcgf.15099 -29.468313 -3.666119  \n",
       "...                                                 ...        ...       ...  \n",
       "5597  https://vispubs.com/?paper=10.1109%2FVISUAL.19...   0.933912 -5.174725  \n",
       "5598  https://vispubs.com/?paper=10.1109%2FVISUAL.19...   0.901553 -5.090282  \n",
       "5599  https://vispubs.com/?paper=10.1109%2FVISUAL.19...   0.895913 -5.134688  \n",
       "5600  https://vispubs.com/?paper=10.1109%2FVISUAL.19...   0.875707 -5.113888  \n",
       "5601  https://vispubs.com/?paper=10.1109%2FVISUAL.19...   0.907948 -5.094199  \n",
       "\n",
       "[5500 rows x 11 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_new = t.merge(tt, left_on='doi', right_index=True)\n",
    "t_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imbed.data_prep import kmeans_cluster_indices\n",
    "from imbed_data_prep.wildchat import WildchatDacc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "fibonacci_sequence = [5, 8, 13, 21, 34]\n",
    "\n",
    "def clusters_df(embeddings, n_clusters = fibonacci_sequence):\n",
    "    if isinstance(embeddings, pd.DataFrame):\n",
    "        if 'embedding' in embeddings.columns:\n",
    "            embeddings = embeddings.embedding\n",
    "        embeddings = np.array(embeddings.to_list())\n",
    "    def gen():\n",
    "        for k in n_clusters:\n",
    "            yield f\"cluster_{k:02.0f}\", kmeans_cluster_indices(embeddings, n_clusters=k)\n",
    "\n",
    "    return pd.DataFrame(dict(gen()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dacc = WildchatDacc()\n",
    "\n",
    "# embeddings = dacc.saves['embeddings.parquet']\n",
    "# ids = embeddings.id_\n",
    "\n",
    "# # make a np array of the embeddings\n",
    "# embeddings = np.array(embeddings.embedding.to_list())\n",
    "\n",
    "# clusters_df_ = clusters_df(embeddings)\n",
    "\n",
    "# # set the indices of the clusters_df_ to the same as the embeddings\n",
    "# clusters_df_ = clusters_df_.set_index(ids)\n",
    "\n",
    "# dacc.saves['clusters.parquet'] = clusters_df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imbed_data_prep.eurovis import EurovisDacc\n",
    "\n",
    "# '/Users/thorwhalen/Dropbox/_odata/app_data/imbed/saves/eurovis/vispubs.csv'\n",
    "\n",
    "dacc = EurovisDacc()\n",
    "dacc\n",
    "list(dacc.saves_bytes_store)\n",
    "print(f\"{dacc.raw_data.shape=}\")\n",
    "df = dacc.raw_data\n",
    "\n",
    "df.iloc[0]\n",
    "print(f\"{sum(df['title'].isna())=}\")\n",
    "print(f\"{sum(df['abstract'].isna())=}\")\n",
    "# remove rows with missing title or abstract\n",
    "df = dacc.raw_data.dropna(subset=['title', 'abstract'])\n",
    "\n",
    "# contatenate title and abstract to make segment\n",
    "df['segment'] = '## ' + df['title'] + '\\n\\n' + df.get('abstract')\n",
    "\n",
    "assert not any(df.segment.isna()), \"some segments are NaN\"\n",
    "\n",
    "import oa\n",
    "\n",
    "# apply oa.num_tokens to segment to get n_tokens\n",
    "df['n_tokens'] = df['segment'].apply(oa.num_tokens)\n",
    "max_tokens = oa.util.embeddings_models[oa.base.DFLT_EMBEDDINGS_MODEL]['max_input']\n",
    "assert df['n_tokens'].max() <= max_tokens, \"some segments exceed max tokens\"\n",
    "\n",
    "segments = dict(zip(df.doi, df.segment))\n",
    "assert len(segments) == len(df), \"oops, duplicate DOIs\"\n",
    "assert all(map(oa.text_is_valid, df.segment)), \"some segments are invalid\"\n",
    "len(segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A failed approach to include keys in batch files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This approach to try to store the keys of the segments in the batch files, failed with:\n",
    "# BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'metadata': too many properties. Expected an object with at most 16 properties, but got an object with 250 properties instead.\", 'type': 'invalid_request_error', 'param': 'metadata', 'code': 'object_above_max_properties'}}\n",
    "\n",
    "from oa.stores import OaStores\n",
    "from imbed import fixed_step_chunker\n",
    "from lkj import print_progress, clog as _clog\n",
    "from functools import partial \n",
    "from itertools import count\n",
    "\n",
    "clog = partial(_clog, log_func=print_progress)\n",
    "\n",
    "\n",
    "def length_if_sizable(segments):\n",
    "    if hasattr(segments, '__len__'):\n",
    "        return len(segments)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "\n",
    "def process_segments_batch(batch, *, oa_stores: OaStores=None):\n",
    "    keys, texts = zip(*batch.items())\n",
    "    batch_task = mk_batch_file_embeddings_task(texts)\n",
    "    file_id = oa_stores.json_files.append(batch_task)\n",
    "    batch_id = oa_stores.batches.append(file_id, metadata=dict(zip(count(), keys)))\n",
    "    return batch_id\n",
    "\n",
    "\n",
    "def create_embedding_task_batches(segments, batch_size, *, oa_stores=None, verbose=True):\n",
    "    log = clog(verbose)\n",
    "    if oa_stores is None:\n",
    "        from oa import OaStores\n",
    "        oa_stores = OaStores()\n",
    "\n",
    "    total_length = length_if_sizable(segments)\n",
    "    if total_length is not None:\n",
    "        total_n_batches = int(total_length / batch_size) + 1\n",
    "    else:\n",
    "        total_n_batches = '<size unknown>'\n",
    "\n",
    "    try:\n",
    "        for i, batch in enumerate(fixed_step_chunker(segments.items(), batch_size)):\n",
    "            log(f\"Processing batch {i+1} of {total_n_batches}\")\n",
    "            batch_id = process_segments_batch(dict(batch), oa_stores=s)\n",
    "            yield batch_id\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "# batch_ids = list(\n",
    "#     create_embedding_task_batches(dacc.segments, batch_size=250, verbose=True)\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cache_this extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dol import cache_this\n",
    "\n",
    "trace = []\n",
    "cache = dict()\n",
    "disk = dict()\n",
    "\n",
    "class A:\n",
    "\n",
    "    @cache_this(cache=disk)\n",
    "    def f(self):\n",
    "        trace.append('In f method')\n",
    "        return 42\n",
    "    \n",
    "a = A()\n",
    "\n",
    "assert a.f == 42\n",
    "assert trace == ['In f method']  # proof that the method was called \n",
    "assert disk['f'] == 42  # proof that the result was cached in disk\n",
    "assert a.f == 42  # access the attribute again\n",
    "assert trace == ['In f method']  # proof that the method was NOT called again\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dol import cache_this, CascadedStores\n",
    "\n",
    "trace = []\n",
    "cache = dict()\n",
    "disk = dict(g=8)\n",
    "\n",
    "cascade_cache_this = cache_this(cache=CascadedStores([cache, disk]))\n",
    "\n",
    "class A:\n",
    "\n",
    "    @cascade_cache_this\n",
    "    def f(self):\n",
    "        trace.append('In f method')\n",
    "        return 42\n",
    "    \n",
    "    @cascade_cache_this\n",
    "    def g(self):\n",
    "        trace.append('In g method')\n",
    "    \n",
    "a = A()\n",
    "\n",
    "assert a.f == 42\n",
    "assert trace == ['In f method']  # proof that the method was called \n",
    "assert cache['f'] == 42  # proof that the result was cached in chached_a\n",
    "assert disk['f'] == 42  # proof that the result was cached in chached_b\n",
    "assert a.f == 42  # access the attribute again\n",
    "assert trace == ['In f method']  # proof that the f method was NOT called again\n",
    "\n",
    "assert a.g == 8\n",
    "assert trace == ['In f method']  # proof that the g method was NEVER called (it got the value from disk)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'CachedProperty' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[14], line 17\u001b[0m\n",
      "\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m42\u001b[39m\n",
      "\u001b[1;32m     15\u001b[0m a \u001b[38;5;241m=\u001b[39m A()\n",
      "\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m42\u001b[39m\n",
      "\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m trace \u001b[38;5;241m==\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIn f method\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# proof that the method was called \u001b[39;00m\n",
      "\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m cache_a[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m42\u001b[39m  \u001b[38;5;66;03m# proof that the result was cached in chached_a\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/Dropbox/py/proj/i/dol/dol/tools.py:168\u001b[0m, in \u001b[0;36mCachedProperty.__get__\u001b[0;34m(self, instance, owner)\u001b[0m\n",
      "\u001b[1;32m    166\u001b[0m val \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_key, _NOT_FOUND)\n",
      "\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n",
      "\u001b[0;32m--> 168\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m    170\u001b[0m         cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_key] \u001b[38;5;241m=\u001b[39m val\n",
      "\n",
      "\u001b[0;31mTypeError\u001b[0m: 'CachedProperty' object is not callable"
     ]
    }
   ],
   "source": [
    "from dol import cache_this\n",
    "\n",
    "trace = []\n",
    "cache = dict()\n",
    "disk = dict()\n",
    "\n",
    "\n",
    "class A:\n",
    "\n",
    "    @cache_this(cache=cache)\n",
    "    @cache_this(cache=disk)\n",
    "    def f(self):\n",
    "        trace.append('In f method')\n",
    "        return 42\n",
    "    \n",
    "a = A()\n",
    "\n",
    "assert a.f == 42\n",
    "assert trace == ['In f method']  # proof that the method was called \n",
    "assert cache['f'] == 42  # proof that the result was cached in chached_a\n",
    "assert disk['f'] == 42  # proof that the result was cached in chached_b\n",
    "assert a.f == 42  # access the attribute again\n",
    "assert trace == ['In f method']  # proof that the method was NOT called again\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
