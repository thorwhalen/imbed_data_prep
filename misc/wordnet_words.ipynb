{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordnet words\n",
    "\n",
    "Here's how we made the base dataset. The steps are:\n",
    "* Get a list of most frequent (English) words\n",
    "* Get embeddings for each of these words\n",
    "* Get planar projections for these embeddings\n",
    "* Link the words in various ways (i.e make the link data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set project rootdir here\n",
    "rootdir = \"\"\n",
    "\n",
    "# ... or, if you'll be sharing this notebook, make it so that the rootdir will be entered by the user\n",
    "# and placed in a config file...\n",
    "if not rootdir:\n",
    "    from config2py import config_getter  # pip install config2py\n",
    "\n",
    "    # If the env variable is not set, running this will ask the user to enter the rootdir\n",
    "    # and it will save it for them for future use\n",
    "    rootdir = config_getter('WORDNET_WORDS_PROJECT_ROOTDIR') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imbed_data_prep.wordnet_words import WordsDacc\n",
    "\n",
    "dacc = WordsDacc(rootdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peeking at the WordsDacc data accessor\n",
    "\n",
    "`WordsDacc` is your entry to all dataset items. \n",
    "You instantiate it with a rootdir and then ask for data items. \n",
    "If the data is stored in your cache, it will be given to you from there, \n",
    "if it's not, it will compute it (download, prepare, etc.) and store it for further use. \n",
    "You can always refresh (redownload, re-compute, etc.) any data items simply by deleting the file in your rootdir. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imbed_data_prep.wordnet_words import *\n",
    "\n",
    "dacc = WordsDacc(rootdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two raw source data items we start with. \n",
    "The first is the wordnet words (because wordnet has a bunch of linguistic features for these):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(dacc.wordnet_words)=147306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['acceptation', 'accepted', 'accepting', 'acceptive', 'acceptor']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{len(dacc.wordnet_words)=}\")\n",
    "dacc.wordnet_words[1000:1005]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second is a word frequency dataset (a count of words in a very large corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(333333,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "word\n",
       "the    23135851162\n",
       "of     13151942776\n",
       "and    12997637966\n",
       "to     12136980858\n",
       "a       9081174698\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{dacc.word_counts.shape}\")\n",
    "dacc.word_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the intersection of both datasets as our `word_list`. \n",
    "Note that you could also specify your own `word_list` via an argument of that name when \n",
    "making a `dacc = WordsDacc(..., word_list=[...])` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(dacc.word_list)=52078\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(dacc.word_list)=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the words of `word_list`, the `wordnet_metadata` data is a big dataframe containing a bunch of information on these words. \n",
    "\n",
    "The row is index by a \"lemma\" id. Without going into linguistics theory too much, we should at least mention this: \n",
    "A \"word\" (or \"lemma name\") is a string of characters, but it could have various meanings (indexed here by \"synset\"), and for each of \n",
    "these (word, meaning) combinations (indexed by \"lemma\") therefore, different characteristics (definition, pos (\"part of speech\"), etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123587, 29)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "word                                                            casting\n",
       "synset                                                        cast.v.03\n",
       "example                  He cast a young woman in the role of Desdemona\n",
       "definition            select to play,sing, or dance a part in a play...\n",
       "lexname                                                   verb.creation\n",
       "name                                                          cast.v.03\n",
       "pos                                                                verb\n",
       "attributes                                                           []\n",
       "causes                                                               []\n",
       "entailments                       [film.v.02, perform.v.01, stage.v.01]\n",
       "hypernyms                                               [delegate.v.02]\n",
       "hyponyms                     [recast.v.01, typecast.v.01, miscast.v.01]\n",
       "in_region_domains                                                    []\n",
       "in_topic_domains                                                     []\n",
       "in_usage_domains                                                     []\n",
       "instance_hypernyms                                                   []\n",
       "instance_hyponyms                                                    []\n",
       "member_holonyms                                                      []\n",
       "member_meronyms                                                      []\n",
       "part_holonyms                                                        []\n",
       "part_meronyms                                                        []\n",
       "region_domains                                                       []\n",
       "root_hypernyms                                           [appoint.v.02]\n",
       "similar_tos                                                          []\n",
       "substance_holonyms                                                   []\n",
       "substance_meronyms                                                   []\n",
       "topic_domains                                    [performing_arts.n.01]\n",
       "usage_domains                                                        []\n",
       "verb_groups                                                 [cast.v.05]\n",
       "Name: cast.v.03.casting, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = dacc.wordnet_metadata\n",
    "print(f\"{meta.shape}\")\n",
    "meta.loc['cast.v.03.casting']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at what different POS ([part-of-speech](https://www.geeksforgeeks.org/nlp-part-of-speech-default-tagging/))\n",
    "categories we have in this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos\n",
       "noun                   64228\n",
       "verb                   34733\n",
       "adjective_satellite    14108\n",
       "adjective               6989\n",
       "adverb                  3529\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.pos.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used an OpenAI embeddings model to compute the embeddings of each (individual) word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dacc.words_embeddings.shape=(52078, 1)\n",
      "Vector size: 1536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "embedding    [0.02674213983118534, 0.008698769845068455, -0...\n",
       "Name: a, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{dacc.words_embeddings.shape=}\")\n",
    "print(f\"Vector size: {len(dacc.words_embeddings.iloc[0].embedding)}\")\n",
    "dacc.words_embeddings.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then can get a planar embedding of these multi-dimensional vectors using all kinds of methods.\n",
    "\n",
    "Here we use UMAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>umap_x</th>\n",
       "      <th>umap_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abnormal</th>\n",
       "      <td>0.814811</td>\n",
       "      <td>9.603489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abnormality</th>\n",
       "      <td>0.899243</td>\n",
       "      <td>9.588635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abnormally</th>\n",
       "      <td>0.872207</td>\n",
       "      <td>9.655293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abo</th>\n",
       "      <td>2.871932</td>\n",
       "      <td>3.976475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aboard</th>\n",
       "      <td>0.326998</td>\n",
       "      <td>5.151422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               umap_x    umap_y\n",
       "word                           \n",
       "abnormal     0.814811  9.603489\n",
       "abnormality  0.899243  9.588635\n",
       "abnormally   0.872207  9.655293\n",
       "abo          2.871932  3.976475\n",
       "aboard       0.326998  5.151422"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dacc.umap_embeddings.iloc[100:105]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `words_and_features` joins a bunch of these data aspects together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dacc.wordnet_feature_meta.shape=(123587, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "word                                                          a\n",
       "frequency                                              0.015441\n",
       "definition    a metric unit of length equal to one ten billi...\n",
       "lexname                                           noun.quantity\n",
       "name                                              angstrom.n.01\n",
       "pos                                                        noun\n",
       "umap_x                                                 3.027916\n",
       "umap_y                                                 3.760965\n",
       "Name: angstrom.n.01.a, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{dacc.wordnet_feature_meta.shape=}\")\n",
    "dacc.wordnet_feature_meta.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making link data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the metadata items we have are lists of synsets (often empty). \n",
    "These have been accessed via the `wordnet_collection_meta` dataframe\n",
    "and can be used to connect some synsets to other synsets, therefore some words to other words.\n",
    "\n",
    "In WordNet, a **synset** (short for \"synonym set\") is a group of words that share the same meaning or concept. Think of it as a cluster of synonyms that can be used interchangeably in certain contexts without changing the overall meaning. For example, the words \"happy,\" \"joyful,\" and \"elated\" might belong to the same synset because they convey similar emotions.\n",
    "\n",
    "The synset relationships are as follows:\n",
    "\n",
    "* **attributes**: These are qualities or characteristics associated with a synset. *Example*: For the synset representing \"banana,\" an attribute might be \"yellow.\"\n",
    "* **causes**: This relationship indicates that one synset brings about or results in another. *Example*: \"Tickling\" (synset) causes \"laughter\" (synset).\n",
    "* **entailments**: Primarily used for verbs, this relationship means that one action logically necessitates another. *Example*: If someone is \"snoring,\" it entails that they are \"sleeping.\"\n",
    "* **hypernyms**: A hypernym is a more general term that encompasses more specific instances. *Example*: \"Vehicle\" is a hypernym of \"car.\"\n",
    "* **hyponyms**: A hyponym is a more specific term within a broader category. *Example*: \"Poodle\" is a hyponym of \"dog.\"\n",
    "* **in_region_domains**: This denotes the regional usage of a synset, indicating where a term is commonly used. *Example*: The term \"biscuit\" in British English refers to what Americans call a \"cookie.\"\n",
    "* **in_topic_domains**: This shows the subject area or field to which a synset belongs. *Example*: The term \"quantum\" belongs to the domain of physics.\n",
    "* **in_usage_domains**: This indicates the context or manner in which a term is used. *Example*: \"LOL\" is used in informal, internet communication.\n",
    "* **instance_hypernyms**: This relationship links a specific instance to its general category. *Example*: \"Einstein\" is an instance of the hypernym \"physicist.\"\n",
    "* **instance_hyponyms**: This connects a general category to its specific instances. *Example*: \"Physicist\" has instance hyponyms like \"Einstein\" and \"Newton.\"\n",
    "* **member_holonyms**: This indicates the whole to which a member belongs. *Example*: A \"tree\" is a member of the holonym \"forest.\"\n",
    "* **member_meronyms**: This shows the members that constitute a collective whole. *Example*: \"Player\" is a member meronym of \"team.\"\n",
    "* **part_holonyms**: This denotes the whole object that a part belongs to. *Example*: A \"wheel\" is part of the holonym \"car.\"\n",
    "* **part_meronyms**: This indicates the parts that make up a whole object. *Example*: \"Keyboard\" is a part meronym of \"computer.\"\n",
    "* **region_domains**: This specifies the geographical area where a term is used. *Example*: \"G'day\" is used in the region domain of Australia.\n",
    "* **root_hypernyms**: This refers to the most general term in a hierarchy. *Example*: For \"poodle,\" the root hypernym might be \"entity.\"\n",
    "* **similar_tos**: This indicates synsets that are similar in meaning. *Example*: \"Big\" is similar to \"large.\"\n",
    "* **substance_holonyms**: This shows the whole that a substance is part of. *Example*: \"Flour\" is a substance holonym of \"bread.\"\n",
    "* **substance_meronyms**: This indicates the substances that make up a whole. *Example*: \"Alcohol\" is a substance meronym of \"wine.\"\n",
    "* **topic_domains**: This denotes the subject area a term is associated with. *Example*: \"Molecule\" belongs to the topic domain of chemistry.\n",
    "* **usage_domains**: This specifies the context in which a term is appropriately used. *Example*: \"Thou\" is used in archaic or poetic contexts.\n",
    "* **verb_groups**: This links verbs that are similar in meaning or usage. *Example*: \"Run\" and \"jog\" might be in the same verb group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imbed_data_prep.wordnet_words import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "attributes                                                    []\n",
       "causes                                                        []\n",
       "entailments                [film.v.02, perform.v.01, stage.v.01]\n",
       "hypernyms                                        [delegate.v.02]\n",
       "hyponyms              [recast.v.01, typecast.v.01, miscast.v.01]\n",
       "in_region_domains                                             []\n",
       "in_topic_domains                                              []\n",
       "in_usage_domains                                              []\n",
       "instance_hypernyms                                            []\n",
       "instance_hyponyms                                             []\n",
       "member_holonyms                                               []\n",
       "member_meronyms                                               []\n",
       "part_holonyms                                                 []\n",
       "part_meronyms                                                 []\n",
       "region_domains                                                []\n",
       "root_hypernyms                                    [appoint.v.02]\n",
       "similar_tos                                                   []\n",
       "substance_holonyms                                            []\n",
       "substance_meronyms                                            []\n",
       "topic_domains                             [performing_arts.n.01]\n",
       "usage_domains                                                 []\n",
       "verb_groups                                          [cast.v.05]\n",
       "Name: cast.v.03.casting, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_meta = dacc.wordnet_collection_meta\n",
    "collection_meta.loc['cast.v.03.casting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for relationship_name in dacc.wordnet_collection_meta.columns:\n",
    "    adjacencies = dacc.wordnet_collection_meta[relationship_name]\n",
    "    link_data = pd.DataFrame(dacc.lemma_graph_edges(adjacencies))\n",
    "    dacc.df_files[f\"link_data/{relationship_name}.parquet\"] = link_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get data from remote source\n",
    "\n",
    "from imbed_data_prep.wordnet_words import WordsDacc\n",
    "\n",
    "rootdir = __import__('config2py').config_getter('WORDNET_WORDS_PROJECT_ROOTDIR') \n",
    "\n",
    "dacc = WordsDacc(rootdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cosmograph import cosmo\n",
    "\n",
    "# help(cosmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['attributes', 'causes', 'entailments', 'hypernyms', 'hyponyms',\n",
      "       'in_region_domains', 'in_topic_domains', 'in_usage_domains',\n",
      "       'instance_hypernyms', 'instance_hyponyms', 'member_holonyms',\n",
      "       'member_meronyms', 'part_holonyms', 'part_meronyms', 'region_domains',\n",
      "       'root_hypernyms', 'similar_tos', 'substance_holonyms',\n",
      "       'substance_meronyms', 'topic_domains', 'usage_domains', 'verb_groups'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(dacc.wordnet_collection_meta.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deoxyadenosine_monophosphate.n.01.a</td>\n",
       "      <td>nucleotide.n.01.nucleotide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deoxyadenosine_monophosphate.n.01.a</td>\n",
       "      <td>nucleotide.n.01.base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adenine.n.01.a</td>\n",
       "      <td>purine.n.01.purine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                source                      target\n",
       "0  deoxyadenosine_monophosphate.n.01.a  nucleotide.n.01.nucleotide\n",
       "1  deoxyadenosine_monophosphate.n.01.a        nucleotide.n.01.base\n",
       "2                       adenine.n.01.a          purine.n.01.purine"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relationship_name = 'hypernyms'\n",
    "df = dacc.df_files[f\"link_data/{relationship_name}.parquet\"]\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmo(links=df, link_source_by='source', link_target_by='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "PackageNotFoundError",
     "evalue": "No package metadata was found for cosmograph",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPackageNotFoundError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetadata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version, PackageNotFoundError\n\u001b[0;32m----> 4\u001b[0m \u001b[43mversion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcosmograph\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/importlib/metadata/__init__.py:996\u001b[0m, in \u001b[0;36mversion\u001b[0;34m(distribution_name)\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mversion\u001b[39m(distribution_name):\n\u001b[1;32m    990\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the version string for the named package.\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \n\u001b[1;32m    992\u001b[0m \u001b[38;5;124;03m    :param distribution_name: The name of the distribution package to query.\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;124;03m    :return: The version string for the package as defined in the package's\u001b[39;00m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;124;03m        \"Version\" metadata key.\u001b[39;00m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 996\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdistribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistribution_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mversion\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/importlib/metadata/__init__.py:969\u001b[0m, in \u001b[0;36mdistribution\u001b[0;34m(distribution_name)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdistribution\u001b[39m(distribution_name):\n\u001b[1;32m    964\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the ``Distribution`` instance for the named package.\u001b[39;00m\n\u001b[1;32m    965\u001b[0m \n\u001b[1;32m    966\u001b[0m \u001b[38;5;124;03m    :param distribution_name: The name of the distribution package as a string.\u001b[39;00m\n\u001b[1;32m    967\u001b[0m \u001b[38;5;124;03m    :return: A ``Distribution`` instance (or subclass thereof).\u001b[39;00m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 969\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistribution_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/importlib/metadata/__init__.py:548\u001b[0m, in \u001b[0;36mDistribution.from_name\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m dist\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 548\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PackageNotFoundError(name)\n",
      "\u001b[0;31mPackageNotFoundError\u001b[0m: No package metadata was found for cosmograph"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version, PackageNotFoundError\n",
    "\n",
    "\n",
    "version(\"cosmograph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "definition    a metric unit of length equal to one ten billi...\n",
       "lexname                                           noun.quantity\n",
       "name                                              angstrom.n.01\n",
       "pos                                                        noun\n",
       "Name: angstrom.n.01.a, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = dacc.wordnet_feature_meta\n",
    "t.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word                                                                  a\n",
       "count                                                        9081174698\n",
       "lemma                                                   angstrom.n.01.a\n",
       "synset                                                    angstrom.n.01\n",
       "example                                                                \n",
       "definition            a metric unit of length equal to one ten billi...\n",
       "lexname                                                   noun.quantity\n",
       "name                                                      angstrom.n.01\n",
       "pos                                                                noun\n",
       "attributes                                                           []\n",
       "causes                                                               []\n",
       "entailments                                                          []\n",
       "hypernyms                                     [metric_linear_unit.n.01]\n",
       "hyponyms                                                             []\n",
       "in_region_domains                                                    []\n",
       "in_topic_domains                                                     []\n",
       "in_usage_domains                                                     []\n",
       "instance_hypernyms                                                   []\n",
       "instance_hyponyms                                                    []\n",
       "member_holonyms                                                      []\n",
       "member_meronyms                                                      []\n",
       "part_holonyms                                          [nanometer.n.01]\n",
       "part_meronyms                                          [picometer.n.01]\n",
       "region_domains                                                       []\n",
       "root_hypernyms                                            [entity.n.01]\n",
       "similar_tos                                                          []\n",
       "substance_holonyms                                                   []\n",
       "substance_meronyms                                                   []\n",
       "topic_domains                                                        []\n",
       "usage_domains                                                        []\n",
       "verb_groups                                                          []\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge the wordnet metadata with the word counts\n",
    "word_counts = dacc.word_counts.reset_index().rename(columns={'index': 'word'})\n",
    "wordnet_metadata = dacc.wordnet_metadata\n",
    "wordnet_metadata = wordnet_metadata.reset_index().rename(columns={'index': 'word'})\n",
    "# # word_counts.merge(wordnet_metadata, on='word', how='left')\n",
    "t = pd.merge(word_counts, wordnet_metadata, on='word')\n",
    "t.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['word', 'definition', 'lexname', 'name', 'pos']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imbed_data_prep.wordnet_words import *\n",
    "wordnet_feature_attr_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function cosmo in module cosmograph.base:\n",
      "\n",
      "cosmo(data=None, *, disable_simulation: bool = False, simulation_decay: float = 1000, simulation_gravity: float = 0, simulation_center: float = 0, simulation_repulsion: float = 0.1, simulation_repulsion_theta: float = 1.7, simulation_repulsion_quadtree_levels: float = 12, simulation_link_spring: float = 1, simulation_link_distance: float = 2, simulation_link_dist_random_variation_range: list[typing.Any] = [1, 1.2], simulation_repulsion_from_mouse: float = 2, simulation_friction: float = 0.85, simulation_cluster: float = None, background_color: Union[str, list[float]] = '#222222', space_size: int = 4096, point_color: Union[str, list[float]] = '#b3b3b3', point_greyout_opacity: float = 0.1, point_size: float = 4, point_size_scale: float = 1, hovered_point_cursor: str = None, render_hovered_point_ring: bool = 0.7, hovered_point_ring_color: Union[str, list[float]] = 'white', focused_point_ring_color: Union[str, list[float]] = 0.95, focused_point_index: int = None, render_links: bool = True, link_color: Union[str, list[float]] = '#666666', link_greyout_opacity: float = 0.1, link_width: float = 1, link_width_scale: float = 1, curved_links: bool = False, curved_link_segments: int = 19, curved_link_weight: float = 0.8, curved_link_control_point_distance: float = 0.5, link_arrows: bool = None, link_arrows_size_scale: float = 1, link_visibility_distance_range: list[float] = [50, 150], link_visibility_min_transparency: float = 0.25, use_quadtree: bool = False, show_FPS_monitor: bool = False, pixel_ratio: float = 2, scale_points_on_zoom: bool = True, initial_zoom_level: float = 3, disable_zoom: bool = False, enable_drag: bool = None, fit_view_on_init: bool = True, fit_view_delay: float = 250, fit_view_padding: float = None, fit_view_duration: float = None, fit_view_by_points_in_rect: list[list[float]] = None, random_seed: Union[int, str] = None, point_sampling_distance: int = 150, point_id_by: str = None, point_index_by: str = None, point_color_by: str = None, point_size_by: str = None, point_size_range: list[float] = None, point_label_by: str = None, point_label_weight_by: str = None, point_x_by: str = None, point_y_by: str = None, point_cluster_by: str = None, point_cluster_strength_by: str = None, point_include_columns: list[str] = None, link_source_by: str = None, link_source_index_by: str = None, link_target_by: str = None, link_target_index_by: str = None, link_color_by: str = None, link_width_by: str = None, link_arrow_by: str = None, link_strength_by: str = None, link_strength_range: list[float] = None, link_include_columns: list[str] = None, show_labels: bool = None, show_dynamic_labels: bool = None, show_labels_for: list[str] = None, show_top_labels: bool = None, show_top_labels_limit: int = None, show_top_labels_by: str = None, static_label_weight: float = None, dynamic_label_weight: float = None, label_margin: float = None, show_hovered_point_label: bool = None, disable_point_size_legend: bool = None, disable_link_width_legend: bool = None, disable_point_color_legend: bool = None, disable_link_color_legend: bool = None, points: object = None, links: object = None, clicked_point_index: int = None, clicked_point_id: str = None, selected_point_indices: list[int] = None, selected_point_ids: list[str] = None, changePoints: Callable[[Dict[str, Any]], Any] = None, changeLinks: Callable[[Dict[str, Any]], Any] = None)\n",
      "        Thin layer over CosmographWidget to provide a base interface to the widget object\n",
      "        \n",
      "    Parameters\n",
      "    ----------\n",
      "    disable_simulation : bool, default=False\n",
      "        Prevents the simulation from running, merely rendering the graph.\n",
      "    simulation_decay : float, default=1000\n",
      "        Defines how quickly the simulation cools down.\n",
      "    simulation_gravity : float, default=0\n",
      "        Coefficient for gravity force.\n",
      "    simulation_center : float, default=0\n",
      "        Centers the mass force coefficient.\n",
      "    simulation_repulsion : float, default=0.1\n",
      "        Configures point repulsion between points.\n",
      "    simulation_repulsion_theta : float, default=1.7\n",
      "        Decreases / increases the detalization of the Many-Body force calculations.\n",
      "    simulation_repulsion_quadtree_levels : float, default=12\n",
      "        Barnes–Hut approximation depth, usable when useQuadtree is set to True.\n",
      "    simulation_link_spring : float, default=1\n",
      "        Spring constant for links.\n",
      "    simulation_link_distance : float, default=2\n",
      "        Default distance for links.\n",
      "    simulation_link_dist_random_variation_range : list, default=[1, 1.2]\n",
      "        Random link distance range.\n",
      "    simulation_repulsion_from_mouse : float, default=2\n",
      "        Mouse position repulsion coefficient, activated by right-click.\n",
      "    simulation_friction : float, default=0.85\n",
      "        Sets simulation friction.\n",
      "    simulation_cluster : float, default=None\n",
      "        \n",
      "    background_color : typing.Union[str, list[float]], default=\"#222222\"\n",
      "        Canvas background color.\n",
      "    space_size : int, default=4096\n",
      "        Size of the simulation space.\n",
      "    point_color : typing.Union[str, list[float]], default=\"#b3b3b3\"\n",
      "        Column name for point colors.\n",
      "    point_greyout_opacity : float, default=0.1\n",
      "        Opacity of unselected nodes during selection.\n",
      "    point_size : float, default=4\n",
      "        Column name for point sizes.\n",
      "    point_size_scale : float, default=1\n",
      "        Scale factor for point sizes.\n",
      "    hovered_point_cursor : str, default=None\n",
      "        Cursor type when hovering over a point.\n",
      "    render_hovered_point_ring : bool, default=0.7\n",
      "        Enables ring around hovered points.\n",
      "    hovered_point_ring_color : typing.Union[str, list[float]], default=\"white\"\n",
      "        Color of hovered point ring.\n",
      "    focused_point_ring_color : typing.Union[str, list[float]], default=0.95\n",
      "        Color of the focused point ring.\n",
      "    focused_point_index : int, default=None\n",
      "        Index of the focused point, prioritized over focus_point method.\n",
      "    render_links : bool, default=True\n",
      "        Enables or disables link rendering.\n",
      "    link_color : typing.Union[str, list[float]], default=\"#666666\"\n",
      "        Column name for link colors.\n",
      "    link_greyout_opacity : float, default=0.1\n",
      "        Opacity of unselected links during selection.\n",
      "    link_width : float, default=1\n",
      "        Column name for link widths.\n",
      "    link_width_scale : float, default=1\n",
      "        Scale factor for link widths.\n",
      "    curved_links : bool, default=False\n",
      "        Enables or disables curved links.\n",
      "    curved_link_segments : int, default=19\n",
      "        Segments defining curved links.\n",
      "    curved_link_weight : float, default=0.8\n",
      "        Weight factor for link curvature.\n",
      "    curved_link_control_point_distance : float, default=0.5\n",
      "        Control point positioning for curves.\n",
      "    link_arrows : bool, default=None\n",
      "        \n",
      "    link_arrows_size_scale : float, default=1\n",
      "        Scale factor for link arrow size.\n",
      "    link_visibility_distance_range : list, default=[50, 150]\n",
      "        Pixel distance range for link transparency.\n",
      "    link_visibility_min_transparency : float, default=0.25\n",
      "        Minimum transparency of links based on link_visibility_distance_range.\n",
      "    use_quadtree : bool, default=False\n",
      "        Activates quadtree algorithm for Many-Body force when set to True.\n",
      "    show_FPS_monitor : bool, default=False\n",
      "        Display an FPS counter in the upper right corner of the canvas.\n",
      "    pixel_ratio : float, default=2\n",
      "        Canvas pixel ratio.\n",
      "    scale_points_on_zoom : bool, default=True\n",
      "        Scales point sizes when zooming.\n",
      "    initial_zoom_level : float, default=3\n",
      "        Starting zoom level.\n",
      "    disable_zoom : bool, default=False\n",
      "        Enables or disables zooming.\n",
      "    enable_drag : bool, default=None\n",
      "        Allows graph dragging.\n",
      "    fit_view_on_init : bool, default=True\n",
      "        Automatically fits view to all points upon initialization.\n",
      "    fit_view_delay : float, default=250\n",
      "        Delay for fitting view after initialization in milliseconds.\n",
      "    fit_view_padding : float, default=None\n",
      "        Padding around fit view area.\n",
      "    fit_view_duration : float, default=None\n",
      "        Animation duration for view fitting in milliseconds.\n",
      "    fit_view_by_points_in_rect : list, default=None\n",
      "        Fits view to specified rectangle of points, active when fit_view_on_init is True.\n",
      "    random_seed : typing.Union[int, str], default=None\n",
      "        Seed value for generating random numbers in simulations.\n",
      "    point_sampling_distance : int, default=150\n",
      "        Distance threshold for sampling points.\n",
      "    point_id_by : str, default=None\n",
      "        \n",
      "    point_index_by : str, default=None\n",
      "        \n",
      "    point_color_by : str, default=None\n",
      "        \n",
      "    point_size_by : str, default=None\n",
      "        \n",
      "    point_size_range : list, default=None\n",
      "        \n",
      "    point_label_by : str, default=None\n",
      "        \n",
      "    point_label_weight_by : str, default=None\n",
      "        \n",
      "    point_x_by : str, default=None\n",
      "        \n",
      "    point_y_by : str, default=None\n",
      "        \n",
      "    point_cluster_by : str, default=None\n",
      "        \n",
      "    point_cluster_strength_by : str, default=None\n",
      "        \n",
      "    point_include_columns : list, default=None\n",
      "        An array of additional column names to include in point data.\n",
      "    link_source_by : str, default=None\n",
      "        \n",
      "    link_source_index_by : str, default=None\n",
      "        \n",
      "    link_target_by : str, default=None\n",
      "        \n",
      "    link_target_index_by : str, default=None\n",
      "        \n",
      "    link_color_by : str, default=None\n",
      "        \n",
      "    link_width_by : str, default=None\n",
      "        \n",
      "    link_arrow_by : str, default=None\n",
      "        \n",
      "    link_strength_by : str, default=None\n",
      "        \n",
      "    link_strength_range : list, default=None\n",
      "        \n",
      "    link_include_columns : list, default=None\n",
      "        An array of additional column names to include in link data.\n",
      "    show_labels : bool, default=None\n",
      "        \n",
      "    show_dynamic_labels : bool, default=None\n",
      "        Flag to show dynamic labels for visible points.\n",
      "    show_labels_for : list, default=None\n",
      "        An array of point ids for which to show labels.\n",
      "    show_top_labels : bool, default=None\n",
      "        Flag to display labels for the top points.\n",
      "    show_top_labels_limit : int, default=None\n",
      "        Maximum number of top points to show labels for.\n",
      "    show_top_labels_by : str, default=None\n",
      "        Column to determine which points are considered as a top.\n",
      "    static_label_weight : float, default=None\n",
      "        Weight of static labels.\n",
      "    dynamic_label_weight : float, default=None\n",
      "        Weight of dynamic labels.\n",
      "    label_margin : float, default=None\n",
      "        \n",
      "    show_hovered_point_label : bool, default=None\n",
      "        Flag to display the label for the currently hovered point.\n",
      "    disable_point_size_legend : bool, default=None\n",
      "        \n",
      "    disable_link_width_legend : bool, default=None\n",
      "        \n",
      "    disable_point_color_legend : bool, default=None\n",
      "        \n",
      "    disable_link_color_legend : bool, default=None\n",
      "        \n",
      "    points : object, default=None\n",
      "        Data in a pandas DataFrame format.\n",
      "    links : object, default=None\n",
      "        Data in a pandas DataFrame format.\n",
      "    clicked_point_index : int, default=None\n",
      "        \n",
      "    clicked_point_id : str, default=None\n",
      "        \n",
      "    selected_point_indices : list, default=None\n",
      "        \n",
      "    selected_point_ids : list, default=None\n",
      "        \n",
      "    changePoints : typing.Callable[[typing.Dict[str, typing.Any]], typing.Any], default=None\n",
      "        \n",
      "    changeLinks : typing.Callable[[typing.Dict[str, typing.Any]], typing.Any], default=None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cosmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function cosmo in module cosmograph.base:\n",
      "\n",
      "cosmo(data=None, *, disable_simulation: bool = False, simulation_decay: float = 1000, simulation_gravity: float = 0, simulation_center: float = 0, simulation_repulsion: float = 0.1, simulation_repulsion_theta: float = 1.7, simulation_repulsion_quadtree_levels: float = 12, simulation_link_spring: float = 1, simulation_link_distance: float = 2, simulation_link_dist_random_variation_range: list[typing.Any] = [1, 1.2], simulation_repulsion_from_mouse: float = 2, simulation_friction: float = 0.85, simulation_cluster: float = None, background_color: Union[str, list[float]] = '#222222', space_size: int = 4096, point_color: Union[str, list[float]] = '#b3b3b3', point_greyout_opacity: float = 0.1, point_size: float = 4, point_size_scale: float = 1, hovered_point_cursor: str = None, render_hovered_point_ring: bool = 0.7, hovered_point_ring_color: Union[str, list[float]] = 'white', focused_point_ring_color: Union[str, list[float]] = 0.95, focused_point_index: int = None, render_links: bool = True, link_color: Union[str, list[float]] = '#666666', link_greyout_opacity: float = 0.1, link_width: float = 1, link_width_scale: float = 1, curved_links: bool = False, curved_link_segments: int = 19, curved_link_weight: float = 0.8, curved_link_control_point_distance: float = 0.5, link_arrows: bool = None, link_arrows_size_scale: float = 1, link_visibility_distance_range: list[float] = [50, 150], link_visibility_min_transparency: float = 0.25, use_quadtree: bool = False, show_FPS_monitor: bool = False, pixel_ratio: float = 2, scale_points_on_zoom: bool = True, initial_zoom_level: float = 3, disable_zoom: bool = False, enable_drag: bool = None, fit_view_on_init: bool = True, fit_view_delay: float = 250, fit_view_padding: float = None, fit_view_duration: float = None, fit_view_by_points_in_rect: list[list[float]] = None, random_seed: Union[int, str] = None, point_sampling_distance: int = 150, point_id_by: str = None, point_index_by: str = None, point_color_by: str = None, point_size_by: str = None, point_size_range: list[float] = None, point_label_by: str = None, point_label_weight_by: str = None, point_x_by: str = None, point_y_by: str = None, point_cluster_by: str = None, point_cluster_strength_by: str = None, point_include_columns: list[str] = None, link_source_by: str = None, link_source_index_by: str = None, link_target_by: str = None, link_target_index_by: str = None, link_color_by: str = None, link_width_by: str = None, link_arrow_by: str = None, link_strength_by: str = None, link_strength_range: list[float] = None, link_include_columns: list[str] = None, show_labels: bool = None, show_dynamic_labels: bool = None, show_labels_for: list[str] = None, show_top_labels: bool = None, show_top_labels_limit: int = None, show_top_labels_by: str = None, static_label_weight: float = None, dynamic_label_weight: float = None, label_margin: float = None, show_hovered_point_label: bool = None, disable_point_size_legend: bool = None, disable_link_width_legend: bool = None, disable_point_color_legend: bool = None, disable_link_color_legend: bool = None, points: object = None, links: object = None, clicked_point_index: int = None, clicked_point_id: str = None, selected_point_indices: list[int] = None, selected_point_ids: list[str] = None, changePoints: Callable[[Dict[str, Any]], Any] = None, changeLinks: Callable[[Dict[str, Any]], Any] = None)\n",
      "        Thin layer over CosmographWidget to provide a base interface to the widget object\n",
      "        \n",
      "    Parameters\n",
      "    ----------\n",
      "    disable_simulation : bool, default=False\n",
      "        Prevents the simulation from running, merely rendering the graph.\n",
      "    simulation_decay : float, default=1000\n",
      "        Defines how quickly the simulation cools down.\n",
      "    simulation_gravity : float, default=0\n",
      "        Coefficient for gravity force.\n",
      "    simulation_center : float, default=0\n",
      "        Centers the mass force coefficient.\n",
      "    simulation_repulsion : float, default=0.1\n",
      "        Configures point repulsion between points.\n",
      "    simulation_repulsion_theta : float, default=1.7\n",
      "        Decreases / increases the detalization of the Many-Body force calculations.\n",
      "    simulation_repulsion_quadtree_levels : float, default=12\n",
      "        Barnes–Hut approximation depth, usable when useQuadtree is set to True.\n",
      "    simulation_link_spring : float, default=1\n",
      "        Spring constant for links.\n",
      "    simulation_link_distance : float, default=2\n",
      "        Default distance for links.\n",
      "    simulation_link_dist_random_variation_range : list, default=[1, 1.2]\n",
      "        Random link distance range.\n",
      "    simulation_repulsion_from_mouse : float, default=2\n",
      "        Mouse position repulsion coefficient, activated by right-click.\n",
      "    simulation_friction : float, default=0.85\n",
      "        Sets simulation friction.\n",
      "    simulation_cluster : float, default=None\n",
      "        \n",
      "    background_color : typing.Union[str, list[float]], default=\"#222222\"\n",
      "        Canvas background color.\n",
      "    space_size : int, default=4096\n",
      "        Size of the simulation space.\n",
      "    point_color : typing.Union[str, list[float]], default=\"#b3b3b3\"\n",
      "        Column name for point colors.\n",
      "    point_greyout_opacity : float, default=0.1\n",
      "        Opacity of unselected nodes during selection.\n",
      "    point_size : float, default=4\n",
      "        Column name for point sizes.\n",
      "    point_size_scale : float, default=1\n",
      "        Scale factor for point sizes.\n",
      "    hovered_point_cursor : str, default=None\n",
      "        Cursor type when hovering over a point.\n",
      "    render_hovered_point_ring : bool, default=0.7\n",
      "        Enables ring around hovered points.\n",
      "    hovered_point_ring_color : typing.Union[str, list[float]], default=\"white\"\n",
      "        Color of hovered point ring.\n",
      "    focused_point_ring_color : typing.Union[str, list[float]], default=0.95\n",
      "        Color of the focused point ring.\n",
      "    focused_point_index : int, default=None\n",
      "        Index of the focused point, prioritized over focus_point method.\n",
      "    render_links : bool, default=True\n",
      "        Enables or disables link rendering.\n",
      "    link_color : typing.Union[str, list[float]], default=\"#666666\"\n",
      "        Column name for link colors.\n",
      "    link_greyout_opacity : float, default=0.1\n",
      "        Opacity of unselected links during selection.\n",
      "    link_width : float, default=1\n",
      "        Column name for link widths.\n",
      "    link_width_scale : float, default=1\n",
      "        Scale factor for link widths.\n",
      "    curved_links : bool, default=False\n",
      "        Enables or disables curved links.\n",
      "    curved_link_segments : int, default=19\n",
      "        Segments defining curved links.\n",
      "    curved_link_weight : float, default=0.8\n",
      "        Weight factor for link curvature.\n",
      "    curved_link_control_point_distance : float, default=0.5\n",
      "        Control point positioning for curves.\n",
      "    link_arrows : bool, default=None\n",
      "        \n",
      "    link_arrows_size_scale : float, default=1\n",
      "        Scale factor for link arrow size.\n",
      "    link_visibility_distance_range : list, default=[50, 150]\n",
      "        Pixel distance range for link transparency.\n",
      "    link_visibility_min_transparency : float, default=0.25\n",
      "        Minimum transparency of links based on link_visibility_distance_range.\n",
      "    use_quadtree : bool, default=False\n",
      "        Activates quadtree algorithm for Many-Body force when set to True.\n",
      "    show_FPS_monitor : bool, default=False\n",
      "        Display an FPS counter in the upper right corner of the canvas.\n",
      "    pixel_ratio : float, default=2\n",
      "        Canvas pixel ratio.\n",
      "    scale_points_on_zoom : bool, default=True\n",
      "        Scales point sizes when zooming.\n",
      "    initial_zoom_level : float, default=3\n",
      "        Starting zoom level.\n",
      "    disable_zoom : bool, default=False\n",
      "        Enables or disables zooming.\n",
      "    enable_drag : bool, default=None\n",
      "        Allows graph dragging.\n",
      "    fit_view_on_init : bool, default=True\n",
      "        Automatically fits view to all points upon initialization.\n",
      "    fit_view_delay : float, default=250\n",
      "        Delay for fitting view after initialization in milliseconds.\n",
      "    fit_view_padding : float, default=None\n",
      "        Padding around fit view area.\n",
      "    fit_view_duration : float, default=None\n",
      "        Animation duration for view fitting in milliseconds.\n",
      "    fit_view_by_points_in_rect : list, default=None\n",
      "        Fits view to specified rectangle of points, active when fit_view_on_init is True.\n",
      "    random_seed : typing.Union[int, str], default=None\n",
      "        Seed value for generating random numbers in simulations.\n",
      "    point_sampling_distance : int, default=150\n",
      "        Distance threshold for sampling points.\n",
      "    point_id_by : str, default=None\n",
      "        \n",
      "    point_index_by : str, default=None\n",
      "        \n",
      "    point_color_by : str, default=None\n",
      "        \n",
      "    point_size_by : str, default=None\n",
      "        \n",
      "    point_size_range : list, default=None\n",
      "        \n",
      "    point_label_by : str, default=None\n",
      "        \n",
      "    point_label_weight_by : str, default=None\n",
      "        \n",
      "    point_x_by : str, default=None\n",
      "        \n",
      "    point_y_by : str, default=None\n",
      "        \n",
      "    point_cluster_by : str, default=None\n",
      "        \n",
      "    point_cluster_strength_by : str, default=None\n",
      "        \n",
      "    point_include_columns : list, default=None\n",
      "        An array of additional column names to include in point data.\n",
      "    link_source_by : str, default=None\n",
      "        \n",
      "    link_source_index_by : str, default=None\n",
      "        \n",
      "    link_target_by : str, default=None\n",
      "        \n",
      "    link_target_index_by : str, default=None\n",
      "        \n",
      "    link_color_by : str, default=None\n",
      "        \n",
      "    link_width_by : str, default=None\n",
      "        \n",
      "    link_arrow_by : str, default=None\n",
      "        \n",
      "    link_strength_by : str, default=None\n",
      "        \n",
      "    link_strength_range : list, default=None\n",
      "        \n",
      "    link_include_columns : list, default=None\n",
      "        An array of additional column names to include in link data.\n",
      "    show_labels : bool, default=None\n",
      "        \n",
      "    show_dynamic_labels : bool, default=None\n",
      "        Flag to show dynamic labels for visible points.\n",
      "    show_labels_for : list, default=None\n",
      "        An array of point ids for which to show labels.\n",
      "    show_top_labels : bool, default=None\n",
      "        Flag to display labels for the top points.\n",
      "    show_top_labels_limit : int, default=None\n",
      "        Maximum number of top points to show labels for.\n",
      "    show_top_labels_by : str, default=None\n",
      "        Column to determine which points are considered as a top.\n",
      "    static_label_weight : float, default=None\n",
      "        Weight of static labels.\n",
      "    dynamic_label_weight : float, default=None\n",
      "        Weight of dynamic labels.\n",
      "    label_margin : float, default=None\n",
      "        \n",
      "    show_hovered_point_label : bool, default=None\n",
      "        Flag to display the label for the currently hovered point.\n",
      "    disable_point_size_legend : bool, default=None\n",
      "        \n",
      "    disable_link_width_legend : bool, default=None\n",
      "        \n",
      "    disable_point_color_legend : bool, default=None\n",
      "        \n",
      "    disable_link_color_legend : bool, default=None\n",
      "        \n",
      "    points : object, default=None\n",
      "        Data in a pandas DataFrame format.\n",
      "    links : object, default=None\n",
      "        Data in a pandas DataFrame format.\n",
      "    clicked_point_index : int, default=None\n",
      "        \n",
      "    clicked_point_id : str, default=None\n",
      "        \n",
      "    selected_point_indices : list, default=None\n",
      "        \n",
      "    selected_point_ids : list, default=None\n",
      "        \n",
      "    changePoints : typing.Callable[[typing.Dict[str, typing.Any]], typing.Any], default=None\n",
      "        \n",
      "    changeLinks : typing.Callable[[typing.Dict[str, typing.Any]], typing.Any], default=None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from cosmograph import cosmo\n",
    "\n",
    "help(cosmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ad2d1ebadc46a6823189e457d088b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Cosmograph(background_color=None, focused_point_ring_color=None, hovered_point_ring_color=None, link_color=Non…"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosmo(points=pd.DataFrame([[1,2], [3,4], [5,6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from cosmograph import cosmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape=(123587, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "word                                                          a\n",
       "frequency                                              0.015441\n",
       "definition    a metric unit of length equal to one ten billi...\n",
       "lexname                                           noun.quantity\n",
       "name                                              angstrom.n.01\n",
       "pos                                                        noun\n",
       "umap_x                                                 3.027916\n",
       "umap_y                                                 3.760965\n",
       "Name: angstrom.n.01.a, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('https://www.dropbox.com/scl/fi/4mnk1e2wx31j9mdsjzecy/wordnet_feature_meta.parquet?rlkey=ixjiiso80s1uk4yhx1v38ekhm&dl=1')\n",
    "print(f\"{df.shape=}\")\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyponyms.shape=(258896, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "source           vitamin_a.n.01.a\n",
       "target    vitamin_a1.n.01.retinol\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyponyms = pd.read_parquet('https://www.dropbox.com/scl/fi/pl72ixv34soo1o8zanfrz/hyponyms.parquet?rlkey=t4d606fmq1uinn29qmli7bx6r&dl=1')\n",
    "print(f\"{hyponyms.shape=}\")\n",
    "hyponyms.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40bbdedd27ed47c5a4ce8df2612dfba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Cosmograph(background_color=None, focused_point_ring_color=None, hovered_point_ring_color=None, link_color=Non…"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = cosmo(\n",
    "    df,\n",
    "    point_id_by='lemma',\n",
    "    point_label_by='word',\n",
    "    point_x_by='umap_x',\n",
    "    point_y_by='umap_y',\n",
    "    point_color_by='pos',\n",
    "    point_size_by='frequency',\n",
    "    point_size_scale=0.01,  # often have to play with this number to get the size right\n",
    ")\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "583a49c4901b4944bbb9b9fbfaeea5da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Cosmograph(background_color=None, focused_point_ring_color=None, hovered_point_ring_color=None, link_color=Non…"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = cosmo(\n",
    "    points=df,\n",
    "    links=hyponyms,\n",
    "    link_source_by='source',\n",
    "    link_target_by='target',\n",
    "    point_id_by='lemma',\n",
    "    point_label_by='word',\n",
    "    # point_x_by='umap_x',\n",
    "    # point_y_by='umap_y',\n",
    "    point_color_by='pos',\n",
    "    point_size_by='frequency',\n",
    "    point_size_scale=0.01,  # often have to play with this number to get the size right\n",
    ")\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: WIP and scrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>23135851162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>13151942776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>12997637966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>12136980858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>9081174698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333328</th>\n",
       "      <td>gooek</td>\n",
       "      <td>12711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333329</th>\n",
       "      <td>gooddg</td>\n",
       "      <td>12711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333330</th>\n",
       "      <td>gooblle</td>\n",
       "      <td>12711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333331</th>\n",
       "      <td>gollgo</td>\n",
       "      <td>12711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333332</th>\n",
       "      <td>golgw</td>\n",
       "      <td>12711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333333 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word        count\n",
       "0           the  23135851162\n",
       "1            of  13151942776\n",
       "2           and  12997637966\n",
       "3            to  12136980858\n",
       "4             a   9081174698\n",
       "...         ...          ...\n",
       "333328    gooek        12711\n",
       "333329   gooddg        12711\n",
       "333330  gooblle        12711\n",
       "333331   gollgo        12711\n",
       "333332    golgw        12711\n",
       "\n",
       "[333333 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequency_data_url = 'https://github.com/thorwhalen/content/raw/refs/heads/master/tables/csv/zip/english-word-frequency.csv.zip'\n",
    "\n",
    "# Note: The (..., keep_default_na=False, na_values=[]) is to avoid words \"null\" and \"nan\" being interpretted as NaN\n",
    "#    see https://www.skytowner.com/explore/preventing_strings_from_getting_parsed_as_nan_for_read_csv_in_pandas\n",
    "word_counts = pd.read_csv(word_frequency_data_url, keep_default_na=False, na_values=[])\n",
    "word_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word properties (definition, type, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147306"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "len(list(wn.all_lemma_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147306"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lexis  # pip install lexis\n",
    "\n",
    "lemmas = lexis.Lemmas()\n",
    "len(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52078"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The words that are both in the lemmas and in the word_counts\n",
    "word_list = sorted(set(lemmas) & set(word_counts.word))\n",
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['examples',\n",
       " '__slots__',\n",
       " 'in_topic_domains',\n",
       " 'attributes',\n",
       " '_examples',\n",
       " 'frame_ids',\n",
       " 'part_holonyms',\n",
       " 'mst',\n",
       " '_lemma_pointers',\n",
       " 'substance_meronyms',\n",
       " '__module__',\n",
       " '_lexname',\n",
       " '_iter_hypernym_lists',\n",
       " '__dir__',\n",
       " '_instance_hypernyms',\n",
       " 'name',\n",
       " '__hash__',\n",
       " '_min_depth',\n",
       " 'topic_domains',\n",
       " 'acyclic_tree',\n",
       " 'in_usage_domains',\n",
       " '__doc__',\n",
       " 'verb_groups',\n",
       " '__dict__',\n",
       " 'entailments',\n",
       " 'hyponyms',\n",
       " 'substance_holonyms',\n",
       " 'hypernym_distances',\n",
       " '__weakref__',\n",
       " 'root_hypernyms',\n",
       " 'min_depth',\n",
       " 'member_holonyms',\n",
       " '_definition',\n",
       " 'hypernym_paths',\n",
       " 'in_region_domains',\n",
       " 'lemma_names',\n",
       " '_name',\n",
       " '_pointers',\n",
       " 'similar_tos',\n",
       " 'definition',\n",
       " '_lemmas',\n",
       " '_pos',\n",
       " 'max_depth',\n",
       " 'causes',\n",
       " 'instance_hypernyms',\n",
       " 'part_meronyms',\n",
       " '_max_depth',\n",
       " '_needs_root',\n",
       " '_hypernyms',\n",
       " 'instance_hyponyms',\n",
       " '_frame_ids',\n",
       " 'lexname',\n",
       " 'usage_domains',\n",
       " 'also_sees',\n",
       " 'member_meronyms',\n",
       " '__sizeof__',\n",
       " 'hypernyms',\n",
       " '__reduce__',\n",
       " '_lemma_names',\n",
       " '__repr__',\n",
       " 'lemmas',\n",
       " '__str__',\n",
       " 'offset',\n",
       " 'region_domains',\n",
       " 'pos',\n",
       " '_offset']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = lemmas['body']\n",
    "tt = t['body.n.01']\n",
    "list(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the entire structure of an organism (an animal, plant, or human being)'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt['definition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_all_hypernyms',\n",
       " '_definition',\n",
       " '_doc',\n",
       " '_examples',\n",
       " '_frame_ids',\n",
       " '_hypernyms',\n",
       " '_instance_hypernyms',\n",
       " '_iter_hypernym_lists',\n",
       " '_lemma_names',\n",
       " '_lemma_pointers',\n",
       " '_lemmas',\n",
       " '_lexname',\n",
       " '_max_depth',\n",
       " '_min_depth',\n",
       " '_name',\n",
       " '_needs_root',\n",
       " '_offset',\n",
       " '_pointers',\n",
       " '_pos',\n",
       " '_related',\n",
       " '_shortest_hypernym_paths',\n",
       " '_wordnet_corpus_reader',\n",
       " 'acyclic_tree',\n",
       " 'also_sees',\n",
       " 'attributes',\n",
       " 'causes',\n",
       " 'closure',\n",
       " 'common_hypernyms',\n",
       " 'definition',\n",
       " 'entailments',\n",
       " 'examples',\n",
       " 'frame_ids',\n",
       " 'hypernym_distances',\n",
       " 'hypernym_paths',\n",
       " 'hypernyms',\n",
       " 'hyponyms',\n",
       " 'in_region_domains',\n",
       " 'in_topic_domains',\n",
       " 'in_usage_domains',\n",
       " 'instance_hypernyms',\n",
       " 'instance_hyponyms',\n",
       " 'jcn_similarity',\n",
       " 'lch_similarity',\n",
       " 'lemma_names',\n",
       " 'lemmas',\n",
       " 'lexname',\n",
       " 'lin_similarity',\n",
       " 'lowest_common_hypernyms',\n",
       " 'max_depth',\n",
       " 'member_holonyms',\n",
       " 'member_meronyms',\n",
       " 'min_depth',\n",
       " 'mst',\n",
       " 'name',\n",
       " 'offset',\n",
       " 'part_holonyms',\n",
       " 'part_meronyms',\n",
       " 'path_similarity',\n",
       " 'pos',\n",
       " 'region_domains',\n",
       " 'res_similarity',\n",
       " 'root_hypernyms',\n",
       " 'shortest_path_distance',\n",
       " 'similar_tos',\n",
       " 'substance_holonyms',\n",
       " 'substance_meronyms',\n",
       " 'topic_domains',\n",
       " 'tree',\n",
       " 'usage_domains',\n",
       " 'verb_groups',\n",
       " 'wup_similarity']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tt.store.store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['body', 'organic_structure', 'physical_structure']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.store.store.lemma_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he felt as if his whole body were on fire']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.store.store.examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'go.n.01': WordnetElement('go.n.01'),\n",
       " 'adam.n.03': WordnetElement('adam.n.03'),\n",
       " 'crack.n.09': WordnetElement('crack.n.09'),\n",
       " 'go.n.04': WordnetElement('go.n.04'),\n",
       " 'travel.v.01': WordnetElement('travel.v.01'),\n",
       " 'go.v.02': WordnetElement('go.v.02'),\n",
       " 'go.v.03': WordnetElement('go.v.03'),\n",
       " 'become.v.01': WordnetElement('become.v.01'),\n",
       " 'go.v.05': WordnetElement('go.v.05'),\n",
       " 'run.v.05': WordnetElement('run.v.05'),\n",
       " 'run.v.03': WordnetElement('run.v.03'),\n",
       " 'proceed.v.04': WordnetElement('proceed.v.04'),\n",
       " 'go.v.09': WordnetElement('go.v.09'),\n",
       " 'go.v.10': WordnetElement('go.v.10'),\n",
       " 'sound.v.02': WordnetElement('sound.v.02'),\n",
       " 'function.v.01': WordnetElement('function.v.01'),\n",
       " 'run_low.v.01': WordnetElement('run_low.v.01'),\n",
       " 'move.v.13': WordnetElement('move.v.13'),\n",
       " 'survive.v.01': WordnetElement('survive.v.01'),\n",
       " 'go.v.16': WordnetElement('go.v.16'),\n",
       " 'die.v.01': WordnetElement('die.v.01'),\n",
       " 'belong.v.03': WordnetElement('belong.v.03'),\n",
       " 'go.v.19': WordnetElement('go.v.19'),\n",
       " 'start.v.09': WordnetElement('start.v.09'),\n",
       " 'move.v.15': WordnetElement('move.v.15'),\n",
       " 'go.v.22': WordnetElement('go.v.22'),\n",
       " 'go.v.23': WordnetElement('go.v.23'),\n",
       " 'blend.v.02': WordnetElement('blend.v.02'),\n",
       " 'go.v.25': WordnetElement('go.v.25'),\n",
       " 'fit.v.02': WordnetElement('fit.v.02'),\n",
       " 'rifle.v.02': WordnetElement('rifle.v.02'),\n",
       " 'go.v.28': WordnetElement('go.v.28'),\n",
       " 'plump.v.04': WordnetElement('plump.v.04'),\n",
       " 'fail.v.04': WordnetElement('fail.v.04'),\n",
       " 'go.a.01': WordnetElement('go.a.01')}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexis.lemma_methods_returning_lemmas\n",
    "lemma = lemmas['go']\n",
    "lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = lemma['a.n.06']\n",
    "dir(w)\n",
    "w.verb_groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('None')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexis.lemma_methods_returning_lemmas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lexis.KvSynset"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = lemmas['a']['a.n.06']\n",
    "type(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'end'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wordnet \u001b[38;5;28;01mas\u001b[39;00m wn\n\u001b[0;32m----> 3\u001b[0m \u001b[43mwn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlemma\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msalt.n.03\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/p10/lib/python3.10/site-packages/nltk/corpus/reader/wordnet.py:1454\u001b[0m, in \u001b[0;36mWordNetCorpusReader.lemma\u001b[0;34m(self, name, lang)\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return lemma object that matches the name\"\"\"\u001b[39;00m\n\u001b[1;32m   1452\u001b[0m \u001b[38;5;66;03m# cannot simply split on first '.',\u001b[39;00m\n\u001b[1;32m   1453\u001b[0m \u001b[38;5;66;03m# e.g.: '.45_caliber.a.01..45_caliber'\u001b[39;00m\n\u001b[0;32m-> 1454\u001b[0m separator \u001b[38;5;241m=\u001b[39m \u001b[43mSENSENUM_RE\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m()\n\u001b[1;32m   1456\u001b[0m synset_name, lemma_name \u001b[38;5;241m=\u001b[39m name[: separator \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m], name[separator:]\n\u001b[1;32m   1458\u001b[0m synset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msynset(synset_name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'end'"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "wn.lemma('salt.n.03.saltiness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>synset</th>\n",
       "      <th>definition</th>\n",
       "      <th>example</th>\n",
       "      <th>pos</th>\n",
       "      <th>hypernyms</th>\n",
       "      <th>hyponyms</th>\n",
       "      <th>member_holonyms</th>\n",
       "      <th>substance_holonyms</th>\n",
       "      <th>part_holonyms</th>\n",
       "      <th>...</th>\n",
       "      <th>part_meronyms</th>\n",
       "      <th>attributes</th>\n",
       "      <th>also_sees</th>\n",
       "      <th>verb_groups</th>\n",
       "      <th>entailments</th>\n",
       "      <th>causes</th>\n",
       "      <th>similar_tos</th>\n",
       "      <th>domain_topic</th>\n",
       "      <th>domain_region</th>\n",
       "      <th>domain_usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>body</td>\n",
       "      <td>body.n.01</td>\n",
       "      <td>the entire structure of an organism (an animal...</td>\n",
       "      <td>he felt as if his whole body were on fire</td>\n",
       "      <td>n</td>\n",
       "      <td>[natural_object.n.01]</td>\n",
       "      <td>[human_body.n.01, life_form.n.01, live_body.n.01]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[arm.n.01, articulatory_system.n.01, body_subs...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[animal.n.01, homo.n.02]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>body</td>\n",
       "      <td>body.n.02</td>\n",
       "      <td>a group of persons associated by some common t...</td>\n",
       "      <td>the whole body filed out of the auditorium</td>\n",
       "      <td>n</td>\n",
       "      <td>[social_group.n.01]</td>\n",
       "      <td>[administration.n.02, christendom.n.01, church...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>body</td>\n",
       "      <td>body.n.03</td>\n",
       "      <td>a natural object consisting of a dead animal o...</td>\n",
       "      <td>they found the body in the lake</td>\n",
       "      <td>n</td>\n",
       "      <td>[natural_object.n.01]</td>\n",
       "      <td>[cadaver.n.01, carcase.n.01, carrion.n.01, mum...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>body</td>\n",
       "      <td>body.n.04</td>\n",
       "      <td>an individual 3-dimensional object that has ma...</td>\n",
       "      <td>heavenly body</td>\n",
       "      <td>n</td>\n",
       "      <td>[natural_object.n.01]</td>\n",
       "      <td>[chromosome.n.01, inclusion_body.n.01, mass.n....</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>body</td>\n",
       "      <td>torso.n.01</td>\n",
       "      <td>the body excluding the head and neck and limbs</td>\n",
       "      <td>they moved their arms and legs and bodies</td>\n",
       "      <td>n</td>\n",
       "      <td>[body_part.n.01]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[body.n.01]</td>\n",
       "      <td>...</td>\n",
       "      <td>[abdomen.n.01, back.n.01, belly.n.02, buttock....</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>hand</td>\n",
       "      <td>hand.n.12</td>\n",
       "      <td>a round of applause to signify approval</td>\n",
       "      <td>give the little lady a great big hand</td>\n",
       "      <td>n</td>\n",
       "      <td>[applause.n.01]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>hand</td>\n",
       "      <td>hand.n.13</td>\n",
       "      <td>terminal part of the forelimb in certain verte...</td>\n",
       "      <td>the kangaroo's forearms seem undeveloped but t...</td>\n",
       "      <td>n</td>\n",
       "      <td>[forepaw.n.01]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>hand</td>\n",
       "      <td>hand.n.14</td>\n",
       "      <td>physical assistance</td>\n",
       "      <td>give me a hand with the chores</td>\n",
       "      <td>n</td>\n",
       "      <td>[aid.n.02]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>hand</td>\n",
       "      <td>pass.v.05</td>\n",
       "      <td>place into the hands or custody of</td>\n",
       "      <td>hand me the spoon, please</td>\n",
       "      <td>v</td>\n",
       "      <td>[transfer.v.05]</td>\n",
       "      <td>[deal.v.12, entrust.v.01, entrust.v.02, give.v...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>hand</td>\n",
       "      <td>hand.v.02</td>\n",
       "      <td>guide or conduct or usher somewhere</td>\n",
       "      <td>hand the elderly lady into the taxi</td>\n",
       "      <td>v</td>\n",
       "      <td>[lead.v.01]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    word      synset                                         definition  \\\n",
       "0   body   body.n.01  the entire structure of an organism (an animal...   \n",
       "1   body   body.n.02  a group of persons associated by some common t...   \n",
       "2   body   body.n.03  a natural object consisting of a dead animal o...   \n",
       "3   body   body.n.04  an individual 3-dimensional object that has ma...   \n",
       "4   body  torso.n.01     the body excluding the head and neck and limbs   \n",
       "..   ...         ...                                                ...   \n",
       "65  hand   hand.n.12            a round of applause to signify approval   \n",
       "66  hand   hand.n.13  terminal part of the forelimb in certain verte...   \n",
       "67  hand   hand.n.14                                physical assistance   \n",
       "68  hand   pass.v.05                 place into the hands or custody of   \n",
       "69  hand   hand.v.02                guide or conduct or usher somewhere   \n",
       "\n",
       "                                              example pos  \\\n",
       "0           he felt as if his whole body were on fire   n   \n",
       "1          the whole body filed out of the auditorium   n   \n",
       "2                     they found the body in the lake   n   \n",
       "3                                       heavenly body   n   \n",
       "4           they moved their arms and legs and bodies   n   \n",
       "..                                                ...  ..   \n",
       "65              give the little lady a great big hand   n   \n",
       "66  the kangaroo's forearms seem undeveloped but t...   n   \n",
       "67                     give me a hand with the chores   n   \n",
       "68                          hand me the spoon, please   v   \n",
       "69                hand the elderly lady into the taxi   v   \n",
       "\n",
       "                hypernyms                                           hyponyms  \\\n",
       "0   [natural_object.n.01]  [human_body.n.01, life_form.n.01, live_body.n.01]   \n",
       "1     [social_group.n.01]  [administration.n.02, christendom.n.01, church...   \n",
       "2   [natural_object.n.01]  [cadaver.n.01, carcase.n.01, carrion.n.01, mum...   \n",
       "3   [natural_object.n.01]  [chromosome.n.01, inclusion_body.n.01, mass.n....   \n",
       "4        [body_part.n.01]                                                 []   \n",
       "..                    ...                                                ...   \n",
       "65        [applause.n.01]                                                 []   \n",
       "66         [forepaw.n.01]                                                 []   \n",
       "67             [aid.n.02]                                                 []   \n",
       "68        [transfer.v.05]  [deal.v.12, entrust.v.01, entrust.v.02, give.v...   \n",
       "69            [lead.v.01]                                                 []   \n",
       "\n",
       "   member_holonyms substance_holonyms part_holonyms  ...  \\\n",
       "0               []                 []            []  ...   \n",
       "1               []                 []            []  ...   \n",
       "2               []                 []            []  ...   \n",
       "3               []                 []            []  ...   \n",
       "4               []                 []   [body.n.01]  ...   \n",
       "..             ...                ...           ...  ...   \n",
       "65              []                 []            []  ...   \n",
       "66              []                 []            []  ...   \n",
       "67              []                 []            []  ...   \n",
       "68              []                 []            []  ...   \n",
       "69              []                 []            []  ...   \n",
       "\n",
       "                                        part_meronyms attributes also_sees  \\\n",
       "0   [arm.n.01, articulatory_system.n.01, body_subs...         []        []   \n",
       "1                                                  []         []        []   \n",
       "2                                                  []         []        []   \n",
       "3                                                  []         []        []   \n",
       "4   [abdomen.n.01, back.n.01, belly.n.02, buttock....         []        []   \n",
       "..                                                ...        ...       ...   \n",
       "65                                                 []         []        []   \n",
       "66                                                 []         []        []   \n",
       "67                                                 []         []        []   \n",
       "68                                                 []         []        []   \n",
       "69                                                 []         []        []   \n",
       "\n",
       "   verb_groups entailments causes similar_tos              domain_topic  \\\n",
       "0           []          []     []          []  [animal.n.01, homo.n.02]   \n",
       "1           []          []     []          []                        []   \n",
       "2           []          []     []          []                        []   \n",
       "3           []          []     []          []                        []   \n",
       "4           []          []     []          []                        []   \n",
       "..         ...         ...    ...         ...                       ...   \n",
       "65          []          []     []          []                        []   \n",
       "66          []          []     []          []                        []   \n",
       "67          []          []     []          []                        []   \n",
       "68          []          []     []          []                        []   \n",
       "69          []          []     []          []                        []   \n",
       "\n",
       "   domain_region domain_usage  \n",
       "0             []           []  \n",
       "1             []           []  \n",
       "2             []           []  \n",
       "3             []           []  \n",
       "4             []           []  \n",
       "..           ...          ...  \n",
       "65            []           []  \n",
       "66            []           []  \n",
       "67            []           []  \n",
       "68            []           []  \n",
       "69            []           []  \n",
       "\n",
       "[70 rows x 22 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_words = ['body', 'head', 'hand']\n",
    "\n",
    "t = pd.DataFrame(wordnet_details(test_words))\n",
    "print(f\"{t.shape}\")\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    word      synset                                         definition  \\\n",
      "0   body   body.n.01  the entire structure of an organism (an animal...   \n",
      "1   body   body.n.02  a group of persons associated by some common t...   \n",
      "2   body   body.n.03  a natural object consisting of a dead animal o...   \n",
      "3   body   body.n.04  an individual 3-dimensional object that has ma...   \n",
      "4   body  torso.n.01     the body excluding the head and neck and limbs   \n",
      "..   ...         ...                                                ...   \n",
      "65  hand   hand.n.12            a round of applause to signify approval   \n",
      "66  hand   hand.n.13  terminal part of the forelimb in certain verte...   \n",
      "67  hand   hand.n.14                                physical assistance   \n",
      "68  hand   pass.v.05                 place into the hands or custody of   \n",
      "69  hand   hand.v.02                guide or conduct or usher somewhere   \n",
      "\n",
      "                                             examples pos  \\\n",
      "0         [he felt as if his whole body were on fire]   n   \n",
      "1   [the whole body filed out of the auditorium, t...   n   \n",
      "2                   [they found the body in the lake]   n   \n",
      "3                                     [heavenly body]   n   \n",
      "4         [they moved their arms and legs and bodies]   n   \n",
      "..                                                ...  ..   \n",
      "65            [give the little lady a great big hand]   n   \n",
      "66  [the kangaroo's forearms seem undeveloped but ...   n   \n",
      "67                   [give me a hand with the chores]   n   \n",
      "68  [hand me the spoon, please, Turn the files ove...   v   \n",
      "69              [hand the elderly lady into the taxi]   v   \n",
      "\n",
      "                                      lemma_names              hypernyms  \\\n",
      "0   [body, organic_structure, physical_structure]  [natural_object.n.01]   \n",
      "1                                          [body]    [social_group.n.01]   \n",
      "2                               [body, dead_body]  [natural_object.n.01]   \n",
      "3                                          [body]  [natural_object.n.01]   \n",
      "4                            [torso, trunk, body]       [body_part.n.01]   \n",
      "..                                            ...                    ...   \n",
      "65                                         [hand]        [applause.n.01]   \n",
      "66                                         [hand]         [forepaw.n.01]   \n",
      "67                           [hand, helping_hand]             [aid.n.02]   \n",
      "68  [pass, hand, reach, pass_on, turn_over, give]        [transfer.v.05]   \n",
      "69                                         [hand]            [lead.v.01]   \n",
      "\n",
      "                                             hyponyms holonyms meronyms  \n",
      "0   [human_body.n.01, life_form.n.01, live_body.n.01]       []       []  \n",
      "1   [administration.n.02, christendom.n.01, church...       []       []  \n",
      "2   [cadaver.n.01, carcase.n.01, carrion.n.01, mum...       []       []  \n",
      "3   [chromosome.n.01, inclusion_body.n.01, mass.n....       []       []  \n",
      "4                                                  []       []       []  \n",
      "..                                                ...      ...      ...  \n",
      "65                                                 []       []       []  \n",
      "66                                                 []       []       []  \n",
      "67                                                 []       []       []  \n",
      "68  [deal.v.12, entrust.v.01, entrust.v.02, give.v...       []       []  \n",
      "69                                                 []       []       []  \n",
      "\n",
      "[70 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import lexis\n",
    "lemmas = lexis.Lemmas()\n",
    "\n",
    "def extract_synset_features(word):\n",
    "    if word in lemmas:\n",
    "        for synset_key, synset in lemmas[word].items():\n",
    "            row = {\n",
    "                \"word\": word,\n",
    "                \"synset\": synset_key,\n",
    "                \"definition\": synset.get('definition', ''),\n",
    "                \"examples\": synset.get('examples', []),\n",
    "                \"pos\": synset.get('pos', ''),\n",
    "                \"lemma_names\": synset.get('lemma_names', []),\n",
    "                \"hypernyms\": [h.name() for h in synset.get('hypernyms', [])],\n",
    "                \"hyponyms\": [h.name() for h in synset.get('hyponyms', [])],\n",
    "                \"holonyms\": [h.name() for h in synset.get('member_holonyms', [])],\n",
    "                \"meronyms\": [h.name() for h in synset.get('member_meronyms', [])],\n",
    "            }\n",
    "            yield row\n",
    "\n",
    "    return data\n",
    "\n",
    "# Combine data for all words\n",
    "\n",
    "rows = []\n",
    "for word in ['body', 'head', 'hand']:\n",
    "    rows.extend(extract_synset_features(word))\n",
    "\n",
    "# Create the dataframe\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Display the dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lemma('natural_object.n.01.natural_object')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'body'\n",
    "t = lemmas[word]\n",
    "t['body.n.01']['hypernyms'][0].lemmas()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147306"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: word, dtype: object)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.word[word_counts.word.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graze as gz\n",
    "b = gz.graze(word_frequency_data_url)\n",
    "from dol import zip_decompress\n",
    "b = zip_decompress(b)\n",
    "import io\n",
    "bi = io.BytesIO(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333331"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = pd.read_csv(bi, na_values=[])\n",
    "t.word.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = bi.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'nan,3398089\\n'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it[12819 + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting embeddings of our words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = '/Users/thorwhalen/Dropbox/_odata/figiri/english_words'\n",
    "\n",
    "from tabled import DfFiles\n",
    "\n",
    "df_files = DfFiles(rootdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52078"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'words_embeddings.parquet' not in df_files:\n",
    "    import oa\n",
    "\n",
    "    assert len(word_list) == len(set(word_list)), \"Words not unique\"\n",
    "    word_embeddings = oa.embeddings(word_list)\n",
    "    df = pd.DataFrame(index=word_list, data=map(lambda x: [x], word_embeddings))\n",
    "    df.columns = ['embedding']\n",
    "    df_files['words_embeddings.parquet'] = df\n",
    "else:\n",
    "    df = df_files['words_embeddings.parquet']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'umap_embeddings.parquet' not in df_files:\n",
    "    import imbed\n",
    "    umap_planar_embeddings = imbed.umap_2d_embeddings(df.embedding)\n",
    "    umap_embeddings = imbed.planar_embeddings_dict_to_df(umap_planar_embeddings, index_name='word')\n",
    "    df_files['umap_embeddings.parquet'] = umap_embeddings\n",
    "else:\n",
    "    umap_embeddings = df_files['umap_embeddings.parquet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>3.027916</td>\n",
       "      <td>3.760965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa</td>\n",
       "      <td>3.009660</td>\n",
       "      <td>3.677792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaa</td>\n",
       "      <td>2.991489</td>\n",
       "      <td>3.758253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aachen</td>\n",
       "      <td>1.601711</td>\n",
       "      <td>1.289808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aah</td>\n",
       "      <td>2.878280</td>\n",
       "      <td>3.509061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52073</th>\n",
       "      <td>zygomatic</td>\n",
       "      <td>-2.601842</td>\n",
       "      <td>2.954538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52074</th>\n",
       "      <td>zygote</td>\n",
       "      <td>-2.934901</td>\n",
       "      <td>1.785373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52075</th>\n",
       "      <td>zygotic</td>\n",
       "      <td>-3.039186</td>\n",
       "      <td>1.812226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52076</th>\n",
       "      <td>zyloprim</td>\n",
       "      <td>-3.420418</td>\n",
       "      <td>0.476265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52077</th>\n",
       "      <td>zymogen</td>\n",
       "      <td>-3.384059</td>\n",
       "      <td>1.371314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52078 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word         x         y\n",
       "0              a  3.027916  3.760965\n",
       "1             aa  3.009660  3.677792\n",
       "2            aaa  2.991489  3.758253\n",
       "3         aachen  1.601711  1.289808\n",
       "4            aah  2.878280  3.509061\n",
       "...          ...       ...       ...\n",
       "52073  zygomatic -2.601842  2.954538\n",
       "52074     zygote -2.934901  1.785373\n",
       "52075    zygotic -3.039186  1.812226\n",
       "52076   zyloprim -3.420418  0.476265\n",
       "52077    zymogen -3.384059  1.371314\n",
       "\n",
       "[52078 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umap_embeddings.reset_index(inplace=True)\n",
    "umap_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files['umap_embeddings.csv'] = umap_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lemmas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m w \u001b[38;5;241m=\u001b[39m \u001b[43mlemmas\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody.n.01\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m w\u001b[38;5;241m.\u001b[39mlemmas()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lemmas' is not defined"
     ]
    }
   ],
   "source": [
    "w = lemmas['body']['body.n.01']\n",
    "w.lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.lemmas()[0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 0]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = next(iter(lemmas['go'].values()))\n",
    "[x.count() for x in w.lemmas()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_frame_ids',\n",
       " '_frame_strings',\n",
       " '_hypernyms',\n",
       " '_instance_hypernyms',\n",
       " '_key',\n",
       " '_lang',\n",
       " '_lex_id',\n",
       " '_lexname_index',\n",
       " '_name',\n",
       " '_related',\n",
       " '_synset',\n",
       " '_syntactic_marker',\n",
       " '_wordnet_corpus_reader',\n",
       " 'also_sees',\n",
       " 'antonyms',\n",
       " 'attributes',\n",
       " 'causes',\n",
       " 'count',\n",
       " 'derivationally_related_forms',\n",
       " 'entailments',\n",
       " 'frame_ids',\n",
       " 'frame_strings',\n",
       " 'hypernyms',\n",
       " 'hyponyms',\n",
       " 'in_region_domains',\n",
       " 'in_topic_domains',\n",
       " 'in_usage_domains',\n",
       " 'instance_hypernyms',\n",
       " 'instance_hyponyms',\n",
       " 'key',\n",
       " 'lang',\n",
       " 'member_holonyms',\n",
       " 'member_meronyms',\n",
       " 'name',\n",
       " 'part_holonyms',\n",
       " 'part_meronyms',\n",
       " 'pertainyms',\n",
       " 'region_domains',\n",
       " 'similar_tos',\n",
       " 'substance_holonyms',\n",
       " 'substance_meronyms',\n",
       " 'synset',\n",
       " 'syntactic_marker',\n",
       " 'topic_domains',\n",
       " 'usage_domains',\n",
       " 'verb_groups']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(w.lemmas()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ww = w.lemmas()[0]\n",
    "ww.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ww.pertainyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
